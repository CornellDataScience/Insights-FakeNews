{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRelevance Detection\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Relevance Detection\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import preprocessing\n",
    "import importlib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'preprocessing' from '/Users/dannyyang/Documents/GitHub/Insights-FakeNews/preprocessing.py'>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run this cell to reload the preprocessing module\n",
    "importlib.reload(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>137</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>1034</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance\n",
       "0  Police find mass graves with at least '15 bodi...      712  unrelated\n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158    related\n",
       "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated\n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated\n",
       "4  Spider burrowed through tourist's stomach and ...     1923    related"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stances = pd.read_csv(\"fn_data/train_stances.csv\")\n",
    "train_stances[\"Stance\"] = train_stances[\"Stance\"].apply(lambda x: \"related\" if x != \"unrelated\" else x)\n",
    "print(train_stances.shape)\n",
    "train_stances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1683, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody\n",
       "0        0  A small meteorite crashed into a wooded area i...\n",
       "1        4  Last week we hinted at what was to come as Ebo...\n",
       "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...\n",
       "3        6  Posting photos of a gun-toting child online, I...\n",
       "4        7  At least 25 suspected Boko Haram insurgents we..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bodies = pd.read_csv(\"fn_data/train_bodies.csv\")\n",
    "print(train_bodies.shape)\n",
    "train_bodies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(np.arange(len(train_stances))) \n",
    "stances = train_stances.values[idx]\n",
    "train = int(len(stances)*0.8)\n",
    "stances_tr = stances[:train]\n",
    "stances_val = stances[train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_body_list(data):\n",
    "    return [preprocessing.get_body(i, train_bodies) for i in set([x[1] for x in data])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_list = get_body_list(stances_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [preprocessing.get_clean_tokens(x) for x in body_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = preprocessing.build_idf_tokens(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['burger', 'year', 'friend', 'australians', 'mcdonald', 's', 'news', 'report', 'charity', 'quarter'] ['say', 'bought', 'showed', 'started', 's', 'wonder', 'went', 'pretty', 'holding', 'add']\n",
      "['burger', 'australians', 'mcdonald', 'charity', 'mickey', 'friend', 'depression', 'specimen', 'nitz', 'anxiety'] ['bought', 'dissuaded', 'sauce', 'wrapping', 'likes', 'showed', 'preserved', 'started', 'blue', 'wonder']\n"
     ]
    }
   ],
   "source": [
    "body = preprocessing.get_body(5, train_bodies)\n",
    "\n",
    "#no IDF\n",
    "processed2 = preprocessing.process_body(body)\n",
    "print(processed2['common_nouns'],processed2['common_verbs'])\n",
    "\n",
    "#with IDF\n",
    "processed = preprocessing.process_body(body, idf)\n",
    "print(processed['common_nouns'],processed['common_verbs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 100\n",
      "processed 200\n",
      "processed 300\n",
      "processed 400\n",
      "processed 500\n",
      "processed 600\n",
      "processed 700\n",
      "processed 800\n",
      "processed 900\n",
      "processed 1000\n",
      "processed 1100\n",
      "processed 1200\n",
      "processed 1300\n",
      "processed 1400\n",
      "processed 1500\n",
      "processed 1600\n",
      "done! processed 1683\n"
     ]
    }
   ],
   "source": [
    "body_info = preprocessing.process_bodies(train_bodies, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feats(data, body_dict):\n",
    "    headline, body_id = data[0],int(data[1])\n",
    "    headline_data = preprocessing.process_sentence(headline)\n",
    "    shared_common_nouns = len(set(headline_data['nouns']).intersection(set(body_dict[body_id]['common_nouns'])))\n",
    "    shared_common_verbs = len(set(headline_data['verbs']).intersection(set(body_dict[body_id]['common_verbs'])))\n",
    "    shared_bigrams = len(set(headline_data['bigrams']).intersection(set(body_dict[body_id]['common_bigrams'])))\n",
    "    sentiment_diff = {\n",
    "        \"pos\": headline_data['sentiment']['pos']-body_dict[body_id]['sentiment']['pos'],\n",
    "        \"neg\": headline_data['sentiment']['neg']-body_dict[body_id]['sentiment']['neg'],\n",
    "        \"neu\": headline_data['sentiment']['neu']-body_dict[body_id]['sentiment']['neu'],\n",
    "        \"compound\": headline_data['sentiment']['compound']-body_dict[body_id]['sentiment']['compound']\n",
    "    }\n",
    "    sentiment_diff_first = {\n",
    "        \"pos\": headline_data['sentiment']['pos']-body_dict[body_id]['first_sentence']['sentiment']['pos'],\n",
    "        \"neg\": headline_data['sentiment']['neg']-body_dict[body_id]['first_sentence']['sentiment']['neg'],\n",
    "        \"neu\": headline_data['sentiment']['neu']-body_dict[body_id]['first_sentence']['sentiment']['neu'],\n",
    "        \"compound\": headline_data['sentiment']['compound']-body_dict[body_id]['first_sentence']['sentiment']['compound']\n",
    "    }\n",
    "    shared_nouns_first = len(set(headline_data['nouns']).intersection(set(body_dict[body_id]['first_sentence']['nouns'])))\n",
    "    shared_verbs_first = len(set(headline_data['verbs']).intersection(set(body_dict[body_id]['first_sentence']['verbs'])))\n",
    "    shared_bigrams_first = len(set(headline_data['bigrams']).intersection(set(body_dict[body_id]['first_sentence']['bigrams'])))\n",
    "    return {\n",
    "        'shared_nouns': shared_common_nouns,\n",
    "        'shared_verbs': shared_common_verbs,\n",
    "        'shared_bigrams': shared_bigrams,\n",
    "        'sentiment_pos': sentiment_diff['pos'],\n",
    "        'sentiment_neg': sentiment_diff['neg'],\n",
    "        'sentiment_neu': sentiment_diff['neu'],\n",
    "        'sentiment_compound':sentiment_diff_first['compound'],\n",
    "        'sentiment_pos_fst': sentiment_diff_first['pos'],\n",
    "        'sentiment_neg_fst': sentiment_diff_first['neg'],\n",
    "        'sentiment_neu_fst': sentiment_diff_first['neu'],\n",
    "        'sentiment_compound_fst':sentiment_diff_first['compound'],\n",
    "        'shared_nouns_fst':shared_nouns_first,\n",
    "        'shared_verbs_fst':shared_verbs_first,\n",
    "        'shared_bigrams_fst':shared_bigrams_first   \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_list = ['shared_nouns',\n",
    "        'shared_verbs',\n",
    "        'shared_bigrams',\n",
    "        'sentiment_pos',\n",
    "        'sentiment_neg',\n",
    "        'sentiment_neu',\n",
    "        'sentiment_compound',\n",
    "        'sentiment_pos_fst',\n",
    "        'sentiment_neg_fst',\n",
    "        'sentiment_neu_fst',\n",
    "        'sentiment_compound_fst',\n",
    "        'shared_nouns_fst',\n",
    "        'shared_verbs_fst',\n",
    "        'shared_bigrams_fst']\n",
    "#train data\n",
    "data_feats = [get_feats(i, body_info) for i in stances_tr]\n",
    "train_df = pd.DataFrame()\n",
    "train_df['label'] = [1 if x[2] == \"unrelated\" else -1 for x in stances_tr]\n",
    "for i in feats_list:\n",
    "    train_df[i] = [x[i] for x in data_feats]\n",
    "\n",
    "#val data\n",
    "val_feats = [get_feats(i, body_info) for i in stances_val]\n",
    "val_df = pd.DataFrame()\n",
    "val_df['label'] = [1 if x[2] == \"unrelated\" else -1 for x in stances_val]\n",
    "for i in feats_list:\n",
    "    val_df[i] = [x[i] for x in val_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-1: 10700, 1: 29277})"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Woman Stays In KFC For A Week To Get Over Her ...</td>\n",
       "      <td>971</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Experts: More facts needed on purported audio ...</td>\n",
       "      <td>195</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angry mob chops off man's genitals with butche...</td>\n",
       "      <td>17</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Former U.S. soldier says IS used chemical weap...</td>\n",
       "      <td>1369</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>These LEGO Instructions from 1974 Are Awesome ...</td>\n",
       "      <td>1169</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Seth Rogen set to play Steve Wozniak in Danny ...</td>\n",
       "      <td>1586</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>$YUM Serving Up #Marijuana &amp; Fried Chicken</td>\n",
       "      <td>1826</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The gold Apple Watch Edition could set you bac...</td>\n",
       "      <td>1700</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Airport worker strips naked at security scanne...</td>\n",
       "      <td>2248</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Canadian official identifies dead Ottawa gunma...</td>\n",
       "      <td>2002</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0     1          2\n",
       "0  Woman Stays In KFC For A Week To Get Over Her ...   971  unrelated\n",
       "1  Experts: More facts needed on purported audio ...   195  unrelated\n",
       "2  Angry mob chops off man's genitals with butche...    17  unrelated\n",
       "3  Former U.S. soldier says IS used chemical weap...  1369    related\n",
       "4  These LEGO Instructions from 1974 Are Awesome ...  1169  unrelated\n",
       "5  Seth Rogen set to play Steve Wozniak in Danny ...  1586  unrelated\n",
       "6         $YUM Serving Up #Marijuana & Fried Chicken  1826  unrelated\n",
       "7  The gold Apple Watch Edition could set you bac...  1700    related\n",
       "8  Airport worker strips naked at security scanne...  2248  unrelated\n",
       "9  Canadian official identifies dead Ottawa gunma...  2002  unrelated"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stances_tr).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unconfirmed report circulating social medium islamic state group carried chemical attack battling kurdish force kobani journalist reporting ground tuesday night kurdish official said aware report doctor lack necessary equipment diagnose cause kurdish victim complaint patient said difficulty breathing burn skin teary eye swollen lip syria iraq thought posse chemical weapon u s coalition force feared weapon fall isis hand silent missile missile placed neighborhood chair democratic union party pyd asya abdullah told kurdish question people lost consciousness struggling breathe investigating situation necessary technical equipment expertise journalists reporting border kobani turkey reportedly spoke doctor scene confirmed pyd s description victim al aan tv reporter jenan moussa posted twitter doctor said victim way clinic speak following symptom teary eye suffocation skin burn victims swollen lip moussa added kurdish affair analyst mutlu civiroglu spoke remaining doctor inside kobani told victim civilian patient came health center 11 10pm burn throat complaining headache situation severe dr ahmed reportedly told civiroglu sure cause planning send affected patient suruc neighboring city turkish border morning examination reports similar chemical attack surfaced week kobani kurdish fighter body appeared sign blistering burns white spot body dead indicated use chemical led death visible wound external bleeding kurdish health minister nisan ahmed told middle east review international affairs journal rumor isis militant obtained chemical weapon given kobani syrian border turkey weapon come undisclosed syrian stockpile used belong damascus regime bashar assad regime carried chemical attack killed nearly thousand people year wa forced dismantle surrender stockpile year attack u s state department said number critical issue remain unresolved syrian president s chemical weapon substance allegedly used kobani ha confirmed chlorine attack syria assad wa supposed surrendered weapon cache chlorine banned chemical weapons convention used large concentration weaponized symptoms chlorine attack include teary eye burning sensation throat sensation suffocation headache isis ha battling kurdish fighter kobani month trying consolidate territory facto headquarters raqqa turkish border despite increase u s led coalition airstrikes aid drop aimed pushing insurgent helping kurdish fighter battle kobani continued tuesday night\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Unconfirmed reports are circulating on social media that the Islamic State group carried out a chemical attack while battling Kurdish forces in Kobani. Several journalists reporting from the ground on Tuesday night -- and at least one Kurdish official -- said they were aware of such reports, but that doctors lack necessary equipment to diagnose the cause of Kurdish victims\\' complaints. The patients said they had difficulty breathing, and many had burns on their skin, teary eyes and swollen lips. Syria (as well as Iraq) is thought to possess chemical weapons, and the U.S. and coalition forces have feared that such weapons might fall into ISIS hands.\\n\\n\"It could have been a silent missile or a missile placed in the neighborhood beforehand,” co-chair of the Democratic Union Party (PYD) Asya Abdullah told the Kurdish Question. “Many people have lost consciousness and are struggling to breathe and see. We are investigating the situation but do not have the necessary technical equipment or expertise.\"\\n\\nJournalists reporting from the border of Kobani and Turkey reportedly spoke to doctors on the scene who confirmed the PYD’s description of victims. Al Aan TV reporter Jenan Moussa posted on Twitter that a doctor said “victims who are on their way to clinic speak of following symptoms: teary eyes, suffocation and skin burns.” Victims also had “swollen lips,” Moussa added.\\n\\nKurdish affairs analyst Mutlu Civiroglu spoke to one of four remaining doctors inside Kobani, who told him all victims were civilians.\\n\\n“Several patients came to health center at 11:10pm with burn in the throat & as well as complaining about headache, though their situation is NOT very severe,\" Dr. Ahmed reportedly told Civiroglu. \"We are NOT sure what the cause is yet, but we are planning to send affected patients to Suruc [neighboring city in the Turkish side of the border] in the morning for further examination.”\\n\\nReports of a similar chemical attack surfaced last week in Kobani, when several Kurdish fighters’ bodies appeared to show signs of blistering.\\n\\n“Burns and white spots on the bodies of the dead indicated the use of chemicals, which led to death without any visible wounds or external bleeding,” Kurdish health minister Nisan Ahmed told Middle East Review of International Affairs journal.\\n\\nThere have been rumors that ISIS militants have obtained chemical weapons. Given that Kobani is on the Syrian border with Turkey, the weapons could have come from an undisclosed Syrian stockpile that used to belong to the Damascus regime.\\n\\nAfter the Bashar Assad regime carried out a chemical attack that killed nearly a thousand people last year, it was forced to dismantle and surrender stockpiles. A year after the attack though, the U.S. State Department said that a “number of critical issues remain unresolved” about the Syrian president\\'s chemical weapons.\\n\\nThe substance allegedly being used in Kobani has yet to be confirmed. However, there have been several chlorine attacks in Syria since Assad was supposed to have surrendered his weapons cache. Chlorine is not banned under the Chemical Weapons Convention but when used in large concentrations it can be weaponized. Symptoms of chlorine attacks include teary eyes, a burning sensation in the throat, the sensation of suffocation and a headache.\\n\\nISIS has been battling Kurdish fighters in Kobani for over a month, trying to consolidate territory from their de-facto headquarters in Raqqa to the Turkish border. Despite an increase in U.S-led coalition airstrikes and aid drops aimed at pushing insurgents back and helping Kurdish fighters, the battle for Kobani continued Tuesday night.'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stances_tr[3][0]\n",
    "print(' '.join(body_info[1369]['tokens']))\n",
    "print(\"\\n\\n\")\n",
    "preprocessing.get_body(1369, train_bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "model = LogisticRegression()\n",
    "model.fit(train_df.iloc[:,1:], train_df.iloc[:,0].values.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.44% training accuracy\n"
     ]
    }
   ],
   "source": [
    "tr_acc = model.score(train_df.iloc[:,1:], train_df.iloc[:,0].values.reshape(-1))\n",
    "print('{0:.2f}% training accuracy'.format(tr_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.25% validation accuracy\n"
     ]
    }
   ],
   "source": [
    "val_acc = model.score(val_df.iloc[:,1:], val_df.iloc[:,0].values.reshape(-1))\n",
    "print('{0:.2f}% validation accuracy'.format(val_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shared_nouns', -2.8139141614841305),\n",
       " ('shared_verbs', -2.5805092593519139),\n",
       " ('shared_bigrams', 0.0),\n",
       " ('sentiment_pos', -1.0617313526481831),\n",
       " ('sentiment_neg', -0.15746176680818072),\n",
       " ('sentiment_neu', -0.17507668645143698),\n",
       " ('sentiment_compound', -0.17246418205308636),\n",
       " ('sentiment_pos_fst', 1.0884129464244918),\n",
       " ('sentiment_neg_fst', -0.82848845357876655),\n",
       " ('sentiment_neu_fst', -0.27055575798928239),\n",
       " ('sentiment_compound_fst', -0.17246418205308636),\n",
       " ('shared_nouns_fst', -1.0136099527997449),\n",
       " ('shared_verbs_fst', -1.1997171149430081),\n",
       " ('shared_bigrams_fst', -2.2068885647881622)]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(feats_list[i],model.coef_[0][i]) for i in list(range(len(feats_list)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[2230  497]\n",
      " [ 178 7090]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "true_label = val_df.iloc[:,0]\n",
    "prediction = model.predict(val_df.iloc[:,1:])\n",
    "matrix = confusion_matrix(true_label,prediction)\n",
    "print('confusion matrix: \\n{}\\n'.format(matrix))\n",
    "tn1, fp1, fn1, tp1 = matrix.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9995, 15)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
