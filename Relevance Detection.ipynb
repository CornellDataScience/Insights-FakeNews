{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRelevance Detection\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Relevance Detection\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import preprocessing\n",
    "import importlib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'preprocessing' from '/Users/dannyyang/Documents/GitHub/Insights-FakeNews/preprocessing.py'>"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run this cell to reload the preprocessing module\n",
    "importlib.reload(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>137</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>1034</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance\n",
       "0  Police find mass graves with at least '15 bodi...      712  unrelated\n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree\n",
       "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated\n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated\n",
       "4  Spider burrowed through tourist's stomach and ...     1923   disagree"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stances = pd.read_csv(\"fn_data/train_stances.csv\")\n",
    "print(train_stances.shape)\n",
    "train_stances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1683, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody\n",
       "0        0  A small meteorite crashed into a wooded area i...\n",
       "1        4  Last week we hinted at what was to come as Ebo...\n",
       "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...\n",
       "3        6  Posting photos of a gun-toting child online, I...\n",
       "4        7  At least 25 suspected Boko Haram insurgents we..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bodies = pd.read_csv(\"fn_data/train_bodies.csv\")\n",
    "print(train_bodies.shape)\n",
    "train_bodies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39375, 3), (10597, 3))"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stances_tr, stances_val = preprocessing.train_test_split(train_bodies, train_stances)\n",
    "stances_tr.shape, stances_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one takes a while!\n",
    "idf = preprocessing.build_idf(train_bodies, stances_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attack', 'kobani', 'victim', 'weapon', 'border', 'report', 'doctor', 'burn', 'eye', 'isi'] ['said', 'used', 'carried', 'battling', 'reporting', 'swollen', 'told', 'spoke', 'confirmed', 'ahmed']\n",
      "['kobani', 'attack', 'moussa', 'burn', 'headache', 'victim', 'suffocation', 'doctor', 'eye', 'throat'] ['swollen', 'battling', 'used', 'said', 'spoke', 'carried', 'ahmed', 'reporting', 'led', 'surrendered']\n"
     ]
    }
   ],
   "source": [
    "#this is just a comparison between using IDF score and not using IDF score - not related to the model\n",
    "#change the body id to see\n",
    "body = preprocessing.get_body(1369, train_bodies)\n",
    "#no IDF\n",
    "processed2 = preprocessing.process_body(body)\n",
    "print(processed2['common_nouns'],processed2['common_verbs'])\n",
    "\n",
    "#with IDF\n",
    "processed = preprocessing.process_body(body, idf)\n",
    "print(processed['common_nouns'],processed['common_verbs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 100\n",
      "processed 200\n",
      "processed 300\n",
      "processed 400\n",
      "processed 500\n",
      "processed 600\n",
      "processed 700\n",
      "processed 800\n",
      "processed 900\n",
      "processed 1000\n",
      "processed 1100\n",
      "processed 1200\n",
      "processed 1300\n",
      "processed 1400\n",
      "processed 1500\n",
      "processed 1600\n",
      "done! processed 1683\n"
     ]
    }
   ],
   "source": [
    "#this takes a while!\n",
    "body_info = preprocessing.process_bodies(train_bodies, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_list = [\n",
    "    'shared_nouns',\n",
    "    'shared_verbs',\n",
    "    'shared_bigrams',\n",
    "    'shared_trigrams',\n",
    "    'shared_tokens',\n",
    "#     'sentiment_pos',\n",
    "#     'sentiment_neg',\n",
    "#     'sentiment_neu',\n",
    "#     'sentiment_compound',\n",
    "\n",
    "    'shared_nouns_fst',\n",
    "    'shared_verbs_fst',\n",
    "    'shared_bigrams_fst',\n",
    "    'shared_trigrams_fst',\n",
    "    'shared_tokens_fst',\n",
    "#     'sentiment_pos_fst',\n",
    "#     'sentiment_neg_fst',\n",
    "#     'sentiment_neu_fst',\n",
    "#     'sentiment_compound_fst',\n",
    "\n",
    "    'shared_nouns_sig',\n",
    "    'shared_verbs_sig',\n",
    "    'shared_bigrams_sig',\n",
    "    'shared_trigrams_sig',\n",
    "    'shared_tokens_sig',\n",
    "#     'sentiment_pos_sig',\n",
    "#     'sentiment_neg_sig',\n",
    "#     'sentiment_neu_sig',\n",
    "#     'sentiment_compound_sig',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one takes a while also!\n",
    "\n",
    "#train data\n",
    "data_feats = [preprocessing.get_feats(i, body_info) for i in stances_tr.values]\n",
    "train_df = pd.DataFrame()\n",
    "for i in feats_list:\n",
    "    train_df[i] = [x[i] for x in data_feats]\n",
    "\n",
    "#val data\n",
    "val_feats = [preprocessing.get_feats(i, body_info) for i in stances_val.values]\n",
    "val_df = pd.DataFrame()\n",
    "for i in feats_list:\n",
    "    val_df[i] = [x[i] for x in val_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shared_nouns</th>\n",
       "      <th>shared_verbs</th>\n",
       "      <th>shared_bigrams</th>\n",
       "      <th>shared_trigrams</th>\n",
       "      <th>shared_tokens</th>\n",
       "      <th>shared_nouns_fst</th>\n",
       "      <th>shared_verbs_fst</th>\n",
       "      <th>shared_bigrams_fst</th>\n",
       "      <th>shared_trigrams_fst</th>\n",
       "      <th>shared_tokens_fst</th>\n",
       "      <th>shared_nouns_sig</th>\n",
       "      <th>shared_verbs_sig</th>\n",
       "      <th>shared_bigrams_sig</th>\n",
       "      <th>shared_trigrams_sig</th>\n",
       "      <th>shared_tokens_sig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shared_nouns  shared_verbs  shared_bigrams  shared_trigrams  shared_tokens  \\\n",
       "0             2             0               0                0              6   \n",
       "1             0             0               0                0              0   \n",
       "2             1             0               0                0              3   \n",
       "3             5             0               0                0             12   \n",
       "4             0             0               0                0              0   \n",
       "\n",
       "   shared_nouns_fst  shared_verbs_fst  shared_bigrams_fst  \\\n",
       "0                 1                 0                   0   \n",
       "1                 0                 0                   0   \n",
       "2                 0                 0                   0   \n",
       "3                 3                 0                   2   \n",
       "4                 0                 0                   0   \n",
       "\n",
       "   shared_trigrams_fst  shared_tokens_fst  shared_nouns_sig  shared_verbs_sig  \\\n",
       "0                    0                  3                 1                 0   \n",
       "1                    0                  0                 0                 0   \n",
       "2                    0                  0                 1                 0   \n",
       "3                    1                  8                 5                 0   \n",
       "4                    0                  0                 0                 0   \n",
       "\n",
       "   shared_bigrams_sig  shared_trigrams_sig  shared_tokens_sig  \n",
       "0                   0                    0                  2  \n",
       "1                   0                    0                  0  \n",
       "2                   0                    0                  1  \n",
       "3                   7                    6                  9  \n",
       "4                   0                    0                  0  "
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-1: 28772, 1: 10603})"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'] = [-1 if x == \"unrelated\" else 1 for x in list(stances_tr['Stance'])]\n",
    "val_df['label'] = [-1 if x == \"unrelated\" else 1 for x in list(stances_val['Stance'])]\n",
    "Counter(train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dannyyang/Library/Python/3.6/lib/python/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "for i in feats_list:\n",
    "    train_df[i] = scaler.fit_transform(train_df[i].values.reshape(-1,1))\n",
    "    val_df[i] = scaler.fit_transform(val_df[i].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "model = LogisticRegression()\n",
    "model.fit(train_df.iloc[:,:-1], train_df.iloc[:,-1].values.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.49% training accuracy\n",
      "96.05% validation accuracy\n"
     ]
    }
   ],
   "source": [
    "tr_acc = model.score(train_df.iloc[:,:-1], train_df.iloc[:,-1].values.reshape(-1))\n",
    "print('{0:.2f}% training accuracy'.format(tr_acc*100))\n",
    "val_acc = model.score(val_df.iloc[:,:-1], val_df.iloc[:,-1].values.reshape(-1))\n",
    "print('{0:.2f}% validation accuracy'.format(val_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shared_nouns', 1.0436195894034368),\n",
       " ('shared_verbs', 0.17090579112350138),\n",
       " ('shared_bigrams', 0.0),\n",
       " ('shared_trigrams', 0.0),\n",
       " ('shared_tokens', 2.5444769305638357),\n",
       " ('shared_nouns_fst', -0.59776984389062682),\n",
       " ('shared_verbs_fst', -0.088235385011290524),\n",
       " ('shared_bigrams_fst', -0.60259625801276784),\n",
       " ('shared_trigrams_fst', -0.035107224032494944),\n",
       " ('shared_tokens_fst', 2.3794049411145468),\n",
       " ('shared_nouns_sig', -0.17922469503414037),\n",
       " ('shared_verbs_sig', -0.15152716694507024),\n",
       " ('shared_bigrams_sig', -0.49102116510446042),\n",
       " ('shared_trigrams_sig', 0.61343327702741157),\n",
       " ('shared_tokens_sig', 0.89173118714318367)]"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get coefficients\n",
    "[(feats_list[i],model.coef_[0][i]) for i in list(range(len(feats_list)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[7637  136]\n",
      " [ 283 2541]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_label = val_df.iloc[:,-1]\n",
    "prediction = model.predict(val_df.iloc[:,:-1])\n",
    "matrix = confusion_matrix(true_label,prediction)\n",
    "print('confusion matrix: \\n{}\\n'.format(matrix))\n",
    "tn1, fp1, fn1, tp1 = matrix.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |     0     |     0     |    626    |    71     |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |     0     |     0     |    168    |    24     |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |     0     |     0     |   1747    |    188    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |     0     |     0     |    136    |   7637    |\n",
      "-------------------------------------------------------------\n",
      "Score: 3854.75 out of 4767.25\t(80.85898578845246%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80.85898578845246"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use FNC scorer to generate score report\n",
    "label_prediction = [\"discuss\" if i == 1 else \"unrelated\" for i in prediction]\n",
    "label_actual = pd.DataFrame(stances_val)['Stance']\n",
    "score.report_score(label_actual, label_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
