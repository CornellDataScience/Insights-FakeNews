{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stance Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import preprocessing, feature_engineering, helpers\n",
    "import importlib\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import itertools\n",
    "import utils\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(preprocessing)\n",
    "importlib.reload(feature_engineering)\n",
    "importlib.reload(helpers)\n",
    "importlib.reload(utils)\n",
    "preprocess = preprocessing.Preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().config.get('IPKernelApp', {})['parent_appname'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13427, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'Nasa Confirms Earth Will Experience 6 Days of...</td>\n",
       "      <td>154</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Banksy 'Arrested &amp; Real Identity Revealed' Is ...</td>\n",
       "      <td>1739</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gateway Pundit</td>\n",
       "      <td>2327</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline  Body ID    Stance\n",
       "1   Hundreds of Palestinians flee floods in Gaza a...      158     agree\n",
       "4   Spider burrowed through tourist's stomach and ...     1923  disagree\n",
       "5   'Nasa Confirms Earth Will Experience 6 Days of...      154     agree\n",
       "8   Banksy 'Arrested & Real Identity Revealed' Is ...     1739     agree\n",
       "10                                     Gateway Pundit     2327   discuss"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stances = pd.read_csv(\"fn_data/train_stances.csv\")\n",
    "train_stances = train_stances.loc[lambda x: x.Stance != \"unrelated\"]\n",
    "print(train_stances.shape)\n",
    "train_stances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1683, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody\n",
       "0        0  A small meteorite crashed into a wooded area i...\n",
       "1        4  Last week we hinted at what was to come as Ebo...\n",
       "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...\n",
       "3        6  Posting photos of a gun-toting child online, I...\n",
       "4        7  At least 25 suspected Boko Haram insurgents we..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bodies = pd.read_csv(\"fn_data/train_bodies.csv\")\n",
    "print(train_bodies.shape)\n",
    "train_bodies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10811, 3), (2616, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stances_tr, stances_val = preprocess.train_test_split(train_bodies, train_stances)\n",
    "stances_tr.shape, stances_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'discuss': 1826, 'agree': 679, 'disagree': 111})\n",
      "0.6980122324159022\n"
     ]
    }
   ],
   "source": [
    "ct = Counter(stances_val['Stance'])\n",
    "print(ct)\n",
    "print(ct.most_common(1)[0][1]/len(list(stances_val[\"Stance\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dict = preprocess.get_glove_dict(\"glove.6B.50d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([('nasa', 'NN')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('confirms', 'NNS')],\n",
       "  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('earth', 'NN')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('experience', 'NN')],\n",
       "  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('day', 'NN')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('total', 'JJ')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('darkness', 'NN')],\n",
       "  {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.25}),\n",
       " ([('december', 'NN')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('fake', 'NN')], {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.4767}),\n",
       " ([('news', 'NN')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('story', 'NN')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('go', 'VB')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('viral', 'JJ')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(nltk.pos_tag([x]),preprocess.get_sentiment(x)) for x in preprocess.get_clean_tokens(list(stances_tr.iloc[2,:])[0], False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7902431610341373"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess.cosine_similarity(glove_dict['reveal'], glove_dict['revealed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 100\n",
      "processed 200\n",
      "processed 300\n",
      "processed 400\n",
      "processed 500\n",
      "processed 600\n",
      "processed 700\n",
      "processed 800\n",
      "processed 900\n",
      "processed 1000\n",
      "processed 1100\n",
      "processed 1200\n",
      "processed 1300\n",
      "processed 1400\n",
      "processed 1500\n",
      "processed 1600\n",
      "done! processed 1683\n"
     ]
    }
   ],
   "source": [
    "body_dict = preprocess.process_bodies_stance(train_bodies, glove_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_feats = [preprocess.process_feats_stance(i, body_dict, glove_dict) for i in stances_tr.values]\n",
    "val_feats = [preprocess.process_feats_stance(i, body_dict, glove_dict) for i in stances_val.values]\n",
    "end = time.time()\n",
    "print(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: get the new get batch function\n",
    "def get_batch(data, targets, i,batch_size):\n",
    "    batches = data[i*batch_size:i*batch_size+batch_size]\n",
    "    results = targets[i*batch_size:i*batch_size+batch_size]\n",
    "    results = [(2 if result == \"agree\" else (1 if result == \"discuss\" else 0)) for result in results]\n",
    "    return np.array(batches),np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "def eval_model(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_x_test,batch_y_test = get_batch(val_feats,[str(x[-1]) for x in stances_val.values],0,len(stances_val))\n",
    "    model.eval()\n",
    "    predicted = None\n",
    "    with torch.no_grad():\n",
    "        inputs = Variable(torch.FloatTensor(batch_x_test))\n",
    "        labels = torch.LongTensor(batch_y_test)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy: %d %%' % (100 * correct / total))\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(predictions):    \n",
    "    #use FNC scorer to generate score report\n",
    "    label_prediction = [(\"agree\" if x == 2 else (\"discuss\" if x == 1 else \"disagree\")) for x in predictions]\n",
    "    label_actual = pd.DataFrame(stances_val)['Stance']\n",
    "    matrix = confusion_matrix(label_actual,label_prediction)\n",
    "    print('confusion matrix: \\n{}\\n'.format(matrix))\n",
    "    score.report_score(label_actual, label_prediction)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "\n",
    "\"\"\"\n",
    "    correct = (preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siamese(nn.Module):\n",
    "    # hidden dim: dimension of one RNN\n",
    "    # 2 * hidden dim: concatenated outputs\n",
    "    def __init__(self,embedding_dim, hidden_dim_head, hidden_dim_bod, dropout, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # RNN dimensions [embedding_dim, hidden_dim]\n",
    "        # To-Do: try varying hidden, output dims for each network\n",
    "        self.rnn1 = nn.RNN(20, hidden_dim_head, dropout=dropout)\n",
    "        self.rnn2 = nn.RNN(72, hidden_dim_bod, dropout=dropout)\n",
    "        # Note: output dim could technically be higher now? cause runnign through a loss function/MLP\n",
    "        #self.fc1 = nn.Linear(hidden_dim, output_dim)\n",
    "        #self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim_head+hidden_dim_bod, output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x originally = [batch size, nubmer of words, embedding dim]\n",
    "        # swap first two dimensions to match rnn specs\n",
    "        #print(f'x shape before: ${x.shape}')\n",
    "        x = x.permute([1,0,2])\n",
    "        \n",
    "        #print(f'x shape: ${x.shape}')\n",
    "        header = x[:, :, :20]\n",
    "        article = x[:, :, 20:]\n",
    "        \n",
    "        #print(f'header shape: ${header.shape}')\n",
    "        #print(f'article shape: ${article.shape}')\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        output1, hidden1 = self.rnn1(header)\n",
    "        output2, hidden2 = self.rnn2(article)\n",
    "        #print(f'Hidden1 shape: {hidden1.squeeze(0).shape}')\n",
    "        #print(f'Hidden2 shape: {hidden2.squeeze(0).shape}')\n",
    "     \n",
    "        hidden = self.dropout(torch.cat((hidden1.squeeze(0), hidden2.squeeze(0)),1))\n",
    "        #print(f'Hidden shape: {hidden.shape}')\n",
    "\n",
    "        #out = self.fc1(hidden1.squeeze(0))\n",
    "        #out = out.append(self.fc2(hidden2.squeeze(0)))\n",
    "        \n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: re-implement with LSTMs for each branch\n",
    "class Siamese_LSTM(nn.Module):\n",
    "    # hidden dim: dimension of one RNN\n",
    "    # 2 * hidden dim: concatenated outputs\n",
    "    def __init__(self,embedding_dim, hidden_dim_head, hidden_dim_bod, \n",
    "                 n_layers_head, n_layers_bod, bidirectional, dropout, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # RNN dimensions [embedding_dim, hidden_dim]\n",
    "        # To-Do: try varying hidden, output dims for each network\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(20, hidden_dim_head, num_layers=n_layers_head, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.rnn2 = nn.LSTM(72, hidden_dim_bod, num_layers=n_layers_bod, bidirectional=bidirectional, dropout=dropout)\n",
    "        # Note: output dim could technically be higher now? cause runnign through a loss function/MLP\n",
    "       \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc1 = nn.Linear((hidden_dim_head+hidden_dim_bod)*2, (hidden_dim_head+hidden_dim_bod)) #doubled for bidirectional\n",
    "        self.fc2 = nn.Linear((hidden_dim_head+hidden_dim_bod), output_dim)\n",
    "        \n",
    "    def set_n_layers(self, head, bod):\n",
    "        self.rnn1.num_layers = head\n",
    "        self.rnn2.num_layers = bod\n",
    "        \n",
    "    def set_n_hidden(self, head, bod):\n",
    "        self.rnn1.hidden_size = head\n",
    "        self.rnn2.hidden_size = bod\n",
    "        \n",
    "    def set_dropout(self, droupout):\n",
    "        self.droupout = droupout\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x originally = [batch size, nubmer of words, embedding dim]\n",
    "        # swap first two dimensions to match rnn specs\n",
    "        #print(f'x shape before: ${x.shape}')\n",
    "        x = x.permute([1,0,2])\n",
    "        \n",
    "        #print(f'x shape: ${x.shape}')\n",
    "        header = x[:, :, :20]\n",
    "        article = x[:, :, 20:]\n",
    "        \n",
    "        #print(f'header shape: ${header.shape}')\n",
    "        #print(f'article shape: ${article.shape}')\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        output1, (hidden1, cell1) = self.rnn1(header)\n",
    "        output2, (hidden2, cell2) = self.rnn2(article)\n",
    "        \n",
    "        \"\"\"print(f'Hidden1 shape: {hidden1.squeeze(0).shape}')\n",
    "        print(f'Hidden2 shape: {hidden2.squeeze(0).shape}')\"\"\"\n",
    "        \n",
    "        # Concats the last forward and backward hidden layers\n",
    "        # Wouldn't you only technically want to do this if it is in fact bidirectional? \n",
    "        hidden1 = torch.cat((hidden1[-2,:,:], hidden1[-1,:,:]), dim=1)\n",
    "        hidden2 = torch.cat((hidden2[-2,:,:], hidden2[-1,:,:]), dim=1)\n",
    "\n",
    "        \"\"\"print(f'Hidden1 shape front/back: {hidden1.shape}')\n",
    "        print(f'Hidden2 shape front/back: {hidden2.shape}')\"\"\"\n",
    "        \n",
    "        hidden_merge = torch.cat((hidden1.squeeze(0), hidden2.squeeze(0)),1)\n",
    "        # TODO: Check if concatenating along dim 1 might be better if first squeeze each hidden\n",
    "        \"\"\"print(f'Concatenated shape: {hidden_merge.shape}')\"\"\"\n",
    "     \n",
    "        hidden = self.dropout(hidden_merge)\n",
    "        \n",
    "        # Todo: add more layers beforehand, that's way too many to concatenate down to 3\n",
    "        fc1 = self.fc1(hidden)\n",
    "        \"\"\"print(f'FC shape: {fc1.shape}')\"\"\"\n",
    "\n",
    "        fc1 = F.relu(fc1)\n",
    "\n",
    "        fc2 = self.fc2(fc1)\n",
    "        \n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 92\n",
    "HIDDEN_DIM_HEAD = 150\n",
    "HIDDEN_DIM_BOD = 256\n",
    "\n",
    "OUTPUT_DIM = 3\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "N_LAYERS = 2\n",
    "#BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Siamese_LSTM(EMBEDDING_DIM, hidden_dim_head=HIDDEN_DIM_HEAD, hidden_dim_bod=HIDDEN_DIM_BOD, \n",
    "                dropout=DROPOUT, output_dim=OUTPUT_DIM, n_layers_head=2, n_layers_bod=2, bidirectional=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "model1 = Siamese_LSTM(EMBEDDING_DIM, hidden_dim_head=HIDDEN_DIM_HEAD, hidden_dim_bod=HIDDEN_DIM_BOD, \n",
    "                dropout=DROPOUT, output_dim=OUTPUT_DIM, n_layers_head=2, n_layers_bod=3, bidirectional=True)\n",
    "optimizer1 = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "# Plateaus at 69.7 validation, some decrease in loss but not enough\n",
    "model2 = Siamese_LSTM(EMBEDDING_DIM, hidden_dim_head=250, hidden_dim_bod=250, \n",
    "                dropout=DROPOUT, output_dim=OUTPUT_DIM, n_layers_head=2, n_layers_bod=2, bidirectional=True)\n",
    "optimizer2 = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "model3 = Siamese_LSTM(EMBEDDING_DIM, hidden_dim_head=100, hidden_dim_bod=100, \n",
    "                dropout=DROPOUT, output_dim=OUTPUT_DIM, n_layers_head=2, n_layers_bod=2, bidirectional=True)\n",
    "optimizer3 = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "model4 = Siamese_LSTM(EMBEDDING_DIM, hidden_dim_head=HIDDEN_DIM_HEAD, hidden_dim_bod=HIDDEN_DIM_BOD, \n",
    "                dropout=0.3, output_dim=OUTPUT_DIM, n_layers_head=2, n_layers_bod=2, bidirectional=True)\n",
    "optimizer4 = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = [(model1, optimizer1),(model2,optimizer2),(model3,optimizer3),(model4,optimizer4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, total_batch, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = get_batch(train_feats, [str(x[-1]) for x in stances_tr.values],i,batch_size)\n",
    "        inputs = Variable(torch.FloatTensor(batch_x))\n",
    "        labels = Variable(torch.LongTensor(batch_y))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(inputs)\n",
    "        loss = criterion(predictions, labels)\n",
    "        _, predicted = torch.max(predictions.data, 1)\n",
    "        acc = binary_accuracy(predicted, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / total_batch, epoch_acc / total_batch\n",
    "\n",
    "def evaluate(model, total_batch, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(total_batch):\n",
    "            batch_x,batch_y = get_batch(val_feats, [str(x[-1]) for x in stances_val.values],i,batch_size)\n",
    "            inputs = Variable(torch.FloatTensor(batch_x))\n",
    "            labels = Variable(torch.LongTensor(batch_y))\n",
    "            predictions = model(inputs)\n",
    "            loss = criterion(predictions, labels)\n",
    "            _, predicted = torch.max(predictions.data, 1)\n",
    "            acc = binary_accuracy(predicted, labels)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / total_batch, epoch_acc / total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0\n",
      "\n",
      "| Epoch: 01 | Train Loss: 0.776 | Train Acc: 65.51% | Val. Loss: 0.701 | Val. Acc: 69.73% |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-a437cee82c30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatches_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatches_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-59e16ac29f71>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, total_batch, optimizer, criterion)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\cds\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-48853085f1b7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m#hidden = [1, batch size, hid dim]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0moutput1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0moutput2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhidden2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \"\"\"print(f'Hidden1 shape: {hidden1.squeeze(0).shape}')\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\cds\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\cds\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 179\u001b[1;33m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batches_train= int(len(train_feats)/batch_size)\n",
    "batches_val = int(len(val_feats)/batch_size)\n",
    "    \n",
    "\n",
    "for i in range(len(queue)):\n",
    "    model = queue[i][0]\n",
    "    optimizer = queue[i][1]\n",
    "    print(f'model {i}\\n')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        train_loss, train_acc = train(model, batches_train, optimizer, criterion)\n",
    "        valid_loss, valid_acc = evaluate(model, batches_val, criterion)\n",
    "\n",
    "        print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 27 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "predicted = eval_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2085, 2: 672})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_l = [i.item() for i in list(predicted)]\n",
    "Counter(predicted_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[ 393    0  360]\n",
      " [  68    0  120]\n",
      " [ 211    0 1605]]\n",
      "\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    393    |     0     |    360    |     0     |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    68     |     0     |    120    |     0     |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    211    |     0     |   1605    |     0     |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |     0     |     0     |     0     |     0     |\n",
      "-------------------------------------------------------------\n",
      "Score: 2187.75 out of 2757.0\t(79.3525571273123%)\n",
      "Normalized confusion matrix\n",
      "[[0.52191235 0.         0.47808765]\n",
      " [0.36170213 0.         0.63829787]\n",
      " [0.11618943 0.         0.88381057]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix = score_model(predicted_l)\n",
    "utils.plot_confusion_matrix(matrix, classes=[\"Agree\",\"Disagree\", \"Discuss\"],\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 155, 17], [0, 1723, 71], [0, 553, 165]]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label = [(2 if x[-1] == \"agree\" else (1 if x[-1] == \"discuss\" else 0)) for x in stances_val.values]\n",
    "[list(x) for x in list(confusion_matrix(true_label,predicted_l))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './saved_models/CNN_refuting_ft.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train finalized model below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final = CNN(EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fts = train_feats+val_feats\n",
    "tr_labels = [str(x[-1]) for x in stances_tr.values]+[str(x[-1]) for x in stances_val.values]\n",
    "\n",
    "def train_final(model, total_batch, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model_final.train()\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = get_batch(fts, tr_labels,i,batch_size)\n",
    "        inputs = Variable(torch.FloatTensor(batch_x))\n",
    "        labels = Variable(torch.LongTensor(batch_y))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model_final(inputs)\n",
    "        loss = criterion(predictions, labels)\n",
    "        _, predicted = torch.max(predictions.data, 1)\n",
    "        acc = binary_accuracy(predicted, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / total_batch, epoch_acc / total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 0.727 | Train Acc: 69.69% |\n",
      "| Epoch: 02 | Train Loss: 0.555 | Train Acc: 77.40% |\n",
      "| Epoch: 03 | Train Loss: 0.465 | Train Acc: 80.90% |\n"
     ]
    }
   ],
   "source": [
    "batches_train= int(len(fts)/batch_size)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_final(model_f, batches_train, optimizer, criterion)\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model_final.state_dict(), './CNN_model_softmax_final.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
