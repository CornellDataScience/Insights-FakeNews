{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stance Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import preprocessing, feature_engineering, helpers\n",
    "import importlib\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import itertools\n",
    "import utils\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(preprocessing)\n",
    "importlib.reload(feature_engineering)\n",
    "importlib.reload(helpers)\n",
    "importlib.reload(utils)\n",
    "preprocess = preprocessing.Preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().config.get('IPKernelApp', {})['parent_appname'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13427, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'Nasa Confirms Earth Will Experience 6 Days of...</td>\n",
       "      <td>154</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Banksy 'Arrested &amp; Real Identity Revealed' Is ...</td>\n",
       "      <td>1739</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gateway Pundit</td>\n",
       "      <td>2327</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline  Body ID    Stance\n",
       "1   Hundreds of Palestinians flee floods in Gaza a...      158     agree\n",
       "4   Spider burrowed through tourist's stomach and ...     1923  disagree\n",
       "5   'Nasa Confirms Earth Will Experience 6 Days of...      154     agree\n",
       "8   Banksy 'Arrested & Real Identity Revealed' Is ...     1739     agree\n",
       "10                                     Gateway Pundit     2327   discuss"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stances = pd.read_csv(\"fn_data/train_stances.csv\")\n",
    "train_stances = train_stances.loc[lambda x: x.Stance != \"unrelated\"]\n",
    "print(train_stances.shape)\n",
    "train_stances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1683, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody\n",
       "0        0  A small meteorite crashed into a wooded area i...\n",
       "1        4  Last week we hinted at what was to come as Ebo...\n",
       "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...\n",
       "3        6  Posting photos of a gun-toting child online, I...\n",
       "4        7  At least 25 suspected Boko Haram insurgents we..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bodies = pd.read_csv(\"fn_data/train_bodies.csv\")\n",
    "print(train_bodies.shape)\n",
    "train_bodies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10632, 3), (2795, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stances_tr, stances_val = preprocess.train_test_split(train_bodies, train_stances)\n",
    "stances_tr.shape, stances_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'discuss': 1865, 'agree': 754, 'disagree': 176})\n",
      "0.667262969588551\n"
     ]
    }
   ],
   "source": [
    "ct = Counter(stances_val['Stance'])\n",
    "print(ct)\n",
    "print(ct.most_common(1)[0][1]/len(list(stances_val[\"Stance\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dict = preprocess.get_glove_dict(\"glove.6B.50d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([('nasa', 'NN')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('confirms', 'NNS')],\n",
       "  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('earth', 'NN')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('experience', 'NN')],\n",
       "  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('day', 'NN')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('total', 'JJ')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('darkness', 'NN')],\n",
       "  {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.25}),\n",
       " ([('december', 'NN')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('fake', 'NN')], {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.4767}),\n",
       " ([('news', 'NN')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('story', 'NN')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('go', 'VB')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " ([('viral', 'JJ')], {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(nltk.pos_tag([x]),preprocess.get_sentiment(x)) for x in preprocess.get_clean_tokens(list(stances_tr.iloc[2,:])[0], False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7902431610341373"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess.cosine_similarity(glove_dict['reveal'], glove_dict['revealed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 100\n",
      "processed 200\n",
      "processed 300\n",
      "processed 400\n",
      "processed 500\n",
      "processed 600\n",
      "processed 700\n",
      "processed 800\n",
      "processed 900\n",
      "processed 1000\n",
      "processed 1100\n",
      "processed 1200\n",
      "processed 1300\n",
      "processed 1400\n",
      "processed 1500\n",
      "processed 1600\n",
      "done! processed 1683\n"
     ]
    }
   ],
   "source": [
    "body_dict = preprocess.process_bodies_stance(train_bodies, glove_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_feats = [preprocess.process_feats_stance(i, body_dict, glove_dict) for i in stances_tr.values]\n",
    "val_feats = [preprocess.process_feats_stance(i, body_dict, glove_dict) for i in stances_val.values]\n",
    "end = time.time()\n",
    "print(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: get the new get batch function\n",
    "def get_batch(data, targets, i,batch_size):\n",
    "    batches = data[i*batch_size:i*batch_size+batch_size]\n",
    "    results = targets[i*batch_size:i*batch_size+batch_size]\n",
    "    results = [(2 if result == \"agree\" else (1 if result == \"discuss\" else 0)) for result in results]\n",
    "    return np.array(batches),np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "def eval_model(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_x_test,batch_y_test = get_batch(val_feats,[str(x[-1]) for x in stances_val.values],0,len(stances_val))\n",
    "    model.eval()\n",
    "    predicted = None\n",
    "    with torch.no_grad():\n",
    "        inputs = Variable(torch.FloatTensor(batch_x_test))\n",
    "        labels = torch.LongTensor(batch_y_test)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy: %d %%' % (100 * correct / total))\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(predictions):    \n",
    "    #use FNC scorer to generate score report\n",
    "    label_prediction = [(\"agree\" if x == 2 else (\"discuss\" if x == 1 else \"disagree\")) for x in predictions]\n",
    "    label_actual = pd.DataFrame(stances_val)['Stance']\n",
    "    matrix = confusion_matrix(label_actual,label_prediction)\n",
    "    print('confusion matrix: \\n{}\\n'.format(matrix))\n",
    "    score.report_score(label_actual, label_prediction)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "\n",
    "\"\"\"\n",
    "    correct = (preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siamese(nn.Module):\n",
    "    # hidden dim: dimension of one RNN\n",
    "    # 2 * hidden dim: concatenated outputs\n",
    "    def __init__(self,embedding_dim, hidden_dim_head, hidden_dim_bod, dropout, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # RNN dimensions [embedding_dim, hidden_dim]\n",
    "        # To-Do: try varying hidden, output dims for each network\n",
    "        self.rnn1 = nn.RNN(20, hidden_dim_head, dropout=dropout)\n",
    "        self.rnn2 = nn.RNN(72, hidden_dim_bod, dropout=dropout)\n",
    "        # Note: output dim could technically be higher now? cause runnign through a loss function/MLP\n",
    "        #self.fc1 = nn.Linear(hidden_dim, output_dim)\n",
    "        #self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim_head+hidden_dim_bod, output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x originally = [batch size, nubmer of words, embedding dim]\n",
    "        # swap first two dimensions to match rnn specs\n",
    "        #print(f'x shape before: ${x.shape}')\n",
    "        x = x.permute([1,0,2])\n",
    "        \n",
    "        #print(f'x shape: ${x.shape}')\n",
    "        header = x[:, :, :20]\n",
    "        article = x[:, :, 20:]\n",
    "        \n",
    "        #print(f'header shape: ${header.shape}')\n",
    "        #print(f'article shape: ${article.shape}')\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        output1, hidden1 = self.rnn1(header)\n",
    "        output2, hidden2 = self.rnn2(article)\n",
    "        #print(f'Hidden1 shape: {hidden1.squeeze(0).shape}')\n",
    "        #print(f'Hidden2 shape: {hidden2.squeeze(0).shape}')\n",
    "     \n",
    "        hidden = self.dropout(torch.cat((hidden1.squeeze(0), hidden2.squeeze(0)),1))\n",
    "        #print(f'Hidden shape: {hidden.shape}')\n",
    "\n",
    "        #out = self.fc1(hidden1.squeeze(0))\n",
    "        #out = out.append(self.fc2(hidden2.squeeze(0)))\n",
    "        \n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: re-implement with LSTMs for each branch\n",
    "class Siamese_LSTM(nn.Module):\n",
    "    # hidden dim: dimension of one RNN\n",
    "    # 2 * hidden dim: concatenated outputs\n",
    "    def __init__(self,embedding_dim, hidden_dim_head, hidden_dim_bod, \n",
    "                 n_layers_head, n_layers_bod, bidirectional, dropout, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # RNN dimensions [embedding_dim, hidden_dim]\n",
    "        self.rnn1 = nn.LSTM(92, hidden_dim_head, num_layers=n_layers_head, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.rnn2 = nn.LSTM(92, hidden_dim_bod, num_layers=n_layers_bod, bidirectional=bidirectional, dropout=dropout)\n",
    "        # Note: output dim could technically be higher now? cause runnign through a loss function/MLP\n",
    "       \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc1 = nn.Linear((hidden_dim_head+hidden_dim_bod)*2, (hidden_dim_head+hidden_dim_bod)) #doubled for bidirectional\n",
    "        self.fc2 = nn.Linear((hidden_dim_head+hidden_dim_bod), output_dim)\n",
    "        \n",
    "    def set_n_layers(self, head, bod):\n",
    "        self.rnn1.num_layers = head\n",
    "        self.rnn2.num_layers = bod\n",
    "        \n",
    "    def set_n_hidden(self, head, bod):\n",
    "        self.rnn1.hidden_size = head\n",
    "        self.rnn2.hidden_size = bod\n",
    "        \n",
    "    def set_dropout(self, droupout):\n",
    "        self.droupout = droupout\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x originally = [batch size, nubmer of words, embedding dim]\n",
    "        # swap first two dimensions to match rnn specs\n",
    "        #print(f'x shape before: ${x.shape}')\n",
    "        x = x.permute([1,0,2])\n",
    "        \n",
    "        \"\"\"print(f'x shape: ${x.shape}')\"\"\"\n",
    "        header = x[:20, :, :]\n",
    "        article = x[20:60, :, :]\n",
    "        \n",
    "        \"\"\"print(f'header shape: ${header.shape}')\n",
    "        print(f'article shape: ${article.shape}')\"\"\"\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        output1, (hidden1, cell1) = self.rnn1(header)\n",
    "        output2, (hidden2, cell2) = self.rnn2(article)\n",
    "        \n",
    "        \"\"\"print(f'Hidden1 shape: {hidden1.shape}')\n",
    "        print(f'Hidden2 shape: {hidden2.shape}')\"\"\"\n",
    "        \n",
    "        # Concats the last forward and backward hidden layers\n",
    "        # Wouldn't you only technically want to do this if it is in fact bidirectional? \n",
    "        hidden1 = torch.cat((hidden1[-2,:,:], hidden1[-1,:,:]), dim=1)\n",
    "        hidden2 = torch.cat((hidden2[-2,:,:], hidden2[-1,:,:]), dim=1)\n",
    "\n",
    "        \"\"\"print(f'Hidden1 shape front/back: {hidden1.shape}')\n",
    "        print(f'Hidden2 shape front/back: {hidden2.shape}')\"\"\"\n",
    "        \n",
    "        hidden_merge = torch.cat((hidden1.squeeze(0), hidden2.squeeze(0)),1)\n",
    "        # TODO: Check if concatenating along dim 1 might be better if first squeeze each hidden\n",
    "        \"\"\"print(f'Concatenated shape: {hidden_merge.shape}')\"\"\"\n",
    "     \n",
    "        hidden = self.dropout(hidden_merge)\n",
    "        \n",
    "        # Todo: add more layers beforehand, that's way too many to concatenate down to 3\n",
    "        fc1 = self.fc1(hidden)\n",
    "        \"\"\"print(f'FC shape: {fc1.shape}')\"\"\"\n",
    "\n",
    "        fc1 = F.relu(fc1)\n",
    "\n",
    "        fc2 = self.fc2(fc1)\n",
    "        \n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 92\n",
    "HIDDEN_DIM_HEAD = 150\n",
    "HIDDEN_DIM_BOD = 256\n",
    "\n",
    "OUTPUT_DIM = 3\n",
    "num_epochs = 5\n",
    "batch_size = 500\n",
    "display_step = 1\n",
    "\n",
    "N_LAYERS = 2\n",
    "#BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Siamese_LSTM(EMBEDDING_DIM, hidden_dim_head=HIDDEN_DIM_HEAD, hidden_dim_bod=HIDDEN_DIM_BOD, \n",
    "                dropout=DROPOUT, output_dim=OUTPUT_DIM, n_layers_head=2, n_layers_bod=2, bidirectional=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "model1 = Siamese_LSTM(EMBEDDING_DIM, hidden_dim_head=HIDDEN_DIM_HEAD, hidden_dim_bod=HIDDEN_DIM_BOD, \n",
    "                dropout=DROPOUT, output_dim=OUTPUT_DIM, n_layers_head=2, n_layers_bod=3, bidirectional=True)\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "model2 = Siamese_LSTM(EMBEDDING_DIM, hidden_dim_head=250, hidden_dim_bod=250, \n",
    "                dropout=DROPOUT, output_dim=OUTPUT_DIM, n_layers_head=2, n_layers_bod=2, bidirectional=True)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "model3 = Siamese_LSTM(EMBEDDING_DIM, hidden_dim_head=100, hidden_dim_bod=100, \n",
    "                dropout=DROPOUT, output_dim=OUTPUT_DIM, n_layers_head=2, n_layers_bod=2, bidirectional=True)\n",
    "optimizer3 = torch.optim.Adam(model3.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "model4 = Siamese_LSTM(EMBEDDING_DIM, hidden_dim_head=HIDDEN_DIM_HEAD, hidden_dim_bod=HIDDEN_DIM_BOD, \n",
    "                dropout=0.3, output_dim=OUTPUT_DIM, n_layers_head=2, n_layers_bod=2, bidirectional=True)\n",
    "optimizer4 = torch.optim.Adam(model4.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = [(model3,optimizer3),(model4,optimizer4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, total_batch, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = get_batch(train_feats, [str(x[-1]) for x in stances_tr.values],i,batch_size)\n",
    "        inputs = Variable(torch.FloatTensor(batch_x))\n",
    "        labels = Variable(torch.LongTensor(batch_y))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(inputs)\n",
    "        loss = criterion(predictions, labels)\n",
    "        _, predicted = torch.max(predictions.data, 1)\n",
    "        acc = binary_accuracy(predicted, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / total_batch, epoch_acc / total_batch\n",
    "\n",
    "def evaluate(model, total_batch, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(total_batch):\n",
    "            batch_x,batch_y = get_batch(val_feats, [str(x[-1]) for x in stances_val.values],i,batch_size)\n",
    "            inputs = Variable(torch.FloatTensor(batch_x))\n",
    "            labels = Variable(torch.LongTensor(batch_y))\n",
    "            predictions = model(inputs)\n",
    "            loss = criterion(predictions, labels)\n",
    "            _, predicted = torch.max(predictions.data, 1)\n",
    "            acc = binary_accuracy(predicted, labels)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / total_batch, epoch_acc / total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 0.713 | Train Acc: 69.63% | Val. Loss: 0.734 | Val. Acc: 69.12% |\n",
      "| Epoch: 02 | Train Loss: 0.686 | Train Acc: 71.44% | Val. Loss: 0.723 | Val. Acc: 69.48% |\n",
      "| Epoch: 03 | Train Loss: 0.666 | Train Acc: 72.02% | Val. Loss: 0.721 | Val. Acc: 69.32% |\n",
      "| Epoch: 04 | Train Loss: 0.653 | Train Acc: 72.60% | Val. Loss: 0.717 | Val. Acc: 69.04% |\n",
      "| Epoch: 05 | Train Loss: 0.640 | Train Acc: 72.98% | Val. Loss: 0.722 | Val. Acc: 70.00% |\n"
     ]
    }
   ],
   "source": [
    "batches_train= int(len(train_feats)/batch_size)\n",
    "batches_val = int(len(val_feats)/batch_size)\n",
    "    \n",
    "\n",
    "\"\"\"for i in range(len(queue)):\n",
    "    model = queue[i][0]\n",
    "    optimizer = queue[i][1]\n",
    "    print(f'model {i}\\n')\"\"\"\n",
    "model = model4\n",
    "optimizer = optimizer4\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss, train_acc = train(model, batches_train, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, batches_val, criterion)\n",
    "\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "predicted = eval_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2152, 2: 643})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_l = [i.item() for i in list(predicted)]\n",
    "Counter(predicted_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[ 327    0  427]\n",
      " [  74    0  102]\n",
      " [ 242    0 1623]]\n",
      "\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    327    |     0     |    427    |     0     |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    74     |     0     |    102    |     0     |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    242    |     0     |   1623    |     0     |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |     0     |     0     |     0     |     0     |\n",
      "-------------------------------------------------------------\n",
      "Score: 2161.25 out of 2795.0\t(77.32558139534883%)\n",
      "Normalized confusion matrix\n",
      "[[0.433687   0.         0.566313  ]\n",
      " [0.42045455 0.         0.57954545]\n",
      " [0.12975871 0.         0.87024129]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix = score_model(predicted_l)\n",
    "utils.plot_confusion_matrix(matrix, classes=[\"Agree\",\"Disagree\", \"Discuss\"],\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 155, 17], [0, 1723, 71], [0, 553, 165]]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label = [(2 if x[-1] == \"agree\" else (1 if x[-1] == \"discuss\" else 0)) for x in stances_val.values]\n",
    "[list(x) for x in list(confusion_matrix(true_label,predicted_l))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './saved_models/CNN_refuting_ft.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train finalized model below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final = CNN(EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fts = train_feats+val_feats\n",
    "tr_labels = [str(x[-1]) for x in stances_tr.values]+[str(x[-1]) for x in stances_val.values]\n",
    "\n",
    "def train_final(model, total_batch, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model_final.train()\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = get_batch(fts, tr_labels,i,batch_size)\n",
    "        inputs = Variable(torch.FloatTensor(batch_x))\n",
    "        labels = Variable(torch.LongTensor(batch_y))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model_final(inputs)\n",
    "        loss = criterion(predictions, labels)\n",
    "        _, predicted = torch.max(predictions.data, 1)\n",
    "        acc = binary_accuracy(predicted, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / total_batch, epoch_acc / total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 0.727 | Train Acc: 69.69% |\n",
      "| Epoch: 02 | Train Loss: 0.555 | Train Acc: 77.40% |\n",
      "| Epoch: 03 | Train Loss: 0.465 | Train Acc: 80.90% |\n"
     ]
    }
   ],
   "source": [
    "batches_train= int(len(fts)/batch_size)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_final(model_f, batches_train, optimizer, criterion)\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model_final.state_dict(), './CNN_model_softmax_final.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
