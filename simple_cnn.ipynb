{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from torchtext.data import Field\n",
    "import csv\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import Iterator, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenize = lambda x: x.split()\n",
    "TEXT = Field(sequential=True, tokenize=tokenize, lower=True, fix_length = 100)\n",
    "LABEL = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>137</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>1034</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance\n",
       "0  Police find mass graves with at least '15 bodi...      712  unrelated\n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree\n",
       "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated\n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated\n",
       "4  Spider burrowed through tourist's stomach and ...     1923   disagree"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stances = pd.read_csv(\"fn_data/train_stances.csv\")\n",
    "print(train_stances.shape)\n",
    "train_stances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1683, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody\n",
       "0        0  A small meteorite crashed into a wooded area i...\n",
       "1        4  Last week we hinted at what was to come as Ebo...\n",
       "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...\n",
       "3        6  Posting photos of a gun-toting child online, I...\n",
       "4        7  At least 25 suspected Boko Haram insurgents we..."
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bodies = pd.read_csv(\"fn_data/train_bodies.csv\")\n",
    "print(train_bodies.shape)\n",
    "train_bodies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_body(n, df):\n",
    "    return df.loc[lambda x: x[\"Body ID\"] == n, \"articleBody\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train_data_consolidated.csv', 'w') as f, open('val_data_consolidated.csv', 'w') as g:\n",
    "    writer_train = csv.writer(f)\n",
    "    writer_val = csv.writer(g)\n",
    "    writer_train.writerow(['Body ID', 'Headline', 'Body', 'unrelated', 'related'])\n",
    "    writer_val.writerow(['Body ID', 'Headline', 'Body', 'unrelated', 'related'])\n",
    "    i = 1\n",
    "    for index, row in train_stances.iterrows():\n",
    "        id = row[\"Body ID\"]\n",
    "        body = get_body(id, train_bodies)\n",
    "        headline = row[\"Headline\"]\n",
    "        stance = row[\"Stance\"]\n",
    "        if i % 4 == 0:\n",
    "            writer_val.writerow([id, headline, body, 1 if stance == 'unrelated' else 0, 0 if stance == 'unrelated' else 1])\n",
    "        else:\n",
    "            writer_train.writerow([id, headline, body, 1 if stance == 'unrelated' else 0, 0 if stance == 'unrelated' else 1])\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37479, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body</th>\n",
       "      <th>unrelated</th>\n",
       "      <th>related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>712</td>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>Danny Boyle is directing the untitled film\\n\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158</td>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>Hundreds of Palestinians were evacuated from t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>30-year-old Moscow resident was hospitalized w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1923</td>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>Fear not arachnophobes, the story of Bunbury's...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154</td>\n",
       "      <td>'Nasa Confirms Earth Will Experience 6 Days of...</td>\n",
       "      <td>Thousands of people have been duped by a fake ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>962</td>\n",
       "      <td>Accused Boston Marathon Bomber Severely Injure...</td>\n",
       "      <td>A British fighter who travelled to Iraq to sto...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1739</td>\n",
       "      <td>Banksy 'Arrested &amp; Real Identity Revealed' Is ...</td>\n",
       "      <td>If you’ve seen a story floating around on your...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>882</td>\n",
       "      <td>British Aid Worker Confirmed Murdered By ISIS</td>\n",
       "      <td>The British Islamic State militant who has fea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2327</td>\n",
       "      <td>Gateway Pundit</td>\n",
       "      <td>A British rapper whose father is awaiting tria...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1003</td>\n",
       "      <td>Kidnapped Nigerian schoolgirls: Government cla...</td>\n",
       "      <td>No one has died more times than Fidel Castro.\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2132</td>\n",
       "      <td>No, that high school kid didn't make $72 milli...</td>\n",
       "      <td>The video was one of those viral sensations th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>47</td>\n",
       "      <td>Soon Marijuana May Lead to Ticket, Not Arrest,...</td>\n",
       "      <td>After campaigning on a promise to reform stop-...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2463</td>\n",
       "      <td>Boko Haram Denies Nigeria Cease-Fire Claim</td>\n",
       "      <td>ABUJA, Nigeria — The leader of Nigeria's Islam...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>295</td>\n",
       "      <td>No, Robert Plant Didn’t Rip Up an $800 Million...</td>\n",
       "      <td>Led Zeppelin fans will be disappointed to lear...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>570</td>\n",
       "      <td>N. Korea’s Kim has leg injury but in control</td>\n",
       "      <td>You want a gold Apple Watch, you say? Then it'...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1500</td>\n",
       "      <td>Tropical spider burrows under man's skin throu...</td>\n",
       "      <td>Tonight — finally! — ESPN is going to have an ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1681</td>\n",
       "      <td>Boko Haram ceasefire ignored as violence flare...</td>\n",
       "      <td>(CNN) -- Boko Haram laughed off Nigeria's anno...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1545</td>\n",
       "      <td>NBC's Tom Brokaw reportedly wants Brian Willia...</td>\n",
       "      <td>Macaulay Culkin has once again died — at least...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1014</td>\n",
       "      <td>NET Extra: Back-from-the-dead Catholic priest ...</td>\n",
       "      <td>A 71 years old cleric Father John Micheal O’ne...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>633</td>\n",
       "      <td>Rumor debunked: RoboCop-style robots are not p...</td>\n",
       "      <td>Knightscope co-founder Stacy Stephens said rum...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>56</td>\n",
       "      <td>Luke Somers Dies In Rescue Attempt, Sister Say...</td>\n",
       "      <td>A man accused of attempting to rape a girl in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2327</td>\n",
       "      <td>Microsoft Tried Out Robot Security Guards on I...</td>\n",
       "      <td>A British rapper whose father is awaiting tria...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1157</td>\n",
       "      <td>Report: Christian Bale Just Bailed on the Stev...</td>\n",
       "      <td>Christian Bale is in talks to play Steve Jobs ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>132</td>\n",
       "      <td>Islamic Militants Post Video Claiming to Show ...</td>\n",
       "      <td>Critics slammed Vogue’s recent Kimye cover as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2344</td>\n",
       "      <td>TEXAS TURKEY FARM CONTAMINATED WITH EBOLA, OVE...</td>\n",
       "      <td>North Korea may have a woman at the helm–Kim J...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>625</td>\n",
       "      <td>SEE IT: ISIS militants caught trying to cross ...</td>\n",
       "      <td>Scottish people have some of the strongest sto...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2176</td>\n",
       "      <td>Thanks Uncle Sam, we have your weapons airdrop...</td>\n",
       "      <td>Longtime \"NBC Nightly News\" anchor Tom Brokaw ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2161</td>\n",
       "      <td>Fisherman lands 19 STONE catfish which could b...</td>\n",
       "      <td>Dino Ferrari hooked the whopper wels catfish, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1040</td>\n",
       "      <td>Would-be rapist has penis severed by angry mob</td>\n",
       "      <td>(Mashable) Reports that Islamic State militant...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1251</td>\n",
       "      <td>Who Is Michael Zehaf-Bibeau? Ottawa Shooter Su...</td>\n",
       "      <td>The lethal animals are being launched at Iraqi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2240</td>\n",
       "      <td>Former PGA Tour player: Tiger Woods suspended ...</td>\n",
       "      <td>A catholic priest from Masschussetts, who was ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>702</td>\n",
       "      <td>Zack Snyder Responds to Fake Stolen Batmobile ...</td>\n",
       "      <td>Mexico's attorney general says DNA tests have ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1720</td>\n",
       "      <td>Priest who died for 48 minutes says he met God...</td>\n",
       "      <td>A South American nun suddenly started experien...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1358</td>\n",
       "      <td>Mum faces real-life Sophie's Choice – as she t...</td>\n",
       "      <td>It's not every night that a pizza delivery dri...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1832</td>\n",
       "      <td>Fidel Castro Dead? Yes, He Is… But The Cuban L...</td>\n",
       "      <td>14.3K 3077reddit70  32\\n\\n(RNS) When Pope Fran...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1374</td>\n",
       "      <td>Magic mushrooms found in BUCKINGHAM PALACE by ...</td>\n",
       "      <td>LONDON — The man in the black balaclava who ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2404</td>\n",
       "      <td>Video showing American journalist beheaded bel...</td>\n",
       "      <td>In a new video, ISIS shows American-made weapo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1744</td>\n",
       "      <td>Canadian Soldier Shot At Ottawa War Memorial: ...</td>\n",
       "      <td>A disturbing video posted online appears to sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1406</td>\n",
       "      <td>Kim Jong-un 'set to open a new restaurant in S...</td>\n",
       "      <td>Police will stop arresting people for low-leve...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1818</td>\n",
       "      <td>New Audio Reveals Pause in Gunfire When Michae...</td>\n",
       "      <td>Video messaging app Glide on Thursday said it ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1958</td>\n",
       "      <td>11 Tripoli Planes Still Missing, Sparks 9/11 C...</td>\n",
       "      <td>Eleven planes missing from Tripoli Airport aft...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2115</td>\n",
       "      <td>India Rape Crisis Sees Mob Castrate Alleged Se...</td>\n",
       "      <td>An alleged attempted rapist in India received ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1849</td>\n",
       "      <td>Michael Phelps’ alleged girlfriend says she wa...</td>\n",
       "      <td>After being officially dead for 48 minutes and...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1966</td>\n",
       "      <td>Seth Rogen reported to play Woz in the upcomin...</td>\n",
       "      <td>BREAKING: Islamic State, in video, beheads Ame...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>992</td>\n",
       "      <td>Nigeria announces truce with Boko Haram; fate ...</td>\n",
       "      <td>(Reuters) - No suspected cases of Ebola have b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2526</td>\n",
       "      <td>ISLAMIC STATE BEHEADS MISSING AMERICAN JOURNAL...</td>\n",
       "      <td>Update: Since the publication of this article,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>731</td>\n",
       "      <td>Scientists Doubt That Meteor Caused Crater In ...</td>\n",
       "      <td>Thousands of social media users are distributi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2045</td>\n",
       "      <td>Nigeria Says Boko Haram Cease-Fire May Lead to...</td>\n",
       "      <td>Amazon has warehouses — hundreds of them, mile...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1212</td>\n",
       "      <td>Calm Yourselves, Durex Has NOT Come Out With A...</td>\n",
       "      <td>Tiger Woods divorced Swedish model Elin Nordeg...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>777</td>\n",
       "      <td>Islamic State flying three jets in Syria: monitor</td>\n",
       "      <td>Mexican hitmen allegedly killed more than a do...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>213</td>\n",
       "      <td>Kim Jong-un relying on ‘cobra wine’ after prob...</td>\n",
       "      <td>Last year, a Vine from President Obama’s trip ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>922</td>\n",
       "      <td>Nigeria: hopes for return of kidnapped schoolg...</td>\n",
       "      <td>More than 200 girls who were kidnapped in Nige...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1758</td>\n",
       "      <td>Former U.S. soldier says IS used chemical weap...</td>\n",
       "      <td>FRISCO, Texas - A patient exhibiting symptoms ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1681</td>\n",
       "      <td>Eyewitness Says Viral Video of Homeless Man Wa...</td>\n",
       "      <td>(CNN) -- Boko Haram laughed off Nigeria's anno...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>900</td>\n",
       "      <td>New Audio Shows Michael Brown Was Shot at 11 T...</td>\n",
       "      <td>A hoax story alleging the British graffiti art...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>40</td>\n",
       "      <td>Meteorite strike in Nicaragua puzzles experts</td>\n",
       "      <td>Young North Korean dictator Kim Jong Un’s heal...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>949</td>\n",
       "      <td>Met police denies reports of Banksy arrest</td>\n",
       "      <td>Let’s clear this one up quickly.\\n\\nA US websi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>488</td>\n",
       "      <td>Video: Marine saved by helmet after Taliban sn...</td>\n",
       "      <td>The marine was shot during a mission in the da...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2495</td>\n",
       "      <td>Militant Group Says It Killed American Journal...</td>\n",
       "      <td>Islamic State militants appear to have killed ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1628</td>\n",
       "      <td>ISIS Claims It Kidnapped Gill Rosenberg, The F...</td>\n",
       "      <td>American fears may be realized. One of the fiv...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Body ID                                           Headline  \\\n",
       "0       712  Police find mass graves with at least '15 bodi...   \n",
       "1       158  Hundreds of Palestinians flee floods in Gaza a...   \n",
       "2       137  Christian Bale passes on role of Steve Jobs, a...   \n",
       "3      1923  Spider burrowed through tourist's stomach and ...   \n",
       "4       154  'Nasa Confirms Earth Will Experience 6 Days of...   \n",
       "5       962  Accused Boston Marathon Bomber Severely Injure...   \n",
       "6      1739  Banksy 'Arrested & Real Identity Revealed' Is ...   \n",
       "7       882      British Aid Worker Confirmed Murdered By ISIS   \n",
       "8      2327                                     Gateway Pundit   \n",
       "9      1003  Kidnapped Nigerian schoolgirls: Government cla...   \n",
       "10     2132  No, that high school kid didn't make $72 milli...   \n",
       "11       47  Soon Marijuana May Lead to Ticket, Not Arrest,...   \n",
       "12     2463         Boko Haram Denies Nigeria Cease-Fire Claim   \n",
       "13      295  No, Robert Plant Didn’t Rip Up an $800 Million...   \n",
       "14      570       N. Korea’s Kim has leg injury but in control   \n",
       "15     1500  Tropical spider burrows under man's skin throu...   \n",
       "16     1681  Boko Haram ceasefire ignored as violence flare...   \n",
       "17     1545  NBC's Tom Brokaw reportedly wants Brian Willia...   \n",
       "18     1014  NET Extra: Back-from-the-dead Catholic priest ...   \n",
       "19      633  Rumor debunked: RoboCop-style robots are not p...   \n",
       "20       56  Luke Somers Dies In Rescue Attempt, Sister Say...   \n",
       "21     2327  Microsoft Tried Out Robot Security Guards on I...   \n",
       "22     1157  Report: Christian Bale Just Bailed on the Stev...   \n",
       "23      132  Islamic Militants Post Video Claiming to Show ...   \n",
       "24     2344  TEXAS TURKEY FARM CONTAMINATED WITH EBOLA, OVE...   \n",
       "25      625  SEE IT: ISIS militants caught trying to cross ...   \n",
       "26     2176  Thanks Uncle Sam, we have your weapons airdrop...   \n",
       "27     2161  Fisherman lands 19 STONE catfish which could b...   \n",
       "28     1040     Would-be rapist has penis severed by angry mob   \n",
       "29     1251  Who Is Michael Zehaf-Bibeau? Ottawa Shooter Su...   \n",
       "..      ...                                                ...   \n",
       "70     2240  Former PGA Tour player: Tiger Woods suspended ...   \n",
       "71      702  Zack Snyder Responds to Fake Stolen Batmobile ...   \n",
       "72     1720  Priest who died for 48 minutes says he met God...   \n",
       "73     1358  Mum faces real-life Sophie's Choice – as she t...   \n",
       "74     1832  Fidel Castro Dead? Yes, He Is… But The Cuban L...   \n",
       "75     1374  Magic mushrooms found in BUCKINGHAM PALACE by ...   \n",
       "76     2404  Video showing American journalist beheaded bel...   \n",
       "77     1744  Canadian Soldier Shot At Ottawa War Memorial: ...   \n",
       "78     1406  Kim Jong-un 'set to open a new restaurant in S...   \n",
       "79     1818  New Audio Reveals Pause in Gunfire When Michae...   \n",
       "80     1958  11 Tripoli Planes Still Missing, Sparks 9/11 C...   \n",
       "81     2115  India Rape Crisis Sees Mob Castrate Alleged Se...   \n",
       "82     1849  Michael Phelps’ alleged girlfriend says she wa...   \n",
       "83     1966  Seth Rogen reported to play Woz in the upcomin...   \n",
       "84      992  Nigeria announces truce with Boko Haram; fate ...   \n",
       "85     2526  ISLAMIC STATE BEHEADS MISSING AMERICAN JOURNAL...   \n",
       "86      731  Scientists Doubt That Meteor Caused Crater In ...   \n",
       "87     2045  Nigeria Says Boko Haram Cease-Fire May Lead to...   \n",
       "88     1212  Calm Yourselves, Durex Has NOT Come Out With A...   \n",
       "89      777  Islamic State flying three jets in Syria: monitor   \n",
       "90      213  Kim Jong-un relying on ‘cobra wine’ after prob...   \n",
       "91      922  Nigeria: hopes for return of kidnapped schoolg...   \n",
       "92     1758  Former U.S. soldier says IS used chemical weap...   \n",
       "93     1681  Eyewitness Says Viral Video of Homeless Man Wa...   \n",
       "94      900  New Audio Shows Michael Brown Was Shot at 11 T...   \n",
       "95       40      Meteorite strike in Nicaragua puzzles experts   \n",
       "96      949         Met police denies reports of Banksy arrest   \n",
       "97      488  Video: Marine saved by helmet after Taliban sn...   \n",
       "98     2495  Militant Group Says It Killed American Journal...   \n",
       "99     1628  ISIS Claims It Kidnapped Gill Rosenberg, The F...   \n",
       "\n",
       "                                                 Body  unrelated  related  \n",
       "0   Danny Boyle is directing the untitled film\\n\\n...          1        0  \n",
       "1   Hundreds of Palestinians were evacuated from t...          0        1  \n",
       "2   30-year-old Moscow resident was hospitalized w...          1        0  \n",
       "3   Fear not arachnophobes, the story of Bunbury's...          0        1  \n",
       "4   Thousands of people have been duped by a fake ...          0        1  \n",
       "5   A British fighter who travelled to Iraq to sto...          1        0  \n",
       "6   If you’ve seen a story floating around on your...          0        1  \n",
       "7   The British Islamic State militant who has fea...          1        0  \n",
       "8   A British rapper whose father is awaiting tria...          0        1  \n",
       "9   No one has died more times than Fidel Castro.\\...          1        0  \n",
       "10  The video was one of those viral sensations th...          1        0  \n",
       "11  After campaigning on a promise to reform stop-...          0        1  \n",
       "12  ABUJA, Nigeria — The leader of Nigeria's Islam...          0        1  \n",
       "13  Led Zeppelin fans will be disappointed to lear...          0        1  \n",
       "14  You want a gold Apple Watch, you say? Then it'...          1        0  \n",
       "15  Tonight — finally! — ESPN is going to have an ...          1        0  \n",
       "16  (CNN) -- Boko Haram laughed off Nigeria's anno...          0        1  \n",
       "17  Macaulay Culkin has once again died — at least...          1        0  \n",
       "18  A 71 years old cleric Father John Micheal O’ne...          0        1  \n",
       "19  Knightscope co-founder Stacy Stephens said rum...          0        1  \n",
       "20  A man accused of attempting to rape a girl in ...          1        0  \n",
       "21  A British rapper whose father is awaiting tria...          1        0  \n",
       "22  Christian Bale is in talks to play Steve Jobs ...          0        1  \n",
       "23  Critics slammed Vogue’s recent Kimye cover as ...          1        0  \n",
       "24  North Korea may have a woman at the helm–Kim J...          1        0  \n",
       "25  Scottish people have some of the strongest sto...          1        0  \n",
       "26  Longtime \"NBC Nightly News\" anchor Tom Brokaw ...          1        0  \n",
       "27  Dino Ferrari hooked the whopper wels catfish, ...          0        1  \n",
       "28  (Mashable) Reports that Islamic State militant...          1        0  \n",
       "29  The lethal animals are being launched at Iraqi...          1        0  \n",
       "..                                                ...        ...      ...  \n",
       "70  A catholic priest from Masschussetts, who was ...          1        0  \n",
       "71  Mexico's attorney general says DNA tests have ...          1        0  \n",
       "72  A South American nun suddenly started experien...          1        0  \n",
       "73  It's not every night that a pizza delivery dri...          1        0  \n",
       "74  14.3K 3077reddit70  32\\n\\n(RNS) When Pope Fran...          1        0  \n",
       "75  LONDON — The man in the black balaclava who ha...          1        0  \n",
       "76  In a new video, ISIS shows American-made weapo...          1        0  \n",
       "77  A disturbing video posted online appears to sh...          1        0  \n",
       "78  Police will stop arresting people for low-leve...          1        0  \n",
       "79  Video messaging app Glide on Thursday said it ...          0        1  \n",
       "80  Eleven planes missing from Tripoli Airport aft...          0        1  \n",
       "81  An alleged attempted rapist in India received ...          0        1  \n",
       "82  After being officially dead for 48 minutes and...          1        0  \n",
       "83  BREAKING: Islamic State, in video, beheads Ame...          1        0  \n",
       "84  (Reuters) - No suspected cases of Ebola have b...          1        0  \n",
       "85  Update: Since the publication of this article,...          1        0  \n",
       "86  Thousands of social media users are distributi...          1        0  \n",
       "87  Amazon has warehouses — hundreds of them, mile...          1        0  \n",
       "88  Tiger Woods divorced Swedish model Elin Nordeg...          1        0  \n",
       "89  Mexican hitmen allegedly killed more than a do...          1        0  \n",
       "90  Last year, a Vine from President Obama’s trip ...          1        0  \n",
       "91  More than 200 girls who were kidnapped in Nige...          0        1  \n",
       "92  FRISCO, Texas - A patient exhibiting symptoms ...          1        0  \n",
       "93  (CNN) -- Boko Haram laughed off Nigeria's anno...          1        0  \n",
       "94  A hoax story alleging the British graffiti art...          1        0  \n",
       "95  Young North Korean dictator Kim Jong Un’s heal...          1        0  \n",
       "96  Let’s clear this one up quickly.\\n\\nA US websi...          0        1  \n",
       "97  The marine was shot during a mission in the da...          0        1  \n",
       "98  Islamic State militants appear to have killed ...          0        1  \n",
       "99  American fears may be realized. One of the fiv...          1        0  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_data_consolidated.csv\")\n",
    "print(train.shape)\n",
    "train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12493, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body</th>\n",
       "      <th>unrelated</th>\n",
       "      <th>related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1034</td>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>(Reuters) - A Canadian soldier was shot at the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2033</td>\n",
       "      <td>Identity of ISIS terrorist known as 'Jihadi Jo...</td>\n",
       "      <td>Adding to Apple's iOS 8 launch troubles, a rep...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1468</td>\n",
       "      <td>Woman detained in Lebanon is not al-Baghdadi's...</td>\n",
       "      <td>An Iraqi official denied that a woman detained...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>Vandals add rude paint job to $2.5m Bugatti (b...</td>\n",
       "      <td>\"Eh-oh!\" A 19-year-old student is claiming tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>608</td>\n",
       "      <td>ISIL Beheads American Photojournalist in Iraq</td>\n",
       "      <td>James Foley, an American journalist who went m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1196</td>\n",
       "      <td>Would you take a bite out of the world's oldes...</td>\n",
       "      <td>Claim: An illustration created in response to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1658</td>\n",
       "      <td>Christian Bale Exits Steve Jobs Movie (Exclusive)</td>\n",
       "      <td>The Islamic State released a video of its jiha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1896</td>\n",
       "      <td>Insurgents killed in Nigeria despite alleged t...</td>\n",
       "      <td>Boko Haram has reportedly agreed to a cease-fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>394</td>\n",
       "      <td>Report: ISIS Leader Abu Bakr Al-Baghdadi Assas...</td>\n",
       "      <td>An unverified photo claims to show the body of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1337</td>\n",
       "      <td>Taylor Lianne Chandler: Michael Phelps' Cougar...</td>\n",
       "      <td>High quality global journalism requires invest...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1299</td>\n",
       "      <td>That Story About a Catholic Priest Dying, Seei...</td>\n",
       "      <td>Welsh actor Christian Bale has withdrawn from ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2248</td>\n",
       "      <td>Planetary Alignment On Jan 4, 2015 Will Decrea...</td>\n",
       "      <td>SEVEN girls, aged 13 to 15, have fallen pregna...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2296</td>\n",
       "      <td>BREAKING NEWS: ISIS beheads missing American j...</td>\n",
       "      <td>North Korean despot Kim Jong-un has been guzzl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>759</td>\n",
       "      <td>Macaulay Culkin Hasn’t Died Despite What Every...</td>\n",
       "      <td>Claim: Actor Macaulay Culkin has died.\\n\\nFALS...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>941</td>\n",
       "      <td>Eggnog-chugging contest leads to hospital stay</td>\n",
       "      <td>It's hardly a secret that Amazon wants to be y...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>367</td>\n",
       "      <td>Anna Wintour: Is Rat Infestation At NYC ‘Vogue...</td>\n",
       "      <td>Social media is awash with news of Islamic Sta...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>703</td>\n",
       "      <td>Islamic State leader's family detained by Leba...</td>\n",
       "      <td>Iraq’s Interior Ministry said on Wednesday tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>724</td>\n",
       "      <td>Spider Burrows Into Australian Man's Appendix ...</td>\n",
       "      <td>Forget sweater weather and crisp autumn leaves...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1040</td>\n",
       "      <td>BREAKING NEWS: ISIS beheads missing American j...</td>\n",
       "      <td>(Mashable) Reports that Islamic State militant...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>487</td>\n",
       "      <td>Paul Rudd Is Not the Viral Video Hero Who Tack...</td>\n",
       "      <td>With Apple's media event just a week away and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1435</td>\n",
       "      <td>New Audio Shows Michael Brown Was Shot at 11 T...</td>\n",
       "      <td>Apple may be planning to hold a special event ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1315</td>\n",
       "      <td>Mystery woman behind the 'richest hands on the...</td>\n",
       "      <td>The identity of the couple behind the mega-suc...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1125</td>\n",
       "      <td>Wife and son of Isil leader Abu Bakr al-Baghda...</td>\n",
       "      <td>DC Toy Collector is the “highest paid performe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1165</td>\n",
       "      <td>Ottawa investigates reports that Isis has capt...</td>\n",
       "      <td>As the anniversary of Sept. 11 approaches, the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>346</td>\n",
       "      <td>CNN Broadcasts Purported Audio Containing Guns...</td>\n",
       "      <td>OTTAWA, Nov 30 (Reuters) - Canada is trying to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1832</td>\n",
       "      <td>Audio recording allegedly captures moment Mich...</td>\n",
       "      <td>14.3K 3077reddit70  32\\n\\n(RNS) When Pope Fran...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>775</td>\n",
       "      <td>NYPD to issue tickets instead of arrest for we...</td>\n",
       "      <td>Media outlets have identified \"Jihadi John\" - ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2174</td>\n",
       "      <td>How did a Texas plumber's truck end up with Sy...</td>\n",
       "      <td>Vladimir Putin spoke at the dedication of a ne...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2097</td>\n",
       "      <td>Christian Bale In Talks To Play Steve Jobs In ...</td>\n",
       "      <td>SEVEN girls, aged 13 to 15, have fallen pregna...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2084</td>\n",
       "      <td>J.J. Abrams Asks Disney To Move Up 'Star Wars:...</td>\n",
       "      <td>The Force may be with us a little sooner than ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2132</td>\n",
       "      <td>North Korean dictator Kim Jong-Un to open rest...</td>\n",
       "      <td>The video was one of those viral sensations th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>36</td>\n",
       "      <td>Hunt for 'cruel' owner who abandoned dog at tr...</td>\n",
       "      <td>The London Metropolitan Police has denied repo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>821</td>\n",
       "      <td>Rare Case: Seven Bosnian Girls, Aged 13 And 14...</td>\n",
       "      <td>The rat infestation in Vogue's new 1 World Tra...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1125</td>\n",
       "      <td>Boko Haram 'ceasefire' doubts after attacks re...</td>\n",
       "      <td>DC Toy Collector is the “highest paid performe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2463</td>\n",
       "      <td>Hope Fades for Girls' Release After Boko Haram...</td>\n",
       "      <td>ABUJA, Nigeria — The leader of Nigeria's Islam...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1048</td>\n",
       "      <td>Court Orders Probe Into Complaints Of 'Forced ...</td>\n",
       "      <td>Amazon is reportedly planning to launch an ad-...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>321</td>\n",
       "      <td>Report: Possible audio tape of Michael Brown s...</td>\n",
       "      <td>A man with a rifle shot a soldier standing gua...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1509</td>\n",
       "      <td>Armed U.S. drones spotted flying over Syria in...</td>\n",
       "      <td>Activists in Al Raqqa have posted images onlin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1547</td>\n",
       "      <td>Vice CEO Throws Down $300K on Lavish Vegas Dinner</td>\n",
       "      <td>A picture of a letter to parents from a box of...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2342</td>\n",
       "      <td>Once Again, The Banksy 'Arrest' Is A Giant Hoa...</td>\n",
       "      <td>More graves have been discovered at the site w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2064</td>\n",
       "      <td>Vogue’s Rat Infestation: Disturbing New Details</td>\n",
       "      <td>The rodents have pestered the staffs of Vanity...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>472</td>\n",
       "      <td>Islamic Militants Post Video Claiming to Show ...</td>\n",
       "      <td>American and British intelligence officials ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1568</td>\n",
       "      <td>Sergeant-at-Arms stopped shooter on Parliament...</td>\n",
       "      <td>It is one of the most annoying aspects of mode...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1438</td>\n",
       "      <td>ISIS cracks down on five confirmed Ebola cases...</td>\n",
       "      <td>A rogue bird let loose on Vladimir Putin over ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1547</td>\n",
       "      <td>Lego letter to parents in 1974 on gender equal...</td>\n",
       "      <td>A picture of a letter to parents from a box of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2290</td>\n",
       "      <td>KIM DINE WITH ME: Porky president Kim Jong-un ...</td>\n",
       "      <td>Central Bedfordshire Council has refuted newsp...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1720</td>\n",
       "      <td>Audio recording allegedly captures moment Mich...</td>\n",
       "      <td>A South American nun suddenly started experien...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1574</td>\n",
       "      <td>WHO investigates media reports ISIS fighters c...</td>\n",
       "      <td>Poverty-stricken parents took to the streets t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1982</td>\n",
       "      <td>Islamic State Militants Claim to Have Beheaded...</td>\n",
       "      <td>MOGADISHU, Somalia — Al-Shabaab’s top leader w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>296</td>\n",
       "      <td>New policy could reduce marijuana possession a...</td>\n",
       "      <td>When Apple unveiled its Apple Watch, the compa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Body ID                                           Headline  \\\n",
       "0      1034  HBO and Apple in Talks for $15/Month Apple TV ...   \n",
       "1      2033  Identity of ISIS terrorist known as 'Jihadi Jo...   \n",
       "2      1468  Woman detained in Lebanon is not al-Baghdadi's...   \n",
       "3       615  Vandals add rude paint job to $2.5m Bugatti (b...   \n",
       "4       608      ISIL Beheads American Photojournalist in Iraq   \n",
       "5      1196  Would you take a bite out of the world's oldes...   \n",
       "6      1658  Christian Bale Exits Steve Jobs Movie (Exclusive)   \n",
       "7      1896  Insurgents killed in Nigeria despite alleged t...   \n",
       "8       394  Report: ISIS Leader Abu Bakr Al-Baghdadi Assas...   \n",
       "9      1337  Taylor Lianne Chandler: Michael Phelps' Cougar...   \n",
       "10     1299  That Story About a Catholic Priest Dying, Seei...   \n",
       "11     2248  Planetary Alignment On Jan 4, 2015 Will Decrea...   \n",
       "12     2296  BREAKING NEWS: ISIS beheads missing American j...   \n",
       "13      759  Macaulay Culkin Hasn’t Died Despite What Every...   \n",
       "14      941     Eggnog-chugging contest leads to hospital stay   \n",
       "15      367  Anna Wintour: Is Rat Infestation At NYC ‘Vogue...   \n",
       "16      703  Islamic State leader's family detained by Leba...   \n",
       "17      724  Spider Burrows Into Australian Man's Appendix ...   \n",
       "18     1040  BREAKING NEWS: ISIS beheads missing American j...   \n",
       "19      487  Paul Rudd Is Not the Viral Video Hero Who Tack...   \n",
       "20     1435  New Audio Shows Michael Brown Was Shot at 11 T...   \n",
       "21     1315  Mystery woman behind the 'richest hands on the...   \n",
       "22     1125  Wife and son of Isil leader Abu Bakr al-Baghda...   \n",
       "23     1165  Ottawa investigates reports that Isis has capt...   \n",
       "24      346  CNN Broadcasts Purported Audio Containing Guns...   \n",
       "25     1832  Audio recording allegedly captures moment Mich...   \n",
       "26      775  NYPD to issue tickets instead of arrest for we...   \n",
       "27     2174  How did a Texas plumber's truck end up with Sy...   \n",
       "28     2097  Christian Bale In Talks To Play Steve Jobs In ...   \n",
       "29     2084  J.J. Abrams Asks Disney To Move Up 'Star Wars:...   \n",
       "30     2132  North Korean dictator Kim Jong-Un to open rest...   \n",
       "31       36  Hunt for 'cruel' owner who abandoned dog at tr...   \n",
       "32      821  Rare Case: Seven Bosnian Girls, Aged 13 And 14...   \n",
       "33     1125  Boko Haram 'ceasefire' doubts after attacks re...   \n",
       "34     2463  Hope Fades for Girls' Release After Boko Haram...   \n",
       "35     1048  Court Orders Probe Into Complaints Of 'Forced ...   \n",
       "36      321  Report: Possible audio tape of Michael Brown s...   \n",
       "37     1509  Armed U.S. drones spotted flying over Syria in...   \n",
       "38     1547  Vice CEO Throws Down $300K on Lavish Vegas Dinner   \n",
       "39     2342  Once Again, The Banksy 'Arrest' Is A Giant Hoa...   \n",
       "40     2064    Vogue’s Rat Infestation: Disturbing New Details   \n",
       "41      472  Islamic Militants Post Video Claiming to Show ...   \n",
       "42     1568  Sergeant-at-Arms stopped shooter on Parliament...   \n",
       "43     1438  ISIS cracks down on five confirmed Ebola cases...   \n",
       "44     1547  Lego letter to parents in 1974 on gender equal...   \n",
       "45     2290  KIM DINE WITH ME: Porky president Kim Jong-un ...   \n",
       "46     1720  Audio recording allegedly captures moment Mich...   \n",
       "47     1574  WHO investigates media reports ISIS fighters c...   \n",
       "48     1982  Islamic State Militants Claim to Have Beheaded...   \n",
       "49      296  New policy could reduce marijuana possession a...   \n",
       "\n",
       "                                                 Body  unrelated  related  \n",
       "0   (Reuters) - A Canadian soldier was shot at the...          1        0  \n",
       "1   Adding to Apple's iOS 8 launch troubles, a rep...          1        0  \n",
       "2   An Iraqi official denied that a woman detained...          0        1  \n",
       "3   \"Eh-oh!\" A 19-year-old student is claiming tha...          1        0  \n",
       "4   James Foley, an American journalist who went m...          0        1  \n",
       "5   Claim: An illustration created in response to ...          1        0  \n",
       "6   The Islamic State released a video of its jiha...          1        0  \n",
       "7   Boko Haram has reportedly agreed to a cease-fi...          0        1  \n",
       "8   An unverified photo claims to show the body of...          0        1  \n",
       "9   High quality global journalism requires invest...          1        0  \n",
       "10  Welsh actor Christian Bale has withdrawn from ...          1        0  \n",
       "11  SEVEN girls, aged 13 to 15, have fallen pregna...          1        0  \n",
       "12  North Korean despot Kim Jong-un has been guzzl...          1        0  \n",
       "13  Claim: Actor Macaulay Culkin has died.\\n\\nFALS...          0        1  \n",
       "14  It's hardly a secret that Amazon wants to be y...          1        0  \n",
       "15  Social media is awash with news of Islamic Sta...          1        0  \n",
       "16  Iraq’s Interior Ministry said on Wednesday tha...          0        1  \n",
       "17  Forget sweater weather and crisp autumn leaves...          1        0  \n",
       "18  (Mashable) Reports that Islamic State militant...          1        0  \n",
       "19  With Apple's media event just a week away and ...          1        0  \n",
       "20  Apple may be planning to hold a special event ...          1        0  \n",
       "21  The identity of the couple behind the mega-suc...          0        1  \n",
       "22  DC Toy Collector is the “highest paid performe...          1        0  \n",
       "23  As the anniversary of Sept. 11 approaches, the...          1        0  \n",
       "24  OTTAWA, Nov 30 (Reuters) - Canada is trying to...          1        0  \n",
       "25  14.3K 3077reddit70  32\\n\\n(RNS) When Pope Fran...          1        0  \n",
       "26  Media outlets have identified \"Jihadi John\" - ...          1        0  \n",
       "27  Vladimir Putin spoke at the dedication of a ne...          1        0  \n",
       "28  SEVEN girls, aged 13 to 15, have fallen pregna...          1        0  \n",
       "29  The Force may be with us a little sooner than ...          0        1  \n",
       "30  The video was one of those viral sensations th...          1        0  \n",
       "31  The London Metropolitan Police has denied repo...          1        0  \n",
       "32  The rat infestation in Vogue's new 1 World Tra...          1        0  \n",
       "33  DC Toy Collector is the “highest paid performe...          1        0  \n",
       "34  ABUJA, Nigeria — The leader of Nigeria's Islam...          0        1  \n",
       "35  Amazon is reportedly planning to launch an ad-...          1        0  \n",
       "36  A man with a rifle shot a soldier standing gua...          1        0  \n",
       "37  Activists in Al Raqqa have posted images onlin...          0        1  \n",
       "38  A picture of a letter to parents from a box of...          1        0  \n",
       "39  More graves have been discovered at the site w...          1        0  \n",
       "40  The rodents have pestered the staffs of Vanity...          0        1  \n",
       "41  American and British intelligence officials ar...          1        0  \n",
       "42  It is one of the most annoying aspects of mode...          1        0  \n",
       "43  A rogue bird let loose on Vladimir Putin over ...          1        0  \n",
       "44  A picture of a letter to parents from a box of...          0        1  \n",
       "45  Central Bedfordshire Council has refuted newsp...          1        0  \n",
       "46  A South American nun suddenly started experien...          1        0  \n",
       "47  Poverty-stricken parents took to the streets t...          1        0  \n",
       "48  MOGADISHU, Somalia — Al-Shabaab’s top leader w...          1        0  \n",
       "49  When Apple unveiled its Apple Watch, the compa...          1        0  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.read_csv(\"val_data_consolidated.csv\")\n",
    "print(val.shape)\n",
    "val.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datafields = [(\"Body ID\", None),\n",
    "                 (\"Headline\", TEXT),\n",
    "                    (\"Body\", TEXT),\n",
    "                 (\"unrelated\", LABEL),\n",
    "                (\"related\", LABEL)]\n",
    "\n",
    "trn, vld = TabularDataset.splits(\n",
    "               path=\"\",\n",
    "               train='train_data_consolidated.csv', validation=\"val_data_consolidated.csv\",\n",
    "               format='csv',\n",
    "               skip_header=True,\n",
    "               fields=train_datafields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "['police', 'find', 'mass', 'graves', 'with', 'at', 'least', \"'15\", \"bodies'\", 'near', 'mexico', 'town', 'where', '43', 'students', 'disappeared', 'after', 'police', 'clash']\n",
      "429\n",
      "['danny', 'boyle', 'is', 'directing', 'the', 'untitled', 'film', 'seth', 'rogen', 'is', 'being', 'eyed', 'to', 'play', 'apple', 'co-founder', 'steve', 'wozniak', 'in', 'sony’s', 'steve', 'jobs', 'biopic.', 'danny', 'boyle', 'is', 'directing', 'the', 'untitled', 'film,', 'based', 'on', 'walter', \"isaacson's\", 'book', 'and', 'adapted', 'by', 'aaron', 'sorkin,', 'which', 'is', 'one', 'of', 'the', 'most', 'anticipated', 'biopics', 'in', 'recent', 'years.', 'negotiations', 'have', 'not', 'yet', 'begun,', 'and', 'it’s', 'not', 'even', 'clear', 'if', 'rogen', 'has', 'an', 'official', 'offer,', 'but', 'the', 'producers', '—', 'scott', 'rudin,', 'guymon', 'casady', 'and', 'mark', 'gordon', '—', 'have', 'set', 'their', 'sights', 'on', 'the', 'talent', 'and', 'are', 'in', 'talks.', 'of', 'course,', 'this', 'may', 'all', 'be', 'for', 'naught', 'as', 'christian', 'bale,', 'the', 'actor', 'who', 'is', 'to', 'play', 'jobs,', 'is', 'still', 'in', 'the', 'midst', 'of', 'closing', 'his', 'deal.', 'sources', 'say', 'that', 'dealmaking', 'process', 'is', 'in', 'a', 'sensitive', 'stage.', 'insiders', 'say', 'boyle', 'will', 'is', 'flying', 'to', 'los', 'angeles', 'to', 'meet', 'with', 'actress', 'to', 'play', 'one', 'of', 'the', 'female', 'leads,', 'an', 'assistant', 'to', 'jobs.', 'insiders', 'say', 'that', 'jessica', 'chastain', 'is', 'one', 'of', 'the', 'actresses', 'on', 'the', 'meeting', 'list.', 'wozniak,', 'known', 'as', '\"woz,\"', 'co-founded', 'apple', 'with', 'jobs', 'and', 'ronald', 'wayne.', 'he', 'first', 'met', 'jobs', 'when', 'they', 'worked', 'at', 'atari', 'and', 'later', 'was', 'responsible', 'for', 'creating', 'the', 'early', 'apple', 'computers.']\n"
     ]
    }
   ],
   "source": [
    "print(len(trn[1].Headline))\n",
    "print(trn[0].Headline)\n",
    "print(len(trn[1].Body))\n",
    "print(trn[0].Body)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trn, vectors = 'glove.6B.100d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torch.autograd import Variable\n",
    "\n",
    "# class CNN_Text(nn.Module):\n",
    "    \n",
    "#     def __init__(self, vocab_size, emb_dim, output_dim, vocab, num_filters, kernel_size):\n",
    "#         super(CNN_Text, self).__init__()\n",
    "#         self.vocab_size = vocab_size\n",
    "#         self.emb_dim = emb_dim\n",
    "#         self.embed = nn.Embedding(vocab_size, self.emb_dim)\n",
    "#         self.embed.weight.data.copy_(vocab.vectors)\n",
    "#         self.embed.weight.requires_grad = False\n",
    "        \n",
    "#         self.conv = nn.Conv2d(in_channels = self.emb_dim, out_channels = num_filters, kernel_size = (kernel_size, 1), stride = (1,1), bias = True)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.kernel_size = kernel_size\n",
    "#         self.dropout = nn.Dropout(0.50)\n",
    "#         self.num_filters = num_filters\n",
    "#         self.output_dim = output_dim\n",
    "        \n",
    "        \n",
    "#         #output layer\n",
    "#         self.linear = nn.Linear(num_filters, self.output_dim)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "#     def forward_once(self, inputs):\n",
    "#         max_seq = inputs.shape[0]\n",
    "#         maxpool = nn.MaxPool3d(kernel_size = (1, max_seq - self.kernel_size + 1, 1), stride = (1,1,1))\n",
    "        \n",
    "#         inputs = inputs.transpose(0, 1) # batch x seq\n",
    "#         #print(inputs.shape)\n",
    "#         emb = self.embed(inputs) # batch x seq x emb_dim\n",
    "#         # print(emb.shape)\n",
    "#         emb = emb.transpose(1, 2) # batch x emb_dim x seq\n",
    "#         # print(emb.shape)\n",
    "#         emb = emb.unsqueeze(-1) # batch x emb_dim x seq x 1\n",
    "#         #print(emb.shape)\n",
    "        \n",
    "#         conv1 = self.conv(emb) # batch x out_channel x (seq + 1 - kernel)\n",
    "#         #print(conv1.shape)\n",
    "#         relu1 = self.relu(conv1)\n",
    "#         pool = maxpool(relu1) # batch x out_channel x 1 x 1\n",
    "#         #print(pool.shape)\n",
    "#         pool = pool.view(-1, self.num_filters) # batch x out_channel  \n",
    "#         #print(pool.shape)\n",
    "#         out = self.dropout(pool)\n",
    "#         score = self.linear(out)\n",
    "#         #print(score.shape)\n",
    "#         pred = self.sigmoid(score)\n",
    "        \n",
    "#         return pred\n",
    "    \n",
    "#     def forward(self, input1, input2):\n",
    "#         output1 = self.forward_once(input1)\n",
    "#         output2 = self.forward_once(input2)\n",
    "#         print(output1.shape)\n",
    "#         print(output2.shape)\n",
    "#         return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class CNN_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_dim, output_dim, vocab, num_filters, kernel_size):\n",
    "        super(CNN_Text, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_dim = emb_dim\n",
    "        self.embed = nn.Embedding(vocab_size, self.emb_dim)\n",
    "        self.embed.weight.data.copy_(vocab.vectors)\n",
    "        self.embed.weight.requires_grad = False\n",
    "        \n",
    "        self.conv13 = nn.Conv2d(in_channels = self.emb_dim, out_channels = num_filters, kernel_size = (3, 1), stride = (1,1), bias = True)\n",
    "        self.conv14 = nn.Conv2d(in_channels = self.emb_dim, out_channels = num_filters , kernel_size = (4, 1), stride = (1,1), bias = True)\n",
    "        self.conv15 = nn.Conv2d(in_channels = self.emb_dim, out_channels = num_filters, kernel_size = (5, 1), stride = (1,1),  bias = True)\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.num_filters = num_filters\n",
    "       \n",
    "        #output layer\n",
    "        self.linear = nn.Linear(num_filters*3, self.output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def conv_and_pool(self, x, conv, kernel_size): #input should be batch x emb_dim x seq x 1\n",
    "        #print(\"conv and poool\")\n",
    "        max_seq = x.shape[2]\n",
    "        #print(\"max seq = {}\".format(max_seq))\n",
    "        x = F.relu(conv(x))  # batch x out_channel x (seq + 1 -  kernel) x 1 -> [128, 64, 98, 1])\n",
    "        #print(x.shape)\n",
    "        max_pool = nn.MaxPool3d(kernel_size = (1, max_seq - kernel_size + 1, 1), stride = (1,1,1))\n",
    "        #print(x.shape)\n",
    "        x = max_pool(x)\n",
    "        #print(\"shape after max pooling: {}\".format(x.shape)) # [128, 64, 1, 1]\n",
    "        return x\n",
    "        \n",
    "    def forward_once(self, inputs):\n",
    "        #max_seq = inputs.shape[0]\n",
    "        #maxpool = nn.MaxPool3d(kernel_size = (1, max_seq - self.kernel_size + 1, 1), stride = (1,1,1))\n",
    "        inputs = inputs.transpose(0, 1) # batch x seq\n",
    "        emb = self.embed(inputs) # batch x seq x emb_dim\n",
    "        emb = emb.transpose(1, 2) # batch x emb_dim x seq\n",
    "        emb = emb.unsqueeze(-1) # batch x emb_dim x seq x 1\n",
    "        \n",
    "        res13 = self.conv_and_pool(emb, self.conv13, 3)\n",
    "        res14 = self.conv_and_pool(emb, self.conv14, 4)\n",
    "        res15 = self.conv_and_pool(emb, self.conv15, 5)\n",
    "        \n",
    "        res13 = res13.view(-1, self.num_filters)\n",
    "        res14 = res14.view(-1, self.num_filters)\n",
    "        res15 = res15.view(-1, self.num_filters)\n",
    "        \n",
    "        x = torch.cat((res13, res14, res15), 1)\n",
    "        #print(x.shape)\n",
    "        x = self.dropout(x)\n",
    "        #print(\"DONE WITH CREATING CONVS\")\n",
    "        \n",
    "        \n",
    "        preds = self.linear(x)\n",
    "        #print(preds.shape) # torch.Size([128, 2])\n",
    "        \n",
    "        preds = self.sigmoid(preds)\n",
    "        \n",
    "        return preds\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "        print(\"loss contrastive\")\n",
    "        print(loss_contrastive)\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_CNN = CNN_Text(len(TEXT.vocab), 100, 1, TEXT.vocab, 64, 5)\n",
    "model_CNN.train()\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model_CNN.parameters(), lr=1e-3)\n",
    "criterion = ContrastiveLoss(margin=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iter, val_iter = BucketIterator.splits(\n",
    " (trn, vld),\n",
    " batch_sizes=(128,128),\n",
    " sort_key=lambda x: len(x.Body), # the BucketIterator needs to be told what function it should use to group the data.\n",
    " sort_within_batch=False,\n",
    " repeat=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "class BatchGenerator:\n",
    "    def __init__(self, dl, x_field1, x_field2, y_field):\n",
    "        self.dl, self.x_field1, self.x_field2, self.y_field = dl, x_field1, x_field2, y_field\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            X1 = getattr(batch, self.x_field1)\n",
    "            X2 = getattr(batch, self.x_field2)\n",
    "            y = getattr(batch, self.y_field)\n",
    "            yield (X1, X2, y)\n",
    "            \n",
    "train_batch_it = BatchGenerator(train_iter, 'Body','Headline', 'unrelated')\n",
    "val_batch_it = BatchGenerator(val_iter, 'Body', 'Headline', 'unrelated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    counter = []\n",
    "    loss_history = [] \n",
    "    iteration_number= 0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(iterator,0):\n",
    "            img0, img1 , label = data\n",
    "            img0, img1 , label = img0, img1 , label\n",
    "            output1,output2 = model(img0,img1)\n",
    "            loss_contrastive = criterion(output1,output2,label.float())\n",
    "            if i %10 == 0 :\n",
    "                print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n",
    "                iteration_number +=10\n",
    "                counter.append(iteration_number)\n",
    "                loss_history.append(loss_contrastive.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive\n",
      "tensor(0.6683, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.6682829260826111\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.6698, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.6030, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.6540, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.6283, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.6004, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.6335, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.6559, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.6440, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.5312, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.5749, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.5748898983001709\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.5253, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.6331, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.4481, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.5193, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.5424, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.4388, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.4906, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.4370, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.4213, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.4207, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.4206843078136444\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.3742, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.3990, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.3727, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.3842, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.3155, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.3274, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.3152, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.3399, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2875, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.3309, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.33091166615486145\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.2825, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2914, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2485, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2620, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2780, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2849, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2733, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2494, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2145, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2434, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.2433924823999405\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.2327, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2390, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2660, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2069, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2534, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2486, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2074, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2353, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2579, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2345, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.23448485136032104\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.2740, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2536, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2326, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2006, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2025, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2230, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2366, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2008, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2233, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1967, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.19670110940933228\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.2326, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2537, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1990, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2093, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2183, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1740, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2022, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2238, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2306, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2456, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.2456214427947998\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.2082, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2373, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2236, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2084, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2132, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1927, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2250, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1873, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1788, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2109, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.21094389259815216\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1980, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1971, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2166, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2072, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2267, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2274, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2005, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2122, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2172, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2068, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.20684389770030975\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.2235, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2110, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2235, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2142, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1785, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2058, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2074, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2133, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2098, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1830, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.18302924931049347\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.2116, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1916, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1986, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2148, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2136, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2071, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1880, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2213, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1993, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1999, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.1999439150094986\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1636, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1868, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1718, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2216, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1899, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2032, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2336, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1928, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2043, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2053, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.20531992614269257\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1833, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1941, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1989, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2250, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1932, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1640, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1911, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2085, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1969, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1917, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.19167490303516388\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.2242, grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive\n",
      "tensor(0.1719, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1965, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2006, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1959, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1724, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1805, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1829, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1702, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1921, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.19211864471435547\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1635, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1995, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2008, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1599, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2029, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2101, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2148, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1934, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1994, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1638, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.1637585312128067\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1887, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1953, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1654, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1959, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1880, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1558, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2032, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1889, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2137, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2028, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.20282210409641266\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1940, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1817, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1455, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1879, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2056, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1632, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1555, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1738, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1874, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2053, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.20533649623394012\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1852, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2576, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1765, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2128, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1511, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1965, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1659, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1885, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2096, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1925, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.19253766536712646\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1572, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1841, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1907, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1712, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1844, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1842, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2058, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2104, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1707, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1708, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.17082087695598602\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1747, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1648, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2092, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1882, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2118, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1849, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2057, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2268, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2022, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1653, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.16528186202049255\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1780, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1735, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2061, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2010, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2057, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1952, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1571, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1636, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1464, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1553, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.15533743798732758\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1877, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1764, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1590, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1572, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1928, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1652, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1939, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2086, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1534, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1828, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.1827559471130371\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1877, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1984, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1870, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1607, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1345, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1341, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1786, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1691, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1859, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1970, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.19699405133724213\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1785, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1397, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1784, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1684, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1854, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1424, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1787, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1723, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1612, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1565, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.15650883316993713\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1577, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1677, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1613, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1995, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1639, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1870, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1633, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1829, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1933, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1552, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.15518756210803986\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1645, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1708, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1370, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1757, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2022, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1774, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1667, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1864, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1911, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1969, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.19689242541790009\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1671, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1569, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1472, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1453, grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive\n",
      "tensor(0.1907, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1377, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2047, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1464, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1704, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1645, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.16445112228393555\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1618, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1958, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1758, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1359, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1556, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1754, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2215, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2006, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1850, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1766, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.1766035109758377\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1552, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1538, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2192, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1967, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1963, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1514, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1637, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1893, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1794, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1659, grad_fn=<MeanBackward1>)\n",
      "Epoch number 0\n",
      " Current loss 0.1659342348575592\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1582, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1665, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1428, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.14284104108810425\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1747, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1559, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1478, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1649, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1346, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1651, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1407, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1770, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1904, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1901, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.19012631475925446\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1506, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1645, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1934, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1821, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1908, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1616, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1474, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1448, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1869, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1675, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.16747793555259705\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1683, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1406, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1641, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1532, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1417, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1799, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1711, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1411, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1923, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1617, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.1616820991039276\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1786, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1353, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1791, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1263, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1458, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1733, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1800, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1817, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1521, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1896, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.18956023454666138\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1808, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1445, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1718, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1734, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1891, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1287, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1835, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1580, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1697, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1534, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.15344004333019257\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1804, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1543, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1551, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1841, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1595, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1821, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1354, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1713, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1857, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1495, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.1495284140110016\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1925, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1467, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1923, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1583, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1582, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1620, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1431, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1212, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1925, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1352, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.1352265328168869\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1404, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1448, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1497, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1752, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1469, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1964, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1821, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1341, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1498, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1169, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.11691370606422424\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1498, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1778, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1605, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1390, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1378, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1191, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1537, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1456, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1655, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1674, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.16744057834148407\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1644, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1589, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1449, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1760, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1651, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1674, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1751, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1310, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1472, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1755, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.17551860213279724\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1508, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1501, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1443, grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive\n",
      "tensor(0.1429, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1789, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1546, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1320, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1601, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1501, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1300, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.13001485168933868\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1624, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1629, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1525, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1803, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1600, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1664, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1448, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1749, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1343, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1567, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.15671679377555847\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1263, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1449, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1592, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1329, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1179, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1696, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1483, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1632, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1585, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1502, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.15015605092048645\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1559, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1699, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1327, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1650, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1179, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1458, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1568, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1434, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1792, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1628, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.16281673312187195\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1542, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1457, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1464, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1498, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1789, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1449, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1590, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1657, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1522, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1589, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.1589142233133316\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1430, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1519, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1616, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1375, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1714, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1587, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1330, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1795, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1808, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1637, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.16366104781627655\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1469, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1580, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1338, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1583, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1580, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1290, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1425, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1713, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1485, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1232, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.12319578230381012\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1383, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1389, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1069, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1771, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1540, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1452, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1635, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1475, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2066, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1548, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.1547527313232422\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1518, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1537, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1392, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1512, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1167, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1471, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1511, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1515, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1430, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1614, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.16139213740825653\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1186, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1351, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1265, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1602, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1733, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1327, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1447, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1607, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1032, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1411, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.14109933376312256\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1399, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1581, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1690, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1593, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1415, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1563, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1468, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1537, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1644, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1908, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.1908227950334549\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1281, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1826, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1731, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1788, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1359, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1542, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1558, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1487, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1261, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1047, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.10474329441785812\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1596, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1320, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.2089, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1119, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1438, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1547, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1496, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1485, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1713, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1614, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.16144803166389465\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1981, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1294, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1384, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1490, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1277, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1329, grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive\n",
      "tensor(0.1527, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1764, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1630, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1597, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.15968920290470123\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1371, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1320, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1420, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1596, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1292, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1526, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1089, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1649, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1899, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1587, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.15871106088161469\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1233, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1157, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1400, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1427, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1241, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1395, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1528, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1545, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1477, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1258, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.1257612705230713\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1596, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1768, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1304, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1683, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1553, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1437, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1352, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1449, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1613, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1602, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.16018901765346527\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1684, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1464, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1712, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1483, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1425, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1621, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1283, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1773, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1459, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1925, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.1925082951784134\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1427, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1656, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1517, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1532, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1588, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1003, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1664, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1128, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1443, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1394, grad_fn=<MeanBackward1>)\n",
      "Epoch number 1\n",
      " Current loss 0.1394200176000595\n",
      "\n",
      "loss contrastive\n",
      "tensor(0.1585, grad_fn=<MeanBackward1>)\n",
      "loss contrastive\n",
      "tensor(0.1380, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(0,2):\n",
    "    for i, data in enumerate(train_batch_it,0):\n",
    "        img0, img1 , label = data\n",
    "        img0, img1 , label = img0, img1 , label\n",
    "        optimizer.zero_grad()\n",
    "        output1,output2 = model_CNN(img0,img1)\n",
    "        loss_contrastive = criterion(output1,output2,label.float())\n",
    "        loss_contrastive.backward()\n",
    "        optimizer.step()\n",
    "        if i %10 == 0 :\n",
    "            print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n",
    "            iteration_number +=10\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss_contrastive.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    batch_num = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(iterator,0):\n",
    "            img0, img1 , label = data\n",
    "            output1,output2 = model(img0,img1)\n",
    "            euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "            print(euclidean_distance)\n",
    "            print(label)\n",
    "            print(\"*********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0938e-01, 2.6486e-02, 1.4764e-02, 3.8404e-02, 6.3206e-03, 7.0899e-03,\n",
      "        1.2306e-01, 5.6804e-02, 3.7451e-02, 5.7852e-02, 3.9487e-02, 2.5692e-02,\n",
      "        1.7941e-02, 3.4291e-02, 2.7424e-02, 1.2709e-02, 6.4257e-02, 2.8552e-02,\n",
      "        5.6959e-02, 2.6519e-02, 8.4709e-02, 7.3856e-02, 5.2609e-02, 1.0000e-06,\n",
      "        1.3570e-02, 1.9449e-02, 2.0647e-03, 8.6965e-01, 8.1846e-01, 7.8720e-01,\n",
      "        8.7804e-01, 8.4439e-01, 7.2466e-01, 8.8908e-01, 8.2758e-01, 8.7456e-01,\n",
      "        8.4079e-01, 8.2444e-01, 8.4884e-01, 8.6154e-01, 8.4823e-01, 7.2655e-01,\n",
      "        8.2865e-01, 8.6334e-01, 7.6907e-01, 7.8102e-03, 8.7255e-01, 8.1188e-01,\n",
      "        7.8065e-01, 8.1480e-01, 7.7014e-01, 8.5584e-01, 8.3960e-01, 7.9126e-01,\n",
      "        8.3739e-01, 1.7014e-02, 3.6031e-02, 1.8702e-02, 7.7624e-01, 3.3455e-02,\n",
      "        8.7863e-01, 8.7564e-01, 8.6967e-01, 8.0924e-01, 8.5961e-01, 8.2029e-01,\n",
      "        8.2883e-01, 8.9241e-01, 8.7226e-01, 8.5741e-01, 5.9573e-01, 8.9102e-01,\n",
      "        7.3306e-01, 8.3024e-01, 7.9009e-01, 8.9204e-01, 8.9342e-01, 8.7634e-01,\n",
      "        8.5124e-01, 5.4079e-01, 7.8370e-01, 8.1719e-01, 8.2817e-01, 8.5736e-01,\n",
      "        8.5394e-01, 7.2650e-01, 8.8376e-01, 7.3323e-01, 8.8333e-01, 9.0286e-01,\n",
      "        8.8670e-01, 8.3626e-01, 8.7815e-01, 8.7413e-01, 8.0031e-01, 8.6927e-01,\n",
      "        8.6723e-01, 8.9316e-01, 8.7093e-01, 7.7670e-01, 3.7933e-01, 8.1581e-01,\n",
      "        3.7898e-01, 7.7239e-01, 8.4238e-01, 8.4095e-01, 8.7579e-01, 7.7452e-01,\n",
      "        4.4569e-01, 7.8381e-01, 4.1696e-01, 3.0459e-01, 5.3555e-03, 6.5519e-01,\n",
      "        8.4178e-01, 3.2928e-01, 6.0370e-01, 8.8549e-01, 8.7843e-01, 8.4609e-01,\n",
      "        4.1149e-01, 9.0072e-02, 7.7798e-01, 8.1429e-01, 8.3076e-01, 8.1036e-01,\n",
      "        2.0359e-03, 8.4132e-01])\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1])\n",
      "*********\n",
      "tensor([0.8574, 0.4343, 0.4618, 0.6682, 0.8672, 0.0339, 0.8283, 0.8391, 0.8208,\n",
      "        0.0948, 0.8831, 0.8233, 0.4405, 0.8046, 0.4400, 0.7901, 0.8734, 0.8021,\n",
      "        0.7964, 0.6893, 0.7425, 0.8136, 0.8104, 0.4578, 0.4419, 0.8251, 0.8672,\n",
      "        0.4085, 0.8540, 0.4119, 0.6846, 0.1598, 0.0797, 0.3404, 0.0101, 0.4617,\n",
      "        0.7005, 0.4777, 0.0093, 0.0229, 0.3301, 0.7181, 0.7469, 0.2809, 0.4790,\n",
      "        0.4865, 0.3378, 0.1789, 0.7566, 0.2527, 0.3480, 0.4368, 0.0205, 0.3277,\n",
      "        0.0366, 0.2612, 0.2949, 0.0068, 0.0250, 0.7393, 0.2664, 0.0872, 0.7939,\n",
      "        0.8451, 0.0835, 0.0749, 0.5724, 0.6769, 0.6094, 0.5793, 0.7969, 0.1542,\n",
      "        0.5595, 0.1009, 0.8519, 0.8726, 0.5968, 0.0883, 0.8158, 0.0129, 0.0322,\n",
      "        0.8138, 0.8280, 0.8084, 0.8460, 0.8660, 0.5722, 0.1738, 0.8597, 0.8664,\n",
      "        0.0443, 0.5743, 0.0270, 0.1027, 0.8211, 0.8044, 0.0597, 0.6695, 0.1037,\n",
      "        0.7515, 0.0801, 0.7194, 0.0186, 0.5224, 0.0086, 0.0732, 0.8029, 0.6129,\n",
      "        0.0528, 0.7731, 0.6548, 0.6692, 0.0019, 0.0287, 0.8027, 0.7952, 0.7752,\n",
      "        0.8048, 0.0298, 0.7569, 0.1084, 0.7858, 0.0268, 0.0581, 0.6196, 0.4003,\n",
      "        0.0296, 0.0498])\n",
      "tensor([1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1])\n",
      "*********\n",
      "tensor([0.7402, 0.7684, 0.5003, 0.7260, 0.0324, 0.7441, 0.6025, 0.6175, 0.6630,\n",
      "        0.0684, 0.1657, 0.4753, 0.2439, 0.1741, 0.0299, 0.1859, 0.4652, 0.1478,\n",
      "        0.2765, 0.4324, 0.0670, 0.3549, 0.2192, 0.0098, 0.0167, 0.0012, 0.7128,\n",
      "        0.0789, 0.3085, 0.0702, 0.3750, 0.2909, 0.1305, 0.0509, 0.3060, 0.0569,\n",
      "        0.0042, 0.3662, 0.7745, 0.0075, 0.3700, 0.0558, 0.0372, 0.0174, 0.0035,\n",
      "        0.0099, 0.0070, 0.3197, 0.0307, 0.0177, 0.0157, 0.3006, 0.0042, 0.0521,\n",
      "        0.0174, 0.0260, 0.0466, 0.5414, 0.0835, 0.5875, 0.6182, 0.5877, 0.5436,\n",
      "        0.5514, 0.0925, 0.5961, 0.5712, 0.6068, 0.5910, 0.5567, 0.0587, 0.6261,\n",
      "        0.5619, 0.6031, 0.6203, 0.4075, 0.6969, 0.6454, 0.7334, 0.4169, 0.1273,\n",
      "        0.0631, 0.1735, 0.7669, 0.1206, 0.6688, 0.1396, 0.6956, 0.1239, 0.7586,\n",
      "        0.6406, 0.4441, 0.7834, 0.1151, 0.1752, 0.7585, 0.5056, 0.6823, 0.7756,\n",
      "        0.7126, 0.6896, 0.6452, 0.0958, 0.1369, 0.6212, 0.7201, 0.6783, 0.3781,\n",
      "        0.0109, 0.5936, 0.1985, 0.1724, 0.7195, 0.0105, 0.0490, 0.0377, 0.0106,\n",
      "        0.0607, 0.0029, 0.0148, 0.0341, 0.0033, 0.0208, 0.0273, 0.0260, 0.0161,\n",
      "        0.0331, 0.0360])\n",
      "tensor([0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0])\n",
      "*********\n",
      "tensor([0.0086, 0.8116, 0.7152, 0.6579, 0.0595, 0.0512, 0.0025, 0.0172, 0.0677,\n",
      "        0.0455, 0.0317, 0.0422, 0.3258, 0.0355, 0.6513, 0.5323, 0.6164, 0.5475,\n",
      "        0.4677, 0.4089, 0.6143, 0.3366, 0.5849, 0.6933, 0.8205, 0.7891, 0.0417,\n",
      "        0.7808, 0.8290, 0.7862, 0.8221, 0.8158, 0.7820, 0.7573, 0.8166, 0.7771,\n",
      "        0.7499, 0.7509, 0.7936, 0.8024, 0.7255, 0.6850, 0.7718, 0.0836, 0.0547,\n",
      "        0.6862, 0.7651, 0.7553, 0.6600, 0.7788, 0.7566, 0.4663, 0.5418, 0.7791,\n",
      "        0.6981, 0.5684, 0.7826, 0.6631, 0.7730, 0.5938, 0.6998, 0.6953, 0.5147,\n",
      "        0.7666, 0.5488, 0.8003, 0.7281, 0.5637, 0.7891, 0.4994, 0.6675, 0.7355,\n",
      "        0.5451, 0.6787, 0.8090, 0.8225, 0.7945, 0.7903, 0.4836, 0.7721, 0.7960,\n",
      "        0.5231, 0.8624, 0.8096, 0.3279, 0.8803, 0.8904, 0.8779, 0.8348, 0.8121,\n",
      "        0.8511, 0.8890, 0.8514, 0.8582, 0.8738, 0.8529, 0.8748, 0.8269, 0.8598,\n",
      "        0.8715, 0.8971, 0.8895, 0.8221, 0.8543, 0.8485, 0.8575, 0.7419, 0.1389,\n",
      "        0.8705, 0.8343, 0.1200, 0.8709, 0.8005, 0.1510, 0.1402, 0.1813, 0.1841,\n",
      "        0.0972, 0.6933, 0.6221, 0.6652, 0.6787, 0.6477, 0.6703, 0.6063, 0.6174,\n",
      "        0.6393, 0.6032])\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "*********\n",
      "tensor([0.5977, 0.5192, 0.2077, 0.2079, 0.8822, 0.8530, 0.9013, 0.8557, 0.8902,\n",
      "        0.7795, 0.8721, 0.9196, 0.7991, 0.8902, 0.9528, 0.9175, 0.7729, 0.8900,\n",
      "        0.9288, 0.8341, 0.5731, 0.7982, 0.9458, 0.9244, 0.8653, 0.7901, 0.9274,\n",
      "        0.8473, 0.8753, 0.9474, 0.9119, 0.5668, 0.9337, 0.8728, 0.8338, 0.9027,\n",
      "        0.9535, 0.9258, 0.9521, 0.9114, 0.9243, 0.8809, 0.7090, 0.6776, 0.9230,\n",
      "        0.8854, 0.8433, 0.7900, 0.9600, 0.9349, 0.9143, 0.8342, 0.7491, 0.4546,\n",
      "        0.8336, 0.8259, 0.8209, 0.7843, 0.3232, 0.7969, 0.7372, 0.0651, 0.8428,\n",
      "        0.8259, 0.7291, 0.3548, 0.7715, 0.3282, 0.7922, 0.7755, 0.3432, 0.8463,\n",
      "        0.8046, 0.2919, 0.6772, 0.8035, 0.7592, 0.8506, 0.7763, 0.8296, 0.8455,\n",
      "        0.8610, 0.6207, 0.7360, 0.8271, 0.8130, 0.6567, 0.8445, 0.7964, 0.8257,\n",
      "        0.7995, 0.7449, 0.8416, 0.8478, 0.8006, 0.7684, 0.8385, 0.8466, 0.8190,\n",
      "        0.8351, 0.8376, 0.8177, 0.8465, 0.7039, 0.8452, 0.7961, 0.8603, 0.8495,\n",
      "        0.8254, 0.4944, 0.8560, 0.8600, 0.8292, 0.8033, 0.4447, 0.5928, 0.5911,\n",
      "        0.6214, 0.0933, 0.8150, 0.8883, 0.8885, 0.0261, 0.0914, 0.0435, 0.1072,\n",
      "        0.6809, 0.0560])\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0])\n",
      "*********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0956, 0.8948, 0.9154, 0.8692, 0.0508, 0.8761, 0.8545, 0.0696, 0.1075,\n",
      "        0.8704, 0.8773, 0.0286, 0.0985, 0.1070, 0.0522, 0.0881, 0.6787, 0.0921,\n",
      "        0.4647, 0.4445, 0.3586, 0.3602, 0.4600, 0.4470, 0.4815, 0.4409, 0.8481,\n",
      "        0.8393, 0.3997, 0.4380, 0.3932, 0.8782, 0.8710, 0.8869, 0.8746, 0.8901,\n",
      "        0.9025, 0.6913, 0.8760, 0.8701, 0.8241, 0.8368, 0.8610, 0.7903, 0.8219,\n",
      "        0.7871, 0.8568, 0.8423, 0.8622, 0.8214, 0.8121, 0.8375, 0.7527, 0.8615,\n",
      "        0.8359, 0.8435, 0.8305, 0.8636, 0.8069, 0.7672, 0.8257, 0.8697, 0.8501,\n",
      "        0.7716, 0.8470, 0.8442, 0.7432, 0.8132, 0.8211, 0.8616, 0.8517, 0.8007,\n",
      "        0.8121, 0.9104, 0.7722, 0.8640, 0.9088, 0.6726, 0.7595, 0.7977, 0.8973,\n",
      "        0.8967, 0.8050, 0.8701, 0.9091, 0.9197, 0.9084, 0.8929, 0.7332, 0.8988,\n",
      "        0.9183, 0.9345, 0.6679, 0.9263, 0.1572, 0.9204, 0.7939, 0.5095, 0.5274,\n",
      "        0.5036, 0.4925, 0.4859, 0.4364, 0.5095, 0.3596, 0.4890, 0.1840, 0.2465,\n",
      "        0.2411, 0.1942, 0.2136, 0.7497, 0.7014, 0.7240, 0.7278, 0.6504, 0.6734,\n",
      "        0.7051, 0.6584, 0.6878, 0.6220, 0.5591, 0.9526, 0.8798, 0.8788, 0.8610,\n",
      "        0.9166, 0.8472])\n",
      "tensor([0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "*********\n",
      "tensor([0.9043, 0.8445, 0.8525, 0.7139, 0.9465, 0.6708, 0.8286, 0.8148, 0.8439,\n",
      "        0.7885, 0.8243, 0.9303, 0.9458, 0.9197, 0.8558, 0.8593, 0.9122, 0.8404,\n",
      "        0.9086, 0.7628, 0.8258, 0.9444, 0.9444, 0.9179, 0.9288, 0.9444, 0.9211,\n",
      "        0.9323, 0.8587, 0.8776, 0.9445, 0.8557, 0.7336, 0.9167, 0.9260, 0.8076,\n",
      "        0.9226, 0.8796, 0.8848, 0.8216, 0.8315, 0.9190, 0.9047, 0.8733, 0.8412,\n",
      "        0.8213, 0.8554, 0.9249, 0.9420, 0.8600, 0.9021, 0.9168, 0.8019, 0.9109,\n",
      "        0.9068, 0.9334, 0.9259, 0.5547, 0.8479, 0.8806, 0.9200, 0.9226, 0.8440,\n",
      "        0.8632, 0.9230, 0.9224, 0.9337, 0.9401, 0.8420, 0.9055, 0.9040, 0.9361,\n",
      "        0.8867, 0.9415, 0.8743, 0.7086, 0.1724, 0.7195, 0.1717, 0.1487, 0.1788,\n",
      "        0.0967, 0.0432, 0.0321, 0.0917, 0.0203, 0.3909, 0.0469, 0.5824, 0.5968,\n",
      "        0.8994, 0.0974, 0.4123, 0.8451, 0.4743, 0.0955, 0.0289, 0.7739, 0.0556,\n",
      "        0.8493, 0.5863, 0.7946, 0.8633, 0.7693, 0.8761, 0.8731, 0.7523, 0.7547,\n",
      "        0.3992, 0.7806, 0.8540, 0.2525, 0.8158, 0.8071, 0.8471, 0.8075, 0.8523,\n",
      "        0.2734, 0.2708, 0.2646, 0.2648, 0.3002, 0.3112, 0.2909, 0.3282, 0.2398,\n",
      "        0.3178, 0.2995])\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 0])\n",
      "*********\n",
      "tensor([0.2599, 0.3094, 0.7563, 0.2178, 0.7343, 0.8550, 0.8428, 0.7536, 0.8442,\n",
      "        0.4139, 0.1748, 0.8188, 0.6906, 0.8629, 0.7262, 0.8070, 0.7248, 0.3898,\n",
      "        0.3621, 0.2438, 0.6550, 0.7245, 0.3142, 0.5122, 0.5403, 0.5149, 0.5276,\n",
      "        0.4974, 0.8563, 0.7410, 0.4467, 0.4288, 0.5134, 0.4254, 0.6668, 0.7044,\n",
      "        0.2244, 0.7330, 0.7132, 0.7426, 0.7329, 0.7688, 0.2235, 0.6824, 0.1379,\n",
      "        0.1909, 0.6839, 0.6993, 0.7462, 0.7073, 0.7440, 0.2314, 0.1989, 0.7289,\n",
      "        0.1920, 0.1889, 0.1743, 0.6507, 0.7041, 0.7748, 0.8340, 0.8551, 0.8716,\n",
      "        0.8168, 0.7270, 0.3599, 0.3630, 0.3853, 0.2885, 0.2935, 0.5810, 0.3492,\n",
      "        0.3549, 0.3849, 0.0082, 0.3650, 0.3595, 0.6065, 0.3661, 0.5868, 0.2971,\n",
      "        0.3457, 0.8507, 0.8263, 0.3321, 0.3829, 0.7665, 0.7934, 0.8427, 0.7816,\n",
      "        0.8359, 0.4919, 0.4400, 0.4542, 0.7906, 0.8253, 0.8392, 0.8569, 0.7067,\n",
      "        0.8364, 0.7710, 0.7754, 0.7962, 0.7673, 0.8362, 0.8206, 0.9438, 0.8246,\n",
      "        0.9044, 0.8437, 0.9169, 0.9128, 0.7184, 0.9118, 0.9096, 0.8718, 0.9050,\n",
      "        0.7583, 0.9025, 0.9213, 0.8097, 0.8423, 0.4503, 0.5417, 0.5413, 0.4487,\n",
      "        0.8186, 0.8260])\n",
      "tensor([0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 0, 0])\n",
      "*********\n",
      "tensor([0.9530, 0.9243, 0.9528, 0.9220, 0.7976, 0.8772, 0.5662, 0.8895, 0.9274,\n",
      "        0.8422, 0.9379, 0.9143, 0.9342, 0.9374, 0.9169, 0.9281, 0.8629, 0.9193,\n",
      "        0.9456, 0.8382, 0.8536, 0.8982, 0.9446, 0.9201, 0.9156, 0.8643, 0.8894,\n",
      "        0.8891, 0.9078, 0.3556, 0.4173, 0.3563, 0.4159, 0.4075, 0.3807, 0.8881,\n",
      "        0.9034, 0.7505, 0.8331, 0.8824, 0.7913, 0.8598, 0.8620, 0.8267, 0.9028,\n",
      "        0.8690, 0.8058, 0.7836, 0.8446, 0.8609, 0.8542, 0.8145, 0.8846, 0.8638,\n",
      "        0.8940, 0.9137, 0.7729, 0.8263, 0.9018, 0.8889, 0.7183, 0.7509, 0.7577,\n",
      "        0.8142, 0.8169, 0.8527, 0.7924, 0.8338, 0.4474, 0.5873, 0.8406, 0.8592,\n",
      "        0.8638, 0.7067, 0.7938, 0.8959, 0.8731, 0.7789, 0.8123, 0.8054, 0.7900,\n",
      "        0.7325, 0.7631, 0.8030, 0.8311, 0.7347, 0.8517, 0.7921, 0.8064, 0.7025,\n",
      "        0.7986, 0.8188, 0.7955, 0.8702, 0.7802, 0.7521, 0.4358, 0.8239, 0.8133,\n",
      "        0.7954, 0.4897, 0.8594, 0.4771, 0.7272, 0.7591, 0.4579, 0.7889, 0.8312,\n",
      "        0.8193, 0.7285, 0.7089, 0.8370, 0.7822, 0.7022, 0.8162, 0.8565, 0.7982,\n",
      "        0.8373, 0.3996, 0.8549, 0.7000, 0.8544, 0.7663, 0.8521, 0.8592, 0.8072,\n",
      "        0.7953, 0.8172])\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1])\n",
      "*********\n",
      "tensor([0.6895, 0.7033, 0.5630, 0.3461, 0.3415, 0.6716, 0.6500, 0.6680, 0.6309,\n",
      "        0.7049, 0.6396, 0.6676, 0.6899, 0.8296, 0.8339, 0.8287, 0.8104, 0.8338,\n",
      "        0.8268, 0.7889, 0.7842, 0.8583, 0.8937, 0.8900, 0.7726, 0.8594, 0.8926,\n",
      "        0.9122, 0.8741, 0.8705, 0.9113, 0.9205, 0.6774, 0.8940, 0.9071, 0.9191,\n",
      "        0.8801, 0.9364, 0.9159, 0.9469, 0.7830, 0.9206, 0.8447, 0.9404, 0.9447,\n",
      "        0.8645, 0.9293, 0.9387, 0.9114, 0.9390, 0.9192, 0.8642, 0.9206, 0.9266,\n",
      "        0.8416, 0.9109, 0.9465, 0.7883, 0.8245, 0.8194, 0.2321, 0.8920, 0.6525,\n",
      "        0.8590, 0.8599, 0.6650, 0.7122, 0.9005, 0.9362, 0.8436, 0.8498, 0.8785,\n",
      "        0.9148, 0.9556, 0.8964, 0.6199, 0.8861, 0.8843, 0.9276, 0.8708, 0.7700,\n",
      "        0.5888, 0.9039, 0.7722, 0.8270, 0.8758, 0.6028, 0.8795, 0.8709, 0.7604,\n",
      "        0.9145, 0.9362, 0.8617, 0.8809, 0.8237, 0.8905, 0.8427, 0.8849, 0.8764,\n",
      "        0.8352, 0.6919, 0.7352, 0.7968, 0.6475, 0.8215, 0.8594, 0.8088, 0.8689,\n",
      "        0.8282, 0.8423, 0.6791, 0.8595, 0.8617, 0.8354, 0.8405, 0.7951, 0.8786,\n",
      "        0.8436, 0.6023, 0.8950, 0.8780, 0.7982, 0.7627, 0.8621, 0.9098, 0.8974,\n",
      "        0.8292, 0.8406])\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "*********\n",
      "tensor([0.6206, 0.8798, 0.8376, 0.4829, 0.8351, 0.9122, 0.8973, 0.8978, 0.9256,\n",
      "        0.8685, 0.8356, 0.9169, 0.9293, 0.8372, 0.9074, 0.8565, 0.9169, 0.8971,\n",
      "        0.9004, 0.9234, 0.9011, 0.7388, 0.8583, 0.8378, 0.9140, 0.4344, 0.5653,\n",
      "        0.9033, 0.5963, 0.7707, 0.9016, 0.7908, 0.7489, 0.7934, 0.7291, 0.4953,\n",
      "        0.7261, 0.7216, 0.7559, 0.8014, 0.7446, 0.8029, 0.7986, 0.8243, 0.6120,\n",
      "        0.7743, 0.7870, 0.4575, 0.6421, 0.8985, 0.7977, 0.7406, 0.8067, 0.8090,\n",
      "        0.7214, 0.6156, 0.8055, 0.4835, 0.7633, 0.7915, 0.8243, 0.8517, 0.8138,\n",
      "        0.8112, 0.8602, 0.8332, 0.9013, 0.9177, 0.8279, 0.7713, 0.7940, 0.7803,\n",
      "        0.7979, 0.8706, 0.8507, 0.8650, 0.8110, 0.8600, 0.8490, 0.9144, 0.7716,\n",
      "        0.8353, 0.7758, 0.7087, 0.8859, 0.8481, 0.8346, 0.8424, 0.8109, 0.8821,\n",
      "        0.8308, 0.8326, 0.8816, 0.8468, 0.7791, 0.8316, 0.7359, 0.7959, 0.7785,\n",
      "        0.6049, 0.7583, 0.8131, 0.7821, 0.6935, 0.8222, 0.8254, 0.8070, 0.8432,\n",
      "        0.8714, 0.7289, 0.5459, 0.7140, 0.6390, 0.7032, 0.6272, 0.7228, 0.7452,\n",
      "        0.6502, 0.6887, 0.7296, 0.6141, 0.6234, 0.6854, 0.6476, 0.6528, 0.6116,\n",
      "        0.7272, 0.7303])\n",
      "tensor([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "*********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7308, 0.7999, 0.7484, 0.7937, 0.8312, 0.7870, 0.7508, 0.7527, 0.6923,\n",
      "        0.7470, 0.8056, 0.7436, 0.7936, 0.8008, 0.7982, 0.6251, 0.8156, 0.7429,\n",
      "        0.7889, 0.7224, 0.7296, 0.6567, 0.7297, 0.7626, 0.8375, 0.7629, 0.7496,\n",
      "        0.8020, 0.6563, 0.7948, 0.7407, 0.8249, 0.7936, 0.8146, 0.7532, 0.8117,\n",
      "        0.8261, 0.8018, 0.7842, 0.8431, 0.8041, 0.8311, 0.7409, 0.7410, 0.8298,\n",
      "        0.8627, 0.8958, 0.8761, 0.8753, 0.8370, 0.8577, 0.8487, 0.7632, 0.8525,\n",
      "        0.8765, 0.8180, 0.6944, 0.8381, 0.5674, 0.8578, 0.8444, 0.7560, 0.8609,\n",
      "        0.8214, 0.7854, 0.6328, 0.7756, 0.7622, 0.8434, 0.8417, 0.7428, 0.7535,\n",
      "        0.7839, 0.5674, 0.7809, 0.8639, 0.7292, 0.8384, 0.8484, 0.7400, 0.8318,\n",
      "        0.8019, 0.8119, 0.8273, 0.4887, 0.6270, 0.6217, 0.8106, 0.7135, 0.8505,\n",
      "        0.5997, 0.8491, 0.8441, 0.8101, 0.8526, 0.8407, 0.6048, 0.8647, 0.4124,\n",
      "        0.8549, 0.8139, 0.6210, 0.8153, 0.5342, 0.6388, 0.7847, 0.8333, 0.8136,\n",
      "        0.7854, 0.4890, 0.8663, 0.5802, 0.8584, 0.8633, 0.4512, 0.3986, 0.8578,\n",
      "        0.6037, 0.8514, 0.6063, 0.8507, 0.7776, 0.7464, 0.6889, 0.6129, 0.5533,\n",
      "        0.5548, 0.6440])\n",
      "tensor([1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1])\n",
      "*********\n",
      "tensor([0.6112, 0.5187, 0.4812, 0.5706, 0.5272, 0.3931, 0.6340, 0.6260, 0.3965,\n",
      "        0.6391, 0.6103, 0.6151, 0.6270, 0.8575, 0.8801, 0.8962, 0.8954, 0.8690,\n",
      "        0.8289, 0.8627, 0.8477, 0.7572, 0.8959, 0.9208, 0.8765, 0.7203, 0.9374,\n",
      "        0.9140, 0.8758, 0.5753, 0.6606, 0.8803, 0.8302, 0.8445, 0.9370, 0.9316,\n",
      "        0.7199, 0.8336, 0.7453, 0.7143, 0.9330, 0.8454, 0.8991, 0.9116, 0.9460,\n",
      "        0.7322, 0.8331, 0.8681, 0.7973, 0.8265, 0.9440, 0.7198, 0.8467, 0.7382,\n",
      "        0.9304, 0.9471, 0.9086, 0.9501, 0.7694, 0.9194, 0.8632, 0.8479, 0.8282,\n",
      "        0.5284, 0.8774, 0.8115, 0.8228, 0.5043, 0.4762, 0.4715, 0.4783, 0.7999,\n",
      "        0.4103, 0.5250, 0.8493, 0.8503, 0.3699, 0.4293, 0.4345, 0.8121, 0.4226,\n",
      "        0.7877, 0.8935, 0.9003, 0.8821, 0.9044, 0.3674, 0.7746, 0.8604, 0.8833,\n",
      "        0.0614, 0.4153, 0.9093, 0.3667, 0.8922, 0.4316, 0.3810, 0.8646, 0.8254,\n",
      "        0.8720, 0.8546, 0.8673, 0.8546, 0.8420, 0.8616, 0.8626, 0.7860, 0.8811,\n",
      "        0.7683, 0.7094, 0.8479, 0.8549, 0.7833, 0.8542, 0.7762, 0.7717, 0.8153,\n",
      "        0.6688, 0.8539, 0.7611, 0.8494, 0.8439, 0.7868, 0.8809, 0.3736, 0.8598,\n",
      "        0.4634, 0.4184])\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0])\n",
      "*********\n",
      "tensor([0.6802, 0.4413, 0.4490, 0.8410, 0.4014, 0.8242, 0.8605, 0.8705, 0.4396,\n",
      "        0.6958, 0.2631, 0.7041, 0.8565, 0.7734, 0.6270, 0.7882, 0.1261, 0.4525,\n",
      "        0.3268, 0.8148, 0.8437, 0.8557, 0.9086, 0.8802, 0.8044, 0.9046, 0.8928,\n",
      "        0.8571, 0.8951, 0.8731, 0.8020, 0.9060, 0.8164, 0.8647, 0.8758, 0.8955,\n",
      "        0.9251, 0.9174, 0.8247, 0.9598, 0.8372, 0.9121, 0.7849, 0.8910, 0.9586,\n",
      "        0.7618, 0.9487, 0.8691, 0.5557, 0.9034, 0.8783, 0.9191, 0.9486, 0.8495,\n",
      "        0.9180, 0.9398, 0.9123, 0.8725, 0.9238, 0.8400, 0.9407, 0.9172, 0.8101,\n",
      "        0.9066, 0.7329, 0.9100, 0.9148, 0.8965, 0.8881, 0.8287, 0.8254, 0.9337,\n",
      "        0.9296, 0.9624, 0.6529, 0.8924, 0.9392, 0.8483, 0.7993, 0.8260, 0.8084,\n",
      "        0.7942, 0.7560, 0.7854, 0.7572, 0.3581, 0.8376, 0.8452, 0.8207, 0.4555,\n",
      "        0.7805, 0.8162, 0.6648, 0.6649, 0.7400, 0.7786, 0.6741, 0.7940, 0.8455,\n",
      "        0.7747, 0.7759, 0.8231, 0.7695, 0.8924, 0.9122, 0.8608, 0.8854, 0.8658,\n",
      "        0.7932, 0.7937, 0.1893, 0.8238, 0.1731, 0.7612, 0.8550, 0.2102, 0.8976,\n",
      "        0.8237, 0.8191, 0.8541, 0.8775, 0.8484, 0.8845, 0.8487, 0.1923, 0.7976,\n",
      "        0.8995, 0.8172])\n",
      "tensor([0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0])\n",
      "*********\n",
      "tensor([0.8458, 0.8886, 0.7348, 0.7570, 0.4235, 0.7829, 0.3863, 0.7656, 0.7656,\n",
      "        0.3076, 0.7432, 0.7512, 0.7713, 0.2852, 0.8072, 0.1323, 0.3381, 0.3379,\n",
      "        0.7851, 0.3169, 0.7699, 0.7311, 0.2483, 0.8047, 0.8136, 0.3684, 0.1402,\n",
      "        0.2737, 0.7751, 0.3805, 0.2254, 0.2779, 0.7415, 0.2706, 0.1781, 0.3169,\n",
      "        0.8683, 0.5507, 0.8665, 0.4475, 0.4401, 0.8520, 0.7761, 0.8424, 0.8345,\n",
      "        0.5169, 0.8300, 0.8459, 0.8166, 0.8103, 0.5160, 0.1771, 0.8385, 0.8718,\n",
      "        0.4259, 0.8778, 0.8466, 0.8607, 0.8761, 0.8797, 0.8475, 0.8475, 0.8659,\n",
      "        0.4361, 0.8678, 0.7383, 0.8115, 0.8796, 0.8251, 0.4435, 0.7929, 0.4238,\n",
      "        0.7039, 0.6963, 0.8118, 0.9105, 0.8748, 0.9103, 0.3415, 0.3532, 0.8828,\n",
      "        0.8183, 0.8729, 0.7683, 0.7881, 0.7731, 0.9297, 0.8258, 0.4283, 0.8464,\n",
      "        0.8733, 0.7657, 0.8022, 0.7926, 0.7682, 0.4186, 0.7363, 0.8077, 0.8640,\n",
      "        0.6031, 0.2908, 0.4356, 0.8436, 0.9095, 0.8489, 0.8281, 0.8104, 0.9215,\n",
      "        0.7996, 0.7198, 0.8052, 0.7855, 0.4242, 0.8755, 0.8573, 0.6611, 0.8648,\n",
      "        0.6436, 0.8063, 0.9047, 0.6449, 0.8857, 0.8044, 0.7939, 0.7883, 0.6168,\n",
      "        0.8084, 0.8985])\n",
      "tensor([1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0])\n",
      "*********\n",
      "tensor([0.7684, 0.8571, 0.8691, 0.5449, 0.8755, 0.8385, 0.8844, 0.7725, 0.8651,\n",
      "        0.6494, 0.8302, 0.5111, 0.7700, 0.6482, 0.8174, 0.8698, 0.8219, 0.8249,\n",
      "        0.8420, 0.8653, 0.5770, 0.8816, 0.9145, 0.9206, 0.6385, 0.9167, 0.9016,\n",
      "        0.8182, 0.8539, 0.8911, 0.9200, 0.8463, 0.8508, 0.8615, 0.6791, 0.8990,\n",
      "        0.8581, 0.7992, 0.7685, 0.8827, 0.9067, 0.8525, 0.8740, 0.7996, 0.9164,\n",
      "        0.9035, 0.8326, 0.7936, 0.9048, 0.8860, 0.8643, 0.9294, 0.8343, 0.9241,\n",
      "        0.8661, 0.8933, 0.8686, 0.8877, 0.9311, 0.9275, 0.8466, 0.8972, 0.8889,\n",
      "        0.9154, 0.9341, 0.8164, 0.8530, 0.9085, 0.9388, 0.8453, 0.8471, 0.9292,\n",
      "        0.8620, 0.8284, 0.8987, 0.6653, 0.6969, 0.8506, 0.6495, 0.6896, 0.4139,\n",
      "        0.4306, 0.6921, 0.4281, 0.6492, 0.4305, 0.5872, 0.8360, 0.8142, 0.8703,\n",
      "        0.8508, 0.8034, 0.8504, 0.8880, 0.8837, 0.7556, 0.8787, 0.8626, 0.8345,\n",
      "        0.8757, 0.9025, 0.8393, 0.8025, 0.8735, 0.8274, 0.2845, 0.8631, 0.8933,\n",
      "        0.7044, 0.9340, 0.8852, 0.9031, 0.8008, 0.8222, 0.8181, 0.8833, 0.9098,\n",
      "        0.8330, 0.2852, 0.8940, 0.8813, 0.8466, 0.7756, 0.8244, 0.8174, 0.8496,\n",
      "        0.9351, 0.8912])\n",
      "tensor([1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1])\n",
      "*********\n",
      "tensor([0.9328, 0.9222, 0.8734, 0.8419, 0.8777, 0.6472, 0.8951, 0.6826, 0.9016,\n",
      "        0.8332, 0.9116, 0.9009, 0.8727, 0.8570, 0.8592, 0.8391, 0.8761, 0.9066,\n",
      "        0.9117, 0.9043, 0.9124, 0.8773, 0.9156, 0.9002, 0.9416, 0.9323, 0.9285,\n",
      "        0.8560, 0.8237, 0.8591, 0.8623, 0.8416, 0.4728, 0.4650, 0.4225, 0.4600,\n",
      "        0.4463, 0.8217, 0.8941, 0.8519, 0.8375, 0.8335, 0.6727, 0.8796, 0.8976,\n",
      "        0.8825, 0.8726, 0.8801, 0.8909, 0.8491, 0.8644, 0.8723, 0.8713, 0.8746,\n",
      "        0.2714, 0.7391, 0.2988, 0.6423, 0.2688, 0.2403, 0.7378, 0.5848, 0.2307,\n",
      "        0.9251, 0.9021, 0.7724, 0.3675, 0.8469, 0.3091, 0.8823, 0.9314, 0.9122,\n",
      "        0.2310, 0.8329, 0.8630, 0.8665, 0.9073, 0.8679, 0.2410, 0.8736, 0.8665,\n",
      "        0.8548, 0.9022, 0.3392, 0.9133, 0.3082, 0.7839, 0.7839, 0.9332, 0.9196,\n",
      "        0.9247, 0.6057, 0.8201, 0.9439, 0.9027, 0.9071, 0.8958, 0.8851, 0.6308,\n",
      "        0.1816, 0.8605, 0.5216, 0.7482, 0.8453, 0.8331, 0.7359, 0.8032, 0.8890,\n",
      "        0.7348, 0.7493, 0.7840, 0.7526, 0.8908, 0.8247, 0.6729, 0.8092, 0.7793,\n",
      "        0.8268, 0.7795, 0.7463, 0.7711, 0.8997, 0.7911, 0.7863, 0.7644, 0.7506,\n",
      "        0.9076, 0.9196])\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0])\n",
      "*********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6081, 0.8278, 0.9020, 0.8923, 0.5396, 0.2639, 0.8926, 0.8551, 0.9096,\n",
      "        0.9296, 0.9257, 0.5793, 0.7558, 0.5876, 0.1271, 0.8333, 0.5677, 0.6498,\n",
      "        0.8680, 0.8996, 0.8794, 0.9383, 0.9295, 0.6389, 0.9312, 0.9010, 0.6162,\n",
      "        0.8503, 0.8249, 0.7849, 0.7816, 0.4034, 0.6079, 0.8113, 0.6033, 0.8735,\n",
      "        0.7984, 0.6046, 0.8492, 0.8253, 0.7849, 0.8129, 0.8582, 0.7408, 0.8108,\n",
      "        0.8270, 0.8034, 0.5065, 0.8413, 0.8656, 0.8380, 0.5536, 0.8317, 0.3953,\n",
      "        0.8043, 0.7999, 0.8246, 0.8248, 0.8525, 0.7710, 0.8122, 0.8023, 0.8333,\n",
      "        0.8294, 0.5228, 0.8374, 0.7549, 0.7772, 0.8324, 0.7815, 0.7987, 0.7715,\n",
      "        0.3976, 0.8771, 0.4384, 0.8368, 0.8158, 0.8254, 0.8732, 0.8586, 0.7979,\n",
      "        0.8273, 0.8561, 0.8634, 0.8277, 0.3692, 0.0712, 0.8647, 0.8703, 0.4122,\n",
      "        0.4237, 0.7207, 0.5516, 0.5936, 0.6089, 0.6444, 0.6394, 0.8319, 0.5754,\n",
      "        0.7911, 0.6222, 0.6042, 0.6458, 0.6343, 0.7704, 0.6209, 0.5061, 0.6333,\n",
      "        0.7677, 0.8803, 0.8688, 0.8899, 0.8374, 0.8949, 0.8960, 0.8271, 0.8919,\n",
      "        0.8903, 0.9013, 0.9418, 0.8916, 0.8412, 0.8824, 0.7405, 0.8948, 0.6368,\n",
      "        0.8854, 0.8896])\n",
      "tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1])\n",
      "*********\n",
      "tensor([0.0978, 0.4770, 0.2024, 0.1325, 0.8888, 0.9280, 0.8272, 0.5242, 0.8452,\n",
      "        0.1103, 0.7960, 0.9177, 0.8903, 0.7537, 0.8474, 0.9125, 0.8560, 0.7978,\n",
      "        0.8267, 0.1288, 0.8611, 0.1684, 0.1598, 0.8612, 0.8761, 0.8305, 0.4025,\n",
      "        0.8902, 0.8919, 0.9162, 0.8957, 0.8892, 0.6766, 0.6832, 0.8936, 0.5656,\n",
      "        0.7585, 0.3497, 0.7143, 0.3796, 0.7590, 0.8930, 0.6667, 0.6407, 0.7840,\n",
      "        0.4050, 0.6214, 0.7769, 0.9041, 0.8590, 0.6904, 0.8536, 0.3671, 0.8912,\n",
      "        0.6824, 0.5333, 0.5009, 0.5710, 0.5717, 0.8731, 0.9016, 0.8842, 0.6423,\n",
      "        0.6086, 0.7978, 0.7518, 0.8825, 0.8758, 0.8580, 0.7779, 0.7970, 0.7402,\n",
      "        0.8498, 0.9009, 0.8722, 0.8383, 0.8495, 0.8249, 0.8187, 0.8093, 0.8272,\n",
      "        0.7499, 0.8320, 0.8870, 0.4898, 0.7807, 0.9264, 0.7760, 0.8747, 0.8251,\n",
      "        0.8794, 0.8926, 0.8520, 0.8520, 0.7807, 0.8973, 0.8091, 0.8685, 0.7957,\n",
      "        0.8362, 0.8504, 0.8509, 0.8260, 0.8265, 0.8628, 0.8544, 0.8014, 0.7859,\n",
      "        0.8493, 0.5845, 0.9085, 0.7612, 0.8174, 0.9010, 0.9232, 0.8523, 0.7645,\n",
      "        0.8713, 0.8272, 0.8446, 0.8537, 0.8971, 0.9000, 0.8828, 0.9015, 0.9041,\n",
      "        0.8585, 0.7187])\n",
      "tensor([0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1])\n",
      "*********\n",
      "tensor([0.8282, 0.8692, 0.8359, 0.8537, 0.8740, 0.8668, 0.8016, 0.8646, 0.8690,\n",
      "        0.8948, 0.8943, 0.8742, 0.8523, 0.8583, 0.8966, 0.8758, 0.9081, 0.9034,\n",
      "        0.3927, 0.3851, 0.3902, 0.3156, 0.9071, 0.3210, 0.3640, 0.8635, 0.3550,\n",
      "        0.8723, 0.9022, 0.8588, 0.8978, 0.9015, 0.8368, 0.3661, 0.8897, 0.3778,\n",
      "        0.3219, 0.9122, 0.3796, 0.8496, 0.8590, 0.7786, 0.8208, 0.9107, 0.7825,\n",
      "        0.8687, 0.6206, 0.9212, 0.8971, 0.8896, 0.7739, 0.9365, 0.5929, 0.7377,\n",
      "        0.6533, 0.8267, 0.7945, 0.8813, 0.8933, 0.8064, 0.8481, 0.7734, 0.4787,\n",
      "        0.7725, 0.7849, 0.8564, 0.8964, 0.8296, 0.9097, 0.7552, 0.7825, 0.8022,\n",
      "        0.8224, 0.9066, 0.8280, 0.9326, 0.9184, 0.7884, 0.7459, 0.8404, 0.8283,\n",
      "        0.8740, 0.7554, 0.8270, 0.7824, 0.8081, 0.8172, 0.7374, 0.8324, 0.3746,\n",
      "        0.2984, 0.8448, 0.3803, 0.8854, 0.6114, 0.8064, 0.3449, 0.7115, 0.6520,\n",
      "        0.4071, 0.8769, 0.8973, 0.3925, 0.3847, 0.3941, 0.2855, 0.8554, 0.8897,\n",
      "        0.9049, 0.8959, 0.8625, 0.8078, 0.8331, 0.8453, 0.7990, 0.7826, 0.8801,\n",
      "        0.8658, 0.8394, 0.8983, 0.8304, 0.8914, 0.8101, 0.6252, 0.8604, 0.8112,\n",
      "        0.7899, 0.8897])\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "*********\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-335-916cc9f9f086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate model performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batch_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-334-cfb708365109>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, iterator, criterion)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mimg0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0moutput1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0meuclidean_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meuclidean_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-315-eeac49ad4758>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input1, input2)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-315-eeac49ad4758>\u001b[0m in \u001b[0;36mforward_once\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mres13\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_and_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mres14\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_and_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mres15\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_and_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mres13\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres13\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_filters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-315-eeac49ad4758>\u001b[0m in \u001b[0;36mconv_and_pool\u001b[0;34m(self, x, conv, kernel_size)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mmax_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#print(\"max seq = {}\".format(max_seq))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# batch x out_channel x (seq + 1 -  kernel) x 1 -> [128, 64, 98, 1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;31m#print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mmax_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "evaluate(model_CNN, val_batch_it, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.data.iterator.BucketIterator object at 0x166bfa2e8>\n",
      "293\n",
      "<torchtext.data.iterator.BucketIterator object at 0x166bfa748>\n",
      "98\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-333-d0c101b6187d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 2\n",
    "print(train_iter)\n",
    "print(len(train_iter))\n",
    "print(val_iter)\n",
    "print(len(val_iter))\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train(model_CNN, train_iter, optimizer, criterion)\n",
    "    print(train_loss)\n",
    "    print(train_acc)\n",
    "    valid_loss, valid_acc = evaluate(model_RNN, val_iter, criterion)\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
