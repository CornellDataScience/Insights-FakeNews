{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import networkx as nx\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import score as sc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13427, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'Nasa Confirms Earth Will Experience 6 Days of...</td>\n",
       "      <td>154</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Banksy 'Arrested &amp; Real Identity Revealed' Is ...</td>\n",
       "      <td>1739</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gateway Pundit</td>\n",
       "      <td>2327</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Woman detained in Lebanon is not al-Baghdadi's...</td>\n",
       "      <td>1468</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Soon Marijuana May Lead to Ticket, Not Arrest,...</td>\n",
       "      <td>47</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Boko Haram Denies Nigeria Cease-Fire Claim</td>\n",
       "      <td>2463</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>No, Robert Plant Didn’t Rip Up an $800 Million...</td>\n",
       "      <td>295</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ISIL Beheads American Photojournalist in Iraq</td>\n",
       "      <td>608</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline  Body ID    Stance\n",
       "1   Hundreds of Palestinians flee floods in Gaza a...      158     agree\n",
       "4   Spider burrowed through tourist's stomach and ...     1923  disagree\n",
       "5   'Nasa Confirms Earth Will Experience 6 Days of...      154     agree\n",
       "8   Banksy 'Arrested & Real Identity Revealed' Is ...     1739     agree\n",
       "10                                     Gateway Pundit     2327   discuss\n",
       "11  Woman detained in Lebanon is not al-Baghdadi's...     1468     agree\n",
       "14  Soon Marijuana May Lead to Ticket, Not Arrest,...       47   discuss\n",
       "16         Boko Haram Denies Nigeria Cease-Fire Claim     2463   discuss\n",
       "17  No, Robert Plant Didn’t Rip Up an $800 Million...      295     agree\n",
       "19      ISIL Beheads American Photojournalist in Iraq      608   discuss"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stances = pd.read_csv(\"fn_data/train_stances.csv\")\n",
    "train_stances = train_stances.loc[lambda x: x.Stance != \"unrelated\"]\n",
    "print(train_stances.shape)\n",
    "train_stances.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1683, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody\n",
       "0        0  A small meteorite crashed into a wooded area i...\n",
       "1        4  Last week we hinted at what was to come as Ebo...\n",
       "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...\n",
       "3        6  Posting photos of a gun-toting child online, I...\n",
       "4        7  At least 25 suspected Boko Haram insurgents we..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bodies = pd.read_csv(\"fn_data/train_bodies.csv\")\n",
    "print(train_bodies.shape)\n",
    "train_bodies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.replace(\"' \",' ')\n",
    "    text = text.replace(\" '\",' ')\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headline_subj(doc):\n",
    "    subjs = {}\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if chunk.root.text not in subjs:\n",
    "            subjs[chunk.root.text] = set([chunk.root.text])\n",
    "        subjs[chunk.root.text].add(chunk.text)\n",
    "    return subjs\n",
    "#         print(chunk.text, \"|\",chunk.root.text, \"|\",chunk.root.dep_,\"|\",\n",
    "#               chunk.root.head.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_graph(doc):\n",
    "    edges = set()\n",
    "    for token in doc:\n",
    "        if len(token) > 1:\n",
    "            for child in token.children:\n",
    "                if len(child) > 1:\n",
    "                    edges.add((token.lower_,child.lower_))\n",
    "    graph = nx.Graph(list(edges))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words = set([\"n't\", \"not\"])\n",
    "doubt_words = set(['fake','fraud', 'hoax', 'false', 'deny', 'denies', 'despite', 'nope', 'doubt', 'bogus', 'debunk', 'prank', 'retract', 'scam'])\n",
    "nr_words = neg_words.union(doubt_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len([p for p in paths if len(set(p).intersection(nr_words)) > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph = build_graph(nlp(b_n))\n",
    "# paths = []\n",
    "# # simple_paths = nx.all_simple_paths(graph, source='hoax', target=\"banksy\",cutoff=5)\n",
    "# # for p in simple_paths:\n",
    "# #     paths.append(p)\n",
    "# # print(len(paths))\n",
    "# # print(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_path_to_negating(graph, subjects):\n",
    "    results = {}\n",
    "    for s in subjects:\n",
    "        if graph.has_node(s) and s not in nr_words:\n",
    "            results[s] = [None, None, 0] #length of path, paths, number of total paths\n",
    "            for word in nr_words:\n",
    "                if word in graph:\n",
    "                    try:\n",
    "                        path = nx.shortest_path(graph, source = s, target = word)\n",
    "                        paths = nx.all_simple_paths(graph, source = s, target = word,cutoff=5)\n",
    "                        if results[s][0] == None or len(path) < results[s][0]:\n",
    "                            results[s][0] = len(path)\n",
    "                            results[s][1] = path\n",
    "                        results[s][2] += len(list(paths))\n",
    "                    except:\n",
    "                        continue\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0\n",
      "Processed 100\n",
      "Processed 200\n",
      "Processed 300\n",
      "Processed 400\n",
      "Processed 500\n",
      "Processed 600\n",
      "Processed 700\n",
      "Processed 800\n",
      "Processed 900\n",
      "Processed 1000\n",
      "Processed 1100\n"
     ]
    }
   ],
   "source": [
    "headline_info = {}\n",
    "body_info = {}\n",
    "start = time.time()\n",
    "stance_data = list(train_stances.values)\n",
    "body_data = list(train_bodies.values)\n",
    "for body in range(len(body_data)):\n",
    "    if body % 100 == 0:\n",
    "        print(\"Processed \"+str(body))\n",
    "    b_id, txt = tuple(body_data[body])\n",
    "    txt = preprocess(txt)\n",
    "    nlp_b = nlp(txt)\n",
    "    body_graph = build_graph(nlp_b)\n",
    "    body_info[b_id] = (nlp_b, body_graph)\n",
    "print(\"Done!\")\n",
    "for headline in range(len(stance_data)):\n",
    "    if headline % 2500 == 0:\n",
    "        print(\"Processed \"+str(headline))\n",
    "    h, b_id, s = tuple(stance_data[headline])\n",
    "    h = preprocess(h)\n",
    "    nlp_h = nlp(h)\n",
    "    headline_graph = build_graph(nlp_h)\n",
    "    headline_info[h] = (nlp_h, headline_graph)\n",
    "print(\"Done!\")\n",
    "end = time.time()\n",
    "print(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5460\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data = list(train_stances.values)\n",
    "predicted = []\n",
    "actual = []\n",
    "for item in data:\n",
    "    h, b, s = tuple(item)\n",
    "    nlp_h, headline_graph = headline_info[h]\n",
    "    nlp_b, body_graph = body_info[b]\n",
    "    subj = get_headline_subj(nlp_h)\n",
    "    \n",
    "    neg_h = get_shortest_path_to_negating(headline_graph, subj)\n",
    "    neg_b = get_shortest_path_to_negating(body_graph, subj)\n",
    "    \n",
    "    shared_subjects = set(neg_h).intersection(set(neg_b))\n",
    "    score = 0 # positive is agree, negative is disagree\n",
    "    for sub in shared_subjects:\n",
    "        nh, nb = neg_h[sub],  neg_b[sub]\n",
    "        #one doc mentions negatively, the other does not\n",
    "        if nh[0] == None and nb[0] != None and nb[0] < 8:\n",
    "            score -= 1\n",
    "        elif nh[0] != None and nb[0] == None and nh[0] < 8:\n",
    "            score -= 1\n",
    "        #both docs mention negatively\n",
    "        elif nh[0] != None and nb[0] != None:\n",
    "            score += 1\n",
    "        #both don't mention negatively -> discuss\n",
    "    if score < 0:\n",
    "        predicted.append(\"disagree\")\n",
    "    elif score > 0:\n",
    "        predicted.append(\"agree\")\n",
    "    else:\n",
    "        predicted.append(\"discuss\")\n",
    "    actual.append(s)\n",
    "end = time.time()\n",
    "print(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    671    |   1863    |   1144    |     0     |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    84     |    620    |    136    |     0     |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    494    |   6006    |   2409    |     0     |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |     0     |     0     |     0     |     0     |\n",
      "-------------------------------------------------------------\n",
      "Score: 6131.75 out of 13427.0\t(45.667312132270794%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45.667312132270794"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.report_score(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
