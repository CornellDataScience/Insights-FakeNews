{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import networkx as nx\n",
    "import score as sc\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, pairwise, f1_score, precision_score\n",
    "from scipy.spatial import distance\n",
    "from preprocessing.utils import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from collections import Counter, defaultdict\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import torch\n",
    "import importlib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "import sentic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "importlib.reload(sys.modules['preprocessing.utils'])\n",
    "from preprocessing.utils import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix_local(y_true, y_pred, classes,\n",
    "                          normalize=True,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout();\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/huggingface/neuralcoref\n",
    "#note: this NEEDS spacy 2.0.12 to work! downgrade with pip install spacy=2.0.12\n",
    "import en_coref_md\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "coref = en_coref_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "negating_words = set([\n",
    "    \"n't\", \"not\", \"no\", \n",
    "    \"never\", \"nobody\", \"non\", \"nope\"])\n",
    "doubting_words = set([\n",
    "    'fake','fraud', 'hoax', \n",
    "    'false', 'deny', 'denies', \n",
    "    'despite', 'doubt', \n",
    "    'bogus', 'debunk', 'prank', \n",
    "    'retract', 'scam', \"withdrawn\",\n",
    "    \"misinformation\"])\n",
    "hedging_words = set([\n",
    "    'allege', 'allegedly','apparently',\n",
    "    'appear','claim','could',\n",
    "    'evidently','largely','likely',\n",
    "    'mainly','may', 'maybe', 'might',\n",
    "    'mostly','perhaps','presumably',\n",
    "    'probably','purport', 'purportedly',\n",
    "    'reported', 'reportedly',\n",
    "    'rumor', 'rumour', 'rumored', 'rumoured',\n",
    "    'says','seem','somewhat',\n",
    "    'unconfirmed'])\n",
    "sus_words = doubting_words.union(hedging_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(sentence):\n",
    "    sent =  vader.polarity_scores(sentence.text)\n",
    "    return [sent[\"pos\"],sent[\"neg\"],sent[\"neu\"],sent[\"compound\"]]\n",
    "\n",
    "def get_avg_sentiment(lst):\n",
    "    sents = np.array([get_sentiment(s) for s in lst])\n",
    "    return list(np.mean(sents, axis = 0))\n",
    "\n",
    "def get_diff_sentiment(a,b):\n",
    "    return list(np.absolute(np.array(a) - np.array(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(bodies, stances, split=0.8):\n",
    "    idx = np.random.permutation(np.arange(len(bodies)))\n",
    "    bodies = bodies.values[idx]\n",
    "    train = int(len(bodies)*0.8)\n",
    "    bodies_tr = set([i[0] for i in bodies[:train]])\n",
    "    bodies_val = set([i[0] for i in bodies[train:]])\n",
    "    stances_tr = stances.loc[stances[\"Body ID\"].isin(bodies_tr), :]\n",
    "    stances_val = stances.loc[stances[\"Body ID\"].isin(bodies_val), :]\n",
    "    return stances_tr, stances_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13427, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'Nasa Confirms Earth Will Experience 6 Days of...</td>\n",
       "      <td>154</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Banksy 'Arrested &amp; Real Identity Revealed' Is ...</td>\n",
       "      <td>1739</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gateway Pundit</td>\n",
       "      <td>2327</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Woman detained in Lebanon is not al-Baghdadi's...</td>\n",
       "      <td>1468</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Soon Marijuana May Lead to Ticket, Not Arrest,...</td>\n",
       "      <td>47</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Boko Haram Denies Nigeria Cease-Fire Claim</td>\n",
       "      <td>2463</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>No, Robert Plant Didn’t Rip Up an $800 Million...</td>\n",
       "      <td>295</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ISIL Beheads American Photojournalist in Iraq</td>\n",
       "      <td>608</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Boko Haram ceasefire ignored as violence flare...</td>\n",
       "      <td>1681</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NET Extra: Back-from-the-dead Catholic priest ...</td>\n",
       "      <td>1014</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Rumor debunked: RoboCop-style robots are not p...</td>\n",
       "      <td>633</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Report: Christian Bale Just Bailed on the Stev...</td>\n",
       "      <td>1157</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Insurgents killed in Nigeria despite alleged t...</td>\n",
       "      <td>1896</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline  Body ID    Stance\n",
       "1   Hundreds of Palestinians flee floods in Gaza a...      158     agree\n",
       "4   Spider burrowed through tourist's stomach and ...     1923  disagree\n",
       "5   'Nasa Confirms Earth Will Experience 6 Days of...      154     agree\n",
       "8   Banksy 'Arrested & Real Identity Revealed' Is ...     1739     agree\n",
       "10                                     Gateway Pundit     2327   discuss\n",
       "11  Woman detained in Lebanon is not al-Baghdadi's...     1468     agree\n",
       "14  Soon Marijuana May Lead to Ticket, Not Arrest,...       47   discuss\n",
       "16         Boko Haram Denies Nigeria Cease-Fire Claim     2463   discuss\n",
       "17  No, Robert Plant Didn’t Rip Up an $800 Million...      295     agree\n",
       "19      ISIL Beheads American Photojournalist in Iraq      608   discuss\n",
       "21  Boko Haram ceasefire ignored as violence flare...     1681   discuss\n",
       "24  NET Extra: Back-from-the-dead Catholic priest ...     1014     agree\n",
       "25  Rumor debunked: RoboCop-style robots are not p...      633     agree\n",
       "29  Report: Christian Bale Just Bailed on the Stev...     1157   discuss\n",
       "31  Insurgents killed in Nigeria despite alleged t...     1896   discuss"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stances = pd.read_csv(\"fn_data/train_stances.csv\")\n",
    "train_stances = train_stances.loc[lambda x: x.Stance != \"unrelated\"]\n",
    "print(train_stances.shape)\n",
    "train_stances.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1683, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody\n",
       "0        0  A small meteorite crashed into a wooded area i...\n",
       "1        4  Last week we hinted at what was to come as Ebo...\n",
       "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...\n",
       "3        6  Posting photos of a gun-toting child online, I...\n",
       "4        7  At least 25 suspected Boko Haram insurgents we..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bodies = pd.read_csv(\"fn_data/train_bodies.csv\")\n",
    "print(train_bodies.shape)\n",
    "train_bodies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_body(n):\n",
    "    return train_bodies.loc[lambda x: x[\"Body ID\"] == n, \"articleBody\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.replace(\"' \",' ')\n",
    "    text = text.replace(\" '\",' ')\n",
    "    text = text.replace(\":\", \". \")\n",
    "    text = text.replace(\";\", \". \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x,y):\n",
    "    return 1 - np.nan_to_num(distance.cosine(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(doc):\n",
    "    \"\"\"\n",
    "    get topics of a sentence\n",
    "    input: spacy doc\n",
    "    output: dictionary with nouns as the key, and the set of noun chunks that contain the noun as the value\n",
    "    special entry _vocab has the set of all tokens in the dict\n",
    "    \"\"\"\n",
    "    subjs = {}\n",
    "    for token in doc:\n",
    "        if token.dep_ in [\"nsubj\", \"nsubjpass\", \"csubj\",\"csubjpass\", \"dobj\", \"dative\", \"attr\", \"oprd\", \"pobj\", \"compound\"]:\n",
    "            txt = token.lemma_.lower()\n",
    "            if txt not in subjs:\n",
    "                subjs[txt] = set([txt])      \n",
    "    for chunk in doc.noun_chunks:\n",
    "        if len(chunk.root.text) > 2:\n",
    "            txt = chunk.root.text.lower()\n",
    "            if txt not in subjs:\n",
    "                subjs[txt] = set([txt])\n",
    "            subjs[txt].add(chunk.text.lower())\n",
    "    subjects_= []\n",
    "    for word in subjs:\n",
    "        for phrase in subjs[word]:\n",
    "            subjects_ += phrase.split(\" \")\n",
    "    subjs[\"_vocab\"] = set(subjects_)\n",
    "    return subjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svos(sent):\n",
    "    \"\"\"\n",
    "    input: Spacy processed sentence\n",
    "    output: dict of subj, dict of v, dict of obj (each word is lemmatized and lowercased)\n",
    "    each entry in dict has key of lemmatized token, value is actual token (to do traversals with later if needed)\n",
    "    \"\"\"\n",
    "    s = {}\n",
    "    v = {}\n",
    "    o = {}\n",
    "    for token in sent:\n",
    "        if token.dep_ == 'ROOT':\n",
    "            v[token.lemma_.lower()] = token\n",
    "        elif token.dep_ in [\"nsubj\", \"nsubjpass\", \"csubj\",\"csubjpass\", \"agent\",\"compound\"]:\n",
    "            s[token.lemma_.lower()] = token\n",
    "        elif token.dep_ in [\"dobj\", \"dative\", \"attr\", \"oprd\", \"pobj\"]:\n",
    "            o[token.lemma_.lower()] = token\n",
    "    # https://github.com/clir/clearnlp-guidelines/blob/master/md/specifications/dependency_labels.md\n",
    "    return (s,v,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentic import SenticPhrase\n",
    "text = \"Hello, World!\"\n",
    "sp = SenticPhrase(text)\n",
    "\n",
    "def get_sentics(sent):\n",
    "    \"\"\"\n",
    "        input: Spacy processed sentence\n",
    "        output: a tuple containing the polarity score and a list of sentic values \n",
    "            (pleasantness, attention, sensitiviy, aptitude )\n",
    "    \"\"\"\n",
    "    sent = (str(sent)).strip().replace(\"'\", \"\")\n",
    "    info = sp.info(sent)\n",
    "          \n",
    "    # Sometimes sentic doesn't returns any sentics values, seems to be only when purely neutral. \n",
    "    # Some sort of tag to make sure this is true could help with classiciation! (if all 0's not enough)\n",
    "    if(len(info[\"sentics\"].values())==0):\n",
    "          info[\"sentics\"] = {\"pleasantness\":0, \"attention\":0, \"sensitiviy\":0, \"aptitude\":0}\n",
    "    return info['polarity'], info[\"sentics\"].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_graph(doc):\n",
    "    \"\"\"\n",
    "    build a NetworkX graph of the dependency tree\n",
    "    input: spacy Doc\n",
    "    output: networkx graph\n",
    "    \"\"\"\n",
    "    edges = set()\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['PUNCT', 'NUM', 'SYM','SPACE','PART']:\n",
    "            for child in token.children:\n",
    "                if child.pos_ not in ['PUNCT', 'NUM', 'SYM','SPACE','PART']:\n",
    "                    edges.add((token.lemma_.lower(),child.lemma_.lower()))\n",
    "    graph = nx.DiGraph(list(edges))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(doc, subjects, n = 5):\n",
    "    \"\"\"\n",
    "    get summary of n sentences in document\n",
    "    first meaningful sentence will always be returned\n",
    "    \"\"\"\n",
    "    subjects_ = subjects[\"_vocab\"]\n",
    "    def score_sentence(sent):\n",
    "        # not very robust right now\n",
    "        score = 0\n",
    "        word_count = 0\n",
    "        for token in sent:\n",
    "            word_count += 1\n",
    "            t = token.lemma_.lower()\n",
    "            if t in subjects_:\n",
    "                score += 1\n",
    "            elif t in negating_words or t in doubting_words or t in hedging_words:\n",
    "                score += 0.5\n",
    "            return score/word_count if word_count > 4 else 0\n",
    "    sentences = [s for s in doc.sents]\n",
    "    scored_sentences = [[idx, sent, score_sentence(sent)] for idx, sent in enumerate(sentences)]\n",
    "    scored_sentences = [s for s in scored_sentences if s[2] > 0] #filter out non-scoring sentences\n",
    "    scored_sentences.sort(key = lambda x: x[2], reverse = True)\n",
    "    top = scored_sentences[:n-1]\n",
    "    top.sort(key = lambda x: x[0])\n",
    "    scored_sentences.sort(key = lambda x: x[0])\n",
    "    result = None\n",
    "    if len(scored_sentences) == 0:\n",
    "        result = [sentences[0]]\n",
    "    else:\n",
    "        result = [scored_sentences[0][1]] + [s[1] for s in top]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_path_to_negating(graph, subjects):\n",
    "    \"\"\"\n",
    "    get the shortest path from each subject to any negating or doubting/hedging word\n",
    "    returns: dictionary with subject as key, and 2-element list of path lengths [negating, doubting]\n",
    "    - if a subject does not exist in graph or have a path to any negating word, then the value will be [None, None]\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for s in subjects:\n",
    "        results[s] = [None, None]\n",
    "        if graph.has_node(s):\n",
    "            for word in negating_words:\n",
    "                if word in graph:\n",
    "                    try:\n",
    "                        path = nx.shortest_path(graph, source = s, target = word)\n",
    "                        if results[s][0] == None or len(path) < results[s][0]:\n",
    "                            results[s][0] = len(path)\n",
    "                    except:\n",
    "                        continue\n",
    "            for word in sus_words:\n",
    "                if word in graph:\n",
    "                    try:\n",
    "                        path = nx.shortest_path(graph, source = s, target = word)\n",
    "                        if results[s][1] == None or len(path) < results[s][1]:\n",
    "                            results[s][1] = len(path)\n",
    "                    except:\n",
    "                        continue\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_distance(graph, root):\n",
    "    \"\"\"\n",
    "    as implemented in the Emergent paper - return the shortest distance between the given root and any \n",
    "    doubting or hedging words in the graph, or None if no such path exists\n",
    "    \"\"\"\n",
    "    if root == None:\n",
    "        return None\n",
    "    min_dist = None\n",
    "    for word in sus_words:\n",
    "        if word in graph:\n",
    "            try:\n",
    "                path = nx.shortest_path(graph, source = root, target = word)\n",
    "                if min_dist == None or len(path) < min_dist:\n",
    "                    min_dist = len(path)\n",
    "            except:\n",
    "                continue\n",
    "    return min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neg_ancestors(doc):\n",
    "    \"\"\"\n",
    "    get the ancestors of every negating word\n",
    "    input: spacy Doc\n",
    "    returns: tuple  - set of words that were in the ancestor list of negating words, \n",
    "    set of words that were in ancestor list of refuting words, # negating words, # refuting words\n",
    "    \"\"\"\n",
    "    results = [set(), set(), 0, 0]\n",
    "    for token in doc:\n",
    "        if token.lemma_.lower() in negating_words:\n",
    "            results[0] = results[0].union(\n",
    "                set([ancestor.lemma_.lower() for ancestor in token.ancestors if len(ancestor) > 2])\n",
    "            )\n",
    "            results[2] += 1\n",
    "        elif token.lemma_.lower() in sus_words:\n",
    "            results[1] = results[1].union(\n",
    "                set([ancestor.lemma_.lower() for ancestor in token.ancestors if len(ancestor) > 2])\n",
    "            )\n",
    "            results[3] += 1\n",
    "    return tuple(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# h_id = 25\n",
    "# df = agrees\n",
    "# test = nlp(preprocess(list(df.values)[h_id][0]))\n",
    "# print(test)\n",
    "# test_graph = build_graph(test)\n",
    "# test_subj = get_topics(test)\n",
    "# test_svo = get_svos(test)\n",
    "# print(get_shortest_path_to_negating(test_graph, test_subj))\n",
    "# print(test_subj, test_svo, list(test_svo[1].keys())[0])\n",
    "# print(root_distance(test_graph, list(test_svo[1].keys())[0]))\n",
    "# print(get_neg_ancestors(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# body_text = get_body(list(df.values)[h_id][1])\n",
    "# body = coref(preprocess(body_text))\n",
    "# resolved = body._.coref_resolved.lower()\n",
    "# body = nlp(resolved)\n",
    "# body_graph = build_graph(body)\n",
    "# summary = get_summary(body, test_subj, 5)\n",
    "# for s in summary:\n",
    "#     svo_s = get_svos(s)\n",
    "#     print(get_shortest_path_to_negating(body_graph, test_subj))\n",
    "#     print(svo_s)\n",
    "#     print(root_distance(body_graph, list(svo_s[1].keys())[0]))\n",
    "#     print(get_neg_ancestors(s))\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess headline and body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_graph():\n",
    "    headline_info = {}\n",
    "    body_info = {}\n",
    "    start = time.time()\n",
    "    stance_data = list(train_stances.values)\n",
    "    body_data = list(train_bodies.values)\n",
    "    for headline in range(len(stance_data)):\n",
    "        if headline % 2500 == 0:\n",
    "            print(\"Processed \"+str(headline))\n",
    "        h, b_id, s = tuple(stance_data[headline])\n",
    "        if h not in headline_info:\n",
    "            nlp_h = nlp(preprocess(h))\n",
    "            headline_graph = build_graph(nlp_h)\n",
    "            headline_subj = get_topics(nlp_h)\n",
    "            headline_svo = get_svos(nlp_h)\n",
    "            headline_root_dist = root_distance(headline_graph, list(headline_svo[1].keys())[0])\n",
    "            headline_neg_ancestors = get_neg_ancestors(nlp_h)\n",
    "            nqh = 0\n",
    "            for tok in nlp_h:\n",
    "                if tok.text == \"?\":\n",
    "                    nqh += 1\n",
    "            headline_info[h] = (nlp_h, headline_graph, headline_subj, headline_svo, headline_root_dist, headline_neg_ancestors, nqh)\n",
    "    print(\"Done with headlines!\")\n",
    "    for body in range(len(body_data)):\n",
    "        if body % 100 == 0:\n",
    "            print(\"Processed \"+str(body))\n",
    "        b_id, txt = tuple(body_data[body])\n",
    "        txt = preprocess(txt)\n",
    "        nlp_a = coref(preprocess(txt))\n",
    "        nlp_b = nlp(nlp_a._.coref_resolved.lower())\n",
    "        body_graph = build_graph(nlp_b)\n",
    "        nqb = 0\n",
    "        for tok in nlp_b:\n",
    "            if tok.text == \"?\":\n",
    "                nqb += 1\n",
    "        body_info[b_id] = (nlp_b, body_graph, nqb)\n",
    "    print(\"Done!\")\n",
    "    end = time.time()\n",
    "    print(int(end-start))\n",
    "    return headline_info, body_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no default __reduce__ due to non-trivial __cinit__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-92c5ab0e0161>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_data/headline_data.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpkl_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheadline_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpkl_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\cds\\lib\\site-packages\\spacy\\tokens\\token.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mspacy.tokens.token.Token.__reduce_cython__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no default __reduce__ due to non-trivial __cinit__"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0\n",
      "Processed 2500\n",
      "Processed 5000\n",
      "Processed 7500\n",
      "Processed 10000\n",
      "Processed 12500\n",
      "Done with headlines!\n",
      "Processed 0\n",
      "Processed 100\n",
      "Processed 200\n",
      "Processed 300\n",
      "Processed 400\n",
      "Processed 500\n",
      "Processed 600\n",
      "Processed 700\n",
      "Processed 800\n",
      "Processed 900\n",
      "Processed 1000\n",
      "Processed 1100\n",
      "Processed 1200\n",
      "Processed 1300\n",
      "Processed 1400\n",
      "Processed 1500\n",
      "Processed 1600\n",
      "Done!\n",
      "563\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "no default __reduce__ due to non-trivial __cinit__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-93a120c2eb97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_data/headline_data.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpkl_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mheadline_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkl_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_dat/body_data.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpkl_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-93a120c2eb97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mheadline_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_data/headline_data.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpkl_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheadline_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpkl_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_data/body_data.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpkl_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpkl_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\cds\\lib\\site-packages\\spacy\\tokens\\token.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mspacy.tokens.token.Token.__reduce_cython__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no default __reduce__ due to non-trivial __cinit__"
     ]
    }
   ],
   "source": [
    "headline_info = None\n",
    "body_info = None\n",
    "try:\n",
    "    with open('saved_data/headline_data.pkl', 'rb') as pkl_data:\n",
    "        headline_info = pickle.load(pkl_data)\n",
    "    with open('saved_dat/body_data.pkl', 'rb') as pkl_data:\n",
    "        body_info = pickle.load(pkl_data)\n",
    "    print(\"Had pickled files already, no problemo\")\n",
    "except:\n",
    "    headline_info, body_info = preprocess_graph()\n",
    "    with open('saved_data/headline_data.pkl', 'wb') as pkl_data:\n",
    "        pickle.dump(headline_info, pkl_data)\n",
    "    with open('saved_data/body_data.pkl', 'wb') as pkl_data:\n",
    "        pickle.dump(body_info, pkl_data)\n",
    "    print(\"Generated train/test data and created pickle files for future use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "body_graphs = {}\n",
    "for i in body_info:\n",
    "    body_graphs[i] = list(body_info[i][1].edges())\n",
    "with open('saved_data/body_graphs.json', 'w') as fp:\n",
    "    json.dump(body_graphs, fp)\n",
    "    \n",
    "headline_graphs = {}\n",
    "for i in headline_info:\n",
    "    headline_graphs[i] = list(headline_info[i][1].edges())\n",
    "with open('saved_data/headline_graphs.json', 'w') as fp:\n",
    "    json.dump(headline_graphs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vec(s):\n",
    "    vecs = [token.vector for token in s]\n",
    "    return np.nan_to_num(np.sum(vecs, axis = 0))\n",
    "\n",
    "def get_features(stance_df, n_sent = 5):\n",
    "    start = time.time()\n",
    "    data = list(stance_df.values)\n",
    "    features = []\n",
    "    actual = []\n",
    "    for item in data:\n",
    "        h, b, s = tuple(item)\n",
    "        headline, headline_graph, headline_subjs, headline_svo, headline_root_dist, headline_neg_ancestors, nq_h  = headline_info[h]\n",
    "        body, body_graph, nq_b = body_info[b]\n",
    "        \n",
    "        #sometimes the coref deletes bodies that are one sentence\n",
    "        if len(body) == 0:\n",
    "            body = nlp(preprocess(get_body(b)))\n",
    "            body_graph = build_graph(body)\n",
    "\n",
    "        #return the shortest path to negating word for each subject in headline_subjs, if one exists\n",
    "        neg_h = get_shortest_path_to_negating(headline_graph, headline_subjs)\n",
    "        neg_b = get_shortest_path_to_negating(body_graph, headline_subjs)\n",
    "\n",
    "        #body summary\n",
    "        summary = get_summary(body, headline_subjs, n_sent)\n",
    "        first_summ_sentence = summary[0]\n",
    "        \n",
    "        summary_svos = [get_svos(s) for s in summary]\n",
    "        summary_root_dist = [root_distance(body_graph, list(s[1].keys())[0]) for s in summary_svos]\n",
    "        summary_neg_ancestors = [get_neg_ancestors(s) for s in summary]\n",
    "        summary_neg_counts = [s[2:] for s in summary_neg_ancestors]\n",
    "        \n",
    "        #svo\n",
    "        body_s, body_v, body_o = {}, {}, {}\n",
    "        headline_s, headline_v, headline_o = headline_svo\n",
    "        for svo in summary_svos:\n",
    "            body_s.update(svo[0])\n",
    "            body_v.update(svo[1])\n",
    "            body_o.update(svo[2])\n",
    "        body_s_vec = list(np.sum([body_s[s].vector for s in body_s], axis = 0)) if len(body_s) > 0 else np.zeros(384)\n",
    "        body_v_vec = list(np.sum([body_v[s].vector for s in body_v], axis = 0)) if len(body_v) > 0 else np.zeros(384)\n",
    "        body_o_vec = list(np.sum([body_o[s].vector for s in body_o], axis = 0)) if len(body_o) > 0 else np.zeros(384)\n",
    "    \n",
    "        headline_s_vec = list(np.sum([headline_s[s].vector for s in headline_s], axis = 0)) if len(headline_s) > 0 else np.zeros(384)\n",
    "        headline_v_vec = list(np.sum([headline_v[s].vector for s in headline_v], axis = 0)) if len(headline_v) > 0 else np.zeros(384)\n",
    "        headline_o_vec = list(np.sum([headline_o[s].vector for s in headline_o], axis = 0)) if len(headline_o) > 0 else np.zeros(384)\n",
    "        \n",
    "        cos_sim_s = cosine_similarity(body_s_vec, headline_s_vec)\n",
    "        cos_sim_v = cosine_similarity(body_v_vec, headline_v_vec)\n",
    "        cos_sim_o = cosine_similarity(body_o_vec, headline_o_vec)\n",
    "        \n",
    "        #negating paths\n",
    "        headline_paths = [neg_h[x] for x in neg_h]\n",
    "        headline_neg_paths = [1 if x[0] != None else 0 for x in headline_paths] + [1]\n",
    "        headline_hedge_paths = [1 if x[1] != None else 0 for x in headline_paths] + [1]\n",
    "        body_paths = [neg_h[x] for x in neg_h]\n",
    "        body_neg_paths = [1 if x[0] != None else 0 for x in body_paths] + [1]\n",
    "        body_hedge_paths = [1 if x[1] != None else 0 for x in body_paths] + [1]\n",
    "        \n",
    "        neg_path_cos_sim = cosine_similarity(headline_neg_paths, body_neg_paths)\n",
    "        hedge_path_cos_sim = cosine_similarity(headline_hedge_paths, body_hedge_paths)\n",
    "        \n",
    "        #root distance\n",
    "        avg_summary_root_dist = None\n",
    "        non_null = [x for x in summary_root_dist if x != None]\n",
    "        if len(non_null) != 0:\n",
    "            avg_summary_root_dist = sum(non_null)/len(non_null)\n",
    "        root_dist_feats = [headline_root_dist, avg_summary_root_dist]\n",
    "        root_dist_feats = [x if x != None else 100 for x in root_dist_feats]\n",
    "    \n",
    "        #sentiment\n",
    "        headline_sent = get_sentiment(headline)\n",
    "        body_sents = [get_sentiment(s) for s in summary]\n",
    "        diff_sents = list(np.sum([get_diff_sentiment(headline_sent, s) for s in body_sents], axis = 0))\n",
    "        \n",
    "        #polarity\n",
    "        \n",
    "        headline_polar, headline_sentic = get_sentics(headline)\n",
    "        body_polars = [0 for s in range(len(summary))]\n",
    "        body_sentics = [[] for s in range(len(summary))]\n",
    "        for s in range(len(summary)): \n",
    "            body_polars[s], body_sentics[s] = get_sentics(summary[s])\n",
    "            body_sentics[s] = np.array(list(body_sentics[s]))\n",
    "        #body_sentics = np.mean(body_sentics, axis=0)\n",
    "        headline_sentic = (list(headline_sentic))\n",
    "        # Right now just an array of differences across each sentence, could be just the average\n",
    "        diff_polars = [np.absolute(headline_polar - s) for s in body_polars]\n",
    "        diff_sentics = list(np.sum([get_diff_sentiment(headline_sentic, s) for s in body_sentics], axis = 0))\n",
    "        #print(f'Diff Polar:${diff_polars} Diff Sentics:{diff_sentics}')\n",
    "        \"\"\"print(headline, summary)\n",
    "        print('headline sent', headline_sentic)\n",
    "        print('diff sent', diff_sentics)\n",
    "        print('headline_polar', headline_polar)\n",
    "        print(\"diff polars\", diff_polars)\"\"\"\n",
    "        \n",
    "        #bow\n",
    "        headline_vocab = set([tok.lemma_.lower() for tok in headline])\n",
    "        fst_summ_vocab = set([tok.lemma_.lower() for tok in first_summ_sentence])\n",
    "        total_vocab = list(headline_vocab.union(fst_summ_vocab))\n",
    "        headline_embedding = [1 if tok in headline_vocab else 0 for tok in total_vocab]\n",
    "        fst_summ_embedding = [1 if tok in fst_summ_vocab else 0 for tok in total_vocab]\n",
    "        bow_cos_sim = cosine_similarity(headline_embedding, fst_summ_embedding)\n",
    "        \n",
    "        #word vecs\n",
    "        cos_sims = [cosine_similarity(get_sentence_vec(s), headline.vector) for s in summary]\n",
    "        fst_cos_sim = cos_sims[0]\n",
    "        avg_cos_sim = sum(cos_sims)/len(cos_sims)\n",
    "        \n",
    "        #build final features list\n",
    "        fts = (\n",
    "            [fst_cos_sim, avg_cos_sim, bow_cos_sim, \n",
    "               neg_path_cos_sim, hedge_path_cos_sim, \n",
    "               cos_sim_s, cos_sim_v, cos_sim_o, nq_h, nq_b] + \n",
    "            headline_sent + diff_sents + headline_sentic + diff_sentics + diff_polars\n",
    "            + root_dist_feats + \n",
    "            list(headline_neg_ancestors[2:]) + list(np.sum(summary_neg_counts, axis = 0))\n",
    "        )\n",
    "        features.append(fts)\n",
    "        actual.append(s)\n",
    "    end = time.time()\n",
    "    print(int(end-start))\n",
    "    return features, actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features from headline/body pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\AppData\\Local\\Continuum\\anaconda3\\envs\\cds\\lib\\site-packages\\scipy\\spatial\\distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "stance_data = get_features(train_stances, 5)\n",
    "stance_dict = {}\n",
    "for idx, d in enumerate(list(train_stances.values)):\n",
    "    h, b, s = d\n",
    "    stance_dict[(h, b)] = stance_data[0][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiple(models, samplings = []):\n",
    "    \"\"\"\n",
    "    helper function for training on models\n",
    "    this isn't true K-fold CV because of the way we do our splits and augmentation\n",
    "    models: a list of instantiated models\n",
    "    sampling: list of 3 ints, representing how much we should oversample agree, disagree, discuss\n",
    "            for example, [1,1,2] will sample each discuss item twice\n",
    "    \"\"\"\n",
    "    stances_tr, stances_val = train_test_split(train_bodies, train_stances)\n",
    "    disagrees = stances_tr[stances_tr[\"Stance\"]==\"disagree\"]\n",
    "    agrees = stances_tr[stances_tr[\"Stance\"]==\"agree\"]\n",
    "    discusses = stances_tr[stances_tr[\"Stance\"]==\"discuss\"]\n",
    "    for m in range(len(models)):\n",
    "        sampling = samplings[m]\n",
    "        model = models[m]\n",
    "        print(\"Model \"+str(m + 1))\n",
    "        data = []\n",
    "        for i in range(sampling[0]):\n",
    "            data.append(agrees)\n",
    "        for i in range(sampling[1]):\n",
    "            data.append(disagrees)\n",
    "        for i in range(sampling[2]):\n",
    "            data.append(discusses)\n",
    "        stances_tr_augmented = pd.concat(data).sample(frac=1).reset_index(drop=True)\n",
    "        training_data = [[],[]]\n",
    "        for h,b,s in list(stances_tr_augmented.values):\n",
    "            training_data[0].append(stance_dict[(h,b)])\n",
    "            training_data[1].append(s)\n",
    "        testing_data = [[],[]]\n",
    "        for h,b,s in list(stances_val.values):\n",
    "            testing_data[0].append(stance_dict[(h,b)])\n",
    "            testing_data[1].append(s)\n",
    "        c1, c2 = Counter(training_data[1]), Counter(testing_data[1])\n",
    "        baseline_tr = max([c1['agree'],c1['disagree'],c1['discuss']])/(c1['agree']+c1['disagree']+c1['discuss'])\n",
    "        baseline_val = max([c2['agree'],c2['disagree'],c2['discuss']])/(c2['agree']+c2['disagree']+c2['discuss'])\n",
    "        print(\"Training Baseline {0:.2f}% Testing Baseline {1:.2f}%\".format(baseline_tr * 100, baseline_val * 100))\n",
    "        model.fit(training_data[0], training_data[1])\n",
    "        tr_acc = model.score(training_data[0], training_data[1])\n",
    "        print('{0:.2f}% training accuracy, vs Baseline {1:.2f}%'.format(tr_acc*100, (tr_acc-baseline_tr)*100))\n",
    "        val_acc = model.score(testing_data[0], testing_data[1])\n",
    "        print('{0:.2f}% validation accuracy, vs Baseline {1:.2f}%'.format(val_acc*100, (val_acc-baseline_val)*100))\n",
    "    training_data = [[],[]]\n",
    "    for h,b,s in list(stances_tr.values):\n",
    "        training_data[0].append(stance_dict[(h,b)])\n",
    "        training_data[1].append(s)\n",
    "    testing_data = [[],[]]\n",
    "    for h,b,s in list(stances_val.values):\n",
    "        testing_data[0].append(stance_dict[(h,b)])\n",
    "        testing_data[1].append(s)\n",
    "    fold_data = training_data, testing_data\n",
    "    print(\"done!\")\n",
    "    return models, fold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiple_subjective(models, samplings = []):\n",
    "    \"\"\"\n",
    "    helper function for training on models\n",
    "    this isn't true K-fold CV because of the way we do our splits and augmentation\n",
    "    models: a list of instantiated models\n",
    "    sampling: list of 3 ints, representing how much we should oversample agree, disagree, discuss\n",
    "            for example, [1,1,2] will sample each discuss item twice\n",
    "    \"\"\"\n",
    "    stances_tr, stances_val = train_test_split(train_bodies, train_stances)\n",
    "    subjective =stances_tr[stances_tr[\"Stance\"]!=\"discuss\"]\n",
    "    objective = stances_tr[stances_tr[\"Stance\"]==\"discuss\"]\n",
    "    for m in range(len(models)):\n",
    "        sampling = samplings[m]\n",
    "        model = models[m]\n",
    "        print(\"\\nModel \"+str(m + 1))\n",
    "        data = []\n",
    "        for i in range(sampling[0]):\n",
    "            data.append(subjective)\n",
    "        for i in range(sampling[1]):\n",
    "            data.append(objective)\n",
    "        stances_tr_augmented = pd.concat(data).sample(frac=1).reset_index(drop=True)\n",
    "        training_data = [[],[]]\n",
    "        for h,b,s in list(stances_tr_augmented.values):\n",
    "            training_data[0].append(stance_dict[(h,b)])\n",
    "            training_data[1].append(s)\n",
    "        testing_data = [[],[]]\n",
    "        for h,b,s in list(stances_val.values):\n",
    "            testing_data[0].append(stance_dict[(h,b)])\n",
    "            testing_data[1].append(s)\n",
    "        c1, c2 = Counter(training_data[1]), Counter(testing_data[1])\n",
    "        \n",
    "        baseline_tr = max([c1['agree']+c1['disagree'],c1['discuss']])/(c1['agree']+c1['disagree']+c1['discuss'])\n",
    "        baseline_val = max([c2['agree']+c2['disagree'],c2['discuss']])/(c2['agree']+c2['disagree']+c2['discuss'])\n",
    "\n",
    "        print(\"Training Baseline {0:.2f}% Testing Baseline {1:.2f}%\".format(baseline_tr * 100, baseline_val * 100))\n",
    "        model.fit(training_data[0], training_data[1])\n",
    "        tr_acc = model.score(training_data[0], training_data[1])\n",
    "        print('{0:.2f}% training accuracy, vs Baseline {1:.2f}%'.format(tr_acc*100, (tr_acc-baseline_tr)*100))\n",
    "        val_acc = model.score(testing_data[0], testing_data[1])\n",
    "        print('{0:.2f}% validation accuracy, vs Baseline {1:.2f}%'.format(val_acc*100, (val_acc-baseline_val)*100))\n",
    "    training_data = [[],[]]\n",
    "    for h,b,s in list(stances_tr.values):\n",
    "        training_data[0].append(stance_dict[(h,b)])\n",
    "        training_data[1].append(s)\n",
    "    testing_data = [[],[]]\n",
    "    for h,b,s in list(stances_val.values):\n",
    "        testing_data[0].append(stance_dict[(h,b)])\n",
    "        testing_data[1].append(s)\n",
    "    fold_data = training_data, testing_data\n",
    "    print(\"done!\")\n",
    "    return models, fold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(30):\n",
    "#     print(np.size(training_data[0][i][0]))\n",
    "# for i in range(len(training_data[0][0])):\n",
    "#     r = []\n",
    "#     for row in training_data[0]:\n",
    "#         r.append(row[i])\n",
    "#     print(r[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_int(labels):\n",
    "    return [(1 if l == \"agree\" else (0 if l == \"discuss\" else -1)) for l in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling = [2,1]\n",
    "\n",
    "def test_simple(model, sampling=[]):\n",
    "    stances_tr, stances_val = train_test_split(train_bodies, train_stances)\n",
    "    subjective = stances_tr[stances_tr[\"Stance\"] != \"discuss\"].sample(frac=sampling[0], replace = True).reset_index(drop=True)\n",
    "    objective = stances_tr[stances_tr[\"Stance\"] == \"discuss\"].sample(frac=sampling[1], replace = True).reset_index(drop=True)\n",
    "\n",
    "    subjective[\"Stance\"] = \"subj\"\n",
    "    objective[\"Stance\"] = \"obj\"\n",
    "    stances_val['Stance'].replace({'agree':'subj', 'disagree':'subj','discuss':'obj'}, inplace=True)\n",
    "    stances_tr['Stance'].replace({'agree':'subj', 'disagree':'subj','discuss':'obj'}, inplace=True)\n",
    "    \n",
    "    stances_tr_augmented = pd.concat((subjective,objective)).sample(frac=1).reset_index(drop=True)\n",
    "    training_data = [[],[]]\n",
    "\n",
    "    for h,b,s in list(stances_tr_augmented.values):\n",
    "        training_data[0].append(stance_dict[(h,b)])\n",
    "        training_data[1].append(s)\n",
    "    testing_data = [[],[]]\n",
    "    for h,b,s in list(stances_val.values):\n",
    "        testing_data[0].append(stance_dict[(h,b)])\n",
    "        testing_data[1].append(s)\n",
    "    c1, c2 = Counter(training_data[1]), Counter(testing_data[1])\n",
    "\n",
    "    print(c1, c2)\n",
    "\n",
    "    baseline_tr = max([c1['subj'], c1['obj']])/(c1['subj'] + c1['obj'])\n",
    "    baseline_val = max([c2['subj'], c2['obj']])/(c2['subj'] + c2['obj'])\n",
    "\n",
    "    print(\"Training Baseline {0:.2f}% Testing Baseline {1:.2f}%\".format(baseline_tr * 100, baseline_val * 100))\n",
    "\n",
    "    model.fit(training_data[0], training_data[1])\n",
    "    tr_acc = model.score(training_data[0], training_data[1])\n",
    "    print('{0:.2f}% training accuracy'.format(tr_acc*100))\n",
    "\n",
    "    val_acc = model.score(testing_data[0], testing_data[1])\n",
    "    print('{0:.2f}% validation accuracy'.format(val_acc*100))\n",
    "    print(\"Baseline comparison: TR {0:.2f}% VAL {1:.2f}%\".format((tr_acc-baseline_tr)*100,(val_acc-baseline_val)*100))\n",
    "\n",
    "    actual = testing_data[1]\n",
    "    predicted = model.predict(testing_data[0])\n",
    "    # actual = actual + [\"unrelated\"] * 7500\n",
    "    # predicted = np.concatenate((predicted, [\"unrelated\"] * 7500),axis = 0)\n",
    "\n",
    "    print(\"F1 Score\")\n",
    "    print(f1_score(actual, predicted, average = None))\n",
    "    print(\"Avg Precision Score\")\n",
    "    print(precision_score(actual, predicted, average = None))\n",
    "    \n",
    "    return actual, predicted, stances_tr, stances_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\AppData\\Local\\Continuum\\anaconda3\\envs\\cds\\lib\\site-packages\\pandas\\core\\generic.py:6586: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'obj': 7108, 'subj': 3577}) Counter({'obj': 1801, 'subj': 941})\n",
      "Training Baseline 66.52% Testing Baseline 65.68%\n",
      "74.89% training accuracy\n",
      "68.34% validation accuracy\n",
      "Baseline comparison: TR 8.37% VAL 2.66%\n",
      "F1 Score\n",
      "[0.79479905 0.30781499]\n",
      "Avg Precision Score\n",
      "[0.69205434 0.61661342]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\AppData\\Local\\Continuum\\anaconda3\\envs\\cds\\lib\\site-packages\\pandas\\core\\generic.py:6586: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'subj': 7394, 'obj': 7153}) Counter({'obj': 1756, 'subj': 821})\n",
      "Training Baseline 50.83% Testing Baseline 68.14%\n",
      "77.62% training accuracy\n",
      "62.40% validation accuracy\n",
      "Baseline comparison: TR 26.80% VAL -5.74%\n",
      "F1 Score\n",
      "[0.67903279 0.54613583]\n",
      "Avg Precision Score\n",
      "[0.81155978 0.44368341]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\AppData\\Local\\Continuum\\anaconda3\\envs\\cds\\lib\\site-packages\\pandas\\core\\generic.py:6586: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'subj': 7320, 'obj': 7100}) Counter({'obj': 1809, 'subj': 858})\n",
      "Training Baseline 50.76% Testing Baseline 67.83%\n",
      "76.62% training accuracy\n",
      "68.58% validation accuracy\n",
      "Baseline comparison: TR 25.85% VAL 0.75%\n",
      "F1 Score\n",
      "[0.7449787  0.59082031]\n",
      "Avg Precision Score\n",
      "[0.82870684 0.50840336]\n"
     ]
    }
   ],
   "source": [
    "samplings = [[2, 1,], [1,1]]\n",
    "\n",
    "model1 = GradientBoostingClassifier(n_estimators = 500, subsample = 0.1, learning_rate = 0.01, random_state=0)\n",
    "actual1, predicted1, tr1, val1 = test_simple(model1, [1, 1])\n",
    "\n",
    "model2 = RandomForestClassifier(n_estimators = 400, max_depth = 7, min_samples_leaf = 3)\n",
    "actual2, predicted2, tr2, val2 = test_simple(model2, samplings[0])\n",
    "\n",
    "model3 = RandomForestClassifier(n_estimators = 400, max_depth = 7)\n",
    "actual3, predicted3, tr3, val3 = test_simple(model3, samplings[0])\n",
    "\n",
    "\"\"\"model3 = LogisticRegression(solver='lbfgs')\n",
    "actual3, predicted3 = test_simple(model3,samplings[0])\n",
    "\n",
    "model4 = SVC(gamma='scale')\n",
    "actual4, predicted4 = test_simple(model4,samplings[0])\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[1681  120]\n",
      " [ 748  193]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ae0c21d6d8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix_local(actual1, predicted1, classes=['obj', \"subj\"], normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.67661692 0.32338308]\n",
      " [0.29487179 0.70512821]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ae0c3b3908>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix_local(actual3, predicted3, classes=['obj', \"subj\"], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = SVC(gamma=\"scale\")\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "test_simple(clf, samplings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_predictions(row):\n",
    "    if((row[\"Stance\"]==\"agree\" or row[\"Stance\"]==\"disagree\") and row[\"predict\"]==\"subj\"): return True\n",
    "    elif(row[\"Stance\"]==\"discuss\" and row[\"predict\"]==\"obj\"): return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape before filter out classified obj (13427, 5)\n",
      "data shape after (9681, 5)\n"
     ]
    }
   ],
   "source": [
    "data = pd.merge(train_bodies, train_stances)\n",
    "training_data = []\n",
    "for bid, b, h, s in list(data.values):\n",
    "    training_data.append(stance_dict[(h,bid)])\n",
    "    #training_data[1].append(s)\n",
    "\n",
    "predict = model3.predict(training_data)\n",
    "data[\"predict\"] = predict\n",
    "print(\"data shape before filter out classified obj\", data.shape)\n",
    "\n",
    "data_filtered = data[data.apply(filter_predictions, axis=1)]\n",
    "print(\"data shape after\", data_filtered.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
