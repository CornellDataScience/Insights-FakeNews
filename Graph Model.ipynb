{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import networkx as nx\n",
    "import score as sc\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, pairwise, f1_score, precision_score\n",
    "from scipy.spatial import distance\n",
    "from preprocessing.utils import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from collections import Counter, defaultdict\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import torch\n",
    "import importlib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "importlib.reload(sys.modules['preprocessing.utils'])\n",
    "from preprocessing.utils import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://github.com/huggingface/neuralcoref\n",
    "#note: this NEEDS spacy 2.0.12 to work! downgrade with pip install spacy=2.0.12\n",
    "import en_coref_md\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "coref = en_coref_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negating_words = set([\n",
    "    \"n't\", \"not\", \"no\", \n",
    "    \"never\", \"nobody\", \"non\", \"nope\"])\n",
    "doubting_words = set([\n",
    "    'fake','fraud', 'hoax', \n",
    "    'false', 'deny', 'denies', \n",
    "    'despite', 'doubt', \n",
    "    'bogus', 'debunk', 'prank', \n",
    "    'retract', 'scam', \"withdrawn\",\n",
    "    \"misinformation\"])\n",
    "hedging_words = set([\n",
    "    'allege', 'allegedly','apparently',\n",
    "    'appear','claim','could',\n",
    "    'evidently','largely','likely',\n",
    "    'mainly','may', 'maybe', 'might',\n",
    "    'mostly','perhaps','presumably',\n",
    "    'probably','purport', 'purportedly',\n",
    "    'reported', 'reportedly',\n",
    "    'rumor', 'rumour', 'rumored', 'rumoured',\n",
    "    'says','seem','somewhat',\n",
    "    'unconfirmed'])\n",
    "sus_words = doubting_words.union(hedging_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(sentence):\n",
    "    sent =  vader.polarity_scores(sentence.text)\n",
    "    return [sent[\"pos\"],sent[\"neg\"],sent[\"neu\"],sent[\"compound\"]]\n",
    "\n",
    "def get_avg_sentiment(lst):\n",
    "    sents = np.array([get_sentiment(s) for s in lst])\n",
    "    return list(np.mean(sents, axis = 0))\n",
    "\n",
    "def get_diff_sentiment(a,b):\n",
    "    return list(np.absolute(np.array(a) - np.array(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(bodies, stances, split=0.8):\n",
    "    idx = np.random.permutation(np.arange(len(bodies)))\n",
    "    bodies = bodies.values[idx]\n",
    "    train = int(len(bodies)*0.8)\n",
    "    bodies_tr = set([i[0] for i in bodies[:train]])\n",
    "    bodies_val = set([i[0] for i in bodies[train:]])\n",
    "    stances_tr = stances.loc[stances[\"Body ID\"].isin(bodies_tr), :]\n",
    "    stances_val = stances.loc[stances[\"Body ID\"].isin(bodies_val), :]\n",
    "    return stances_tr, stances_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13427, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'Nasa Confirms Earth Will Experience 6 Days of...</td>\n",
       "      <td>154</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Banksy 'Arrested &amp; Real Identity Revealed' Is ...</td>\n",
       "      <td>1739</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gateway Pundit</td>\n",
       "      <td>2327</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Woman detained in Lebanon is not al-Baghdadi's...</td>\n",
       "      <td>1468</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Soon Marijuana May Lead to Ticket, Not Arrest,...</td>\n",
       "      <td>47</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Boko Haram Denies Nigeria Cease-Fire Claim</td>\n",
       "      <td>2463</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>No, Robert Plant Didn’t Rip Up an $800 Million...</td>\n",
       "      <td>295</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ISIL Beheads American Photojournalist in Iraq</td>\n",
       "      <td>608</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Boko Haram ceasefire ignored as violence flare...</td>\n",
       "      <td>1681</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NET Extra: Back-from-the-dead Catholic priest ...</td>\n",
       "      <td>1014</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Rumor debunked: RoboCop-style robots are not p...</td>\n",
       "      <td>633</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Report: Christian Bale Just Bailed on the Stev...</td>\n",
       "      <td>1157</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Insurgents killed in Nigeria despite alleged t...</td>\n",
       "      <td>1896</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline  Body ID    Stance\n",
       "1   Hundreds of Palestinians flee floods in Gaza a...      158     agree\n",
       "4   Spider burrowed through tourist's stomach and ...     1923  disagree\n",
       "5   'Nasa Confirms Earth Will Experience 6 Days of...      154     agree\n",
       "8   Banksy 'Arrested & Real Identity Revealed' Is ...     1739     agree\n",
       "10                                     Gateway Pundit     2327   discuss\n",
       "11  Woman detained in Lebanon is not al-Baghdadi's...     1468     agree\n",
       "14  Soon Marijuana May Lead to Ticket, Not Arrest,...       47   discuss\n",
       "16         Boko Haram Denies Nigeria Cease-Fire Claim     2463   discuss\n",
       "17  No, Robert Plant Didn’t Rip Up an $800 Million...      295     agree\n",
       "19      ISIL Beheads American Photojournalist in Iraq      608   discuss\n",
       "21  Boko Haram ceasefire ignored as violence flare...     1681   discuss\n",
       "24  NET Extra: Back-from-the-dead Catholic priest ...     1014     agree\n",
       "25  Rumor debunked: RoboCop-style robots are not p...      633     agree\n",
       "29  Report: Christian Bale Just Bailed on the Stev...     1157   discuss\n",
       "31  Insurgents killed in Nigeria despite alleged t...     1896   discuss"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stances = pd.read_csv(\"fn_data/train_stances.csv\")\n",
    "train_stances = train_stances.loc[lambda x: x.Stance != \"unrelated\"]\n",
    "print(train_stances.shape)\n",
    "train_stances.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1683, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody\n",
       "0        0  A small meteorite crashed into a wooded area i...\n",
       "1        4  Last week we hinted at what was to come as Ebo...\n",
       "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...\n",
       "3        6  Posting photos of a gun-toting child online, I...\n",
       "4        7  At least 25 suspected Boko Haram insurgents we..."
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bodies = pd.read_csv(\"fn_data/train_bodies.csv\")\n",
    "print(train_bodies.shape)\n",
    "train_bodies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10964, 3), (2463, 3))"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagrees = stances_tr[stances_tr[\"Stance\"]==\"disagree\"]\n",
    "agrees = stances_tr[stances_tr[\"Stance\"]==\"agree\"]\n",
    "discusses = stances_tr[stances_tr[\"Stance\"]==\"discuss\"]\n",
    "stances_tr_augmented = pd.concat([stances_tr, agrees, disagrees, disagrees, disagrees, disagrees, disagrees, disagrees]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_body(n):\n",
    "    return train_bodies.loc[lambda x: x[\"Body ID\"] == n, \"articleBody\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.replace(\"' \",' ')\n",
    "    text = text.replace(\" '\",' ')\n",
    "    text = text.replace(\":\", \". \")\n",
    "    text = text.replace(\";\", \". \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(x,y):\n",
    "    return 1 - np.nan_to_num(distance.cosine(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_topics(doc):\n",
    "    \"\"\"\n",
    "    get topics of a sentence\n",
    "    input: spacy doc\n",
    "    output: dictionary with nouns as the key, and the set of noun chunks that contain the noun as the value\n",
    "    special entry _vocab has the set of all tokens in the dict\n",
    "    \"\"\"\n",
    "    subjs = {}\n",
    "    for token in doc:\n",
    "        if token.dep_ in [\"nsubj\", \"nsubjpass\", \"csubj\",\"csubjpass\", \"dobj\", \"dative\", \"attr\", \"oprd\", \"pobj\", \"compound\"]:\n",
    "            txt = token.lemma_.lower()\n",
    "            if txt not in subjs:\n",
    "                subjs[txt] = set([txt])      \n",
    "    for chunk in doc.noun_chunks:\n",
    "        if len(chunk.root.text) > 2:\n",
    "            txt = chunk.root.text.lower()\n",
    "            if txt not in subjs:\n",
    "                subjs[txt] = set([txt])\n",
    "            subjs[txt].add(chunk.text.lower())\n",
    "    subjects_= []\n",
    "    for word in subjs:\n",
    "        for phrase in subjs[word]:\n",
    "            subjects_ += phrase.split(\" \")\n",
    "    subjs[\"_vocab\"] = set(subjects_)\n",
    "    return subjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_svos(sent):\n",
    "    \"\"\"\n",
    "    input: Spacy processed sentence\n",
    "    output: dict of subj, dict of v, dict of obj (each word is lemmatized and lowercased)\n",
    "    each entry in dict has key of lemmatized token, value is actual token (to do traversals with later if needed)\n",
    "    \"\"\"\n",
    "    s = {}\n",
    "    v = {}\n",
    "    o = {}\n",
    "    for token in sent:\n",
    "        if token.dep_ == 'ROOT':\n",
    "            v[token.lemma_.lower()] = token\n",
    "        elif token.dep_ in [\"nsubj\", \"nsubjpass\", \"csubj\",\"csubjpass\", \"agent\",\"compound\"]:\n",
    "            s[token.lemma_.lower()] = token\n",
    "        elif token.dep_ in [\"dobj\", \"dative\", \"attr\", \"oprd\", \"pobj\"]:\n",
    "            o[token.lemma_.lower()] = token\n",
    "    # https://github.com/clir/clearnlp-guidelines/blob/master/md/specifications/dependency_labels.md\n",
    "    return (s,v,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_graph(doc):\n",
    "    \"\"\"\n",
    "    build a NetworkX graph of the dependency tree\n",
    "    input: spacy Doc\n",
    "    output: networkx graph\n",
    "    \"\"\"\n",
    "    edges = set()\n",
    "    for token in doc:\n",
    "        for child in token.children:\n",
    "            edges.add((token.lemma_.lower(),child.lemma_.lower()))\n",
    "    graph = nx.DiGraph(list(edges))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_summary(doc, subjects, n = 5):\n",
    "    \"\"\"\n",
    "    get summary of n sentences in document\n",
    "    first meaningful sentence will always be returned\n",
    "    \"\"\"\n",
    "    subjects_ = subjects[\"_vocab\"]\n",
    "    def score_sentence(sent):\n",
    "        # not very robust right now\n",
    "        score = 0\n",
    "        word_count = 0\n",
    "        for token in sent:\n",
    "            word_count += 1\n",
    "            t = token.lemma_.lower()\n",
    "            if t in subjects_:\n",
    "                score += 1\n",
    "            elif t in negating_words or t in doubting_words or t in hedging_words:\n",
    "                score += 0.5\n",
    "            return score/word_count if word_count > 4 else 0\n",
    "    sentences = [s for s in doc.sents]\n",
    "    scored_sentences = [[idx, sent, score_sentence(sent)] for idx, sent in enumerate(sentences)]\n",
    "    # scored_sentences = [s for s in scored_sentences if s[2] > 0] #filter out non-scoring sentences\n",
    "    scored_sentences.sort(key = lambda x: x[2], reverse = True)\n",
    "    top = scored_sentences[:n-1]\n",
    "    top.sort(key = lambda x: x[0])\n",
    "    result = [scored_sentences[0][1]] + [s[1] for s in top]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_shortest_path_to_negating(graph, subjects):\n",
    "    \"\"\"\n",
    "    get the shortest path from each subject to any negating or doubting/hedging word\n",
    "    returns: dictionary with subject as key, and 2-element list of path lengths [negating, doubting]\n",
    "    - if a subject does not exist in graph or have a path to any negating word, then the value will be [None, None]\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for s in subjects:\n",
    "        results[s] = [None, None]\n",
    "        if graph.has_node(s):\n",
    "            for word in negating_words:\n",
    "                if word in graph:\n",
    "                    try:\n",
    "                        path = nx.shortest_path(graph, source = s, target = word)\n",
    "                        if results[s][0] == None or len(path) < results[s][0]:\n",
    "                            results[s][0] = len(path)\n",
    "                    except:\n",
    "                        continue\n",
    "            for word in sus_words:\n",
    "                if word in graph:\n",
    "                    try:\n",
    "                        path = nx.shortest_path(graph, source = s, target = word)\n",
    "                        if results[s][1] == None or len(path) < results[s][1]:\n",
    "                            results[s][1] = len(path)\n",
    "                    except:\n",
    "                        continue\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def root_distance(graph, root):\n",
    "    \"\"\"\n",
    "    as implemented in the Emergent paper - return the shortest distance between the given root and any \n",
    "    doubting or hedging words in the graph, or None if no such path exists\n",
    "    \"\"\"\n",
    "    if root == None:\n",
    "        return None\n",
    "    min_dist = None\n",
    "    for word in sus_words:\n",
    "        if word in graph:\n",
    "            try:\n",
    "                path = nx.shortest_path(graph, source = root, target = word)\n",
    "                if min_dist == None or len(path) < min_dist:\n",
    "                    min_dist = len(path)\n",
    "            except:\n",
    "                continue\n",
    "    return min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_neg_ancestors(doc):\n",
    "    \"\"\"\n",
    "    get the ancestors of every negating word\n",
    "    input: spacy Doc\n",
    "    returns: tuple  - set of words that were in the ancestor list of negating words, \n",
    "    set of words that were in ancestor list of refuting words, # negating words, # refuting words\n",
    "    \"\"\"\n",
    "    results = [set(), set(), 0, 0]\n",
    "    for token in doc:\n",
    "        if token.lemma_.lower() in negating_words:\n",
    "            results[0] = results[0].union(\n",
    "                set([ancestor.lemma_.lower() for ancestor in token.ancestors if len(ancestor) > 2])\n",
    "            )\n",
    "            results[2] += 1\n",
    "        elif token.lemma_.lower() in sus_words:\n",
    "            results[1] = results[1].union(\n",
    "                set([ancestor.lemma_.lower() for ancestor in token.ancestors if len(ancestor) > 2])\n",
    "            )\n",
    "            results[3] += 1\n",
    "    return tuple(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bugatti Veyron Vandalized With Penis Graffiti? Viral Photo Isn’t What It Seems\n",
      "{'bugatti': [None, None], 'veyron': [None, None], 'penis': [None, None], 'graffiti': [None, None], 'viral': [None, None], 'photo': [None, None], 'what': [None, None], '-pron-': [None, None], '_vocab': [None, None]}\n",
      "{'bugatti': {'bugatti'}, 'veyron': {'bugatti veyron', 'veyron'}, 'penis': {'penis'}, 'graffiti': {'penis graffiti', 'graffiti'}, 'viral': {'viral'}, 'photo': {'viral photo', 'photo'}, 'what': {'what'}, '-pron-': {'-pron-'}, '_vocab': {'what', 'bugatti', 'veyron', '-pron-', 'graffiti', 'penis', 'viral', 'photo'}} ({'bugatti': Bugatti, 'veyron': Veyron, 'penis': Penis, 'viral': Viral, 'photo': Photo, '-pron-': It}, {'vandalized': Vandalized, 'be': Is}, {'graffiti': Graffiti, 'what': What}) vandalized\n",
      "None\n",
      "(set(), set(), 1, 1)\n"
     ]
    }
   ],
   "source": [
    "h_id = 20\n",
    "df = agrees\n",
    "test = nlp(preprocess(list(df.values)[h_id][0]))\n",
    "print(test)\n",
    "test_graph = build_graph(test)\n",
    "test_subj = get_topics(test)\n",
    "test_svo = get_svos(test)\n",
    "print(get_shortest_path_to_negating(test_graph, test_subj))\n",
    "print(test_subj, test_svo, list(test_svo[1].keys())[0])\n",
    "print(root_distance(test_graph, list(test_svo[1].keys())[0]))\n",
    "print(get_neg_ancestors(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An image of a gold Bugatti Veyron graffitied with a drawing of a penis may have upset car lovers - but An image of a gold Bugatti Veyron graffitied with a drawing of a penis turns out the vehicle was included in a YouTube hoax.\n",
      "\n",
      "Photos from multiple Instagram accounts have revealed the vehicle wasn't permanently damaged.\n",
      "\n",
      "Instagram user @andreysmygov uploaded a photo last Friday of the Veyron with a caption that suggested it was painted on as a stunt for TwinzTV, Car Crushing noted.\n",
      "\n",
      "Scroll down for video\n",
      "\n",
      "Graffitied.  A photo of the Veyron the Veyron was reportedly taken in Seattle, according to a Reddit post\n",
      "\n",
      "Busted.  A photo of the vandalised Bugatti Veyron included a caption suggesting the car was spray-painted as a stunt with TwinzTV\n",
      "\n",
      "'How often do u get to spray paint on a Bugatti lol shoutout to the homie @vgtorious for letting us @twinztv1 @twinztv2 @twinz_tv @nigxl @alexwood66, @alexwood66 wrote online.\n",
      "\n",
      "Brothers Jeremy and Jason Holden run the YouTube pranks channel TwinzTV.\n",
      "\n",
      "A Saturday photo @andreysmygov shows user @vgtorious standing next to the Veyron, this time with different graffiti.\n",
      "\n",
      "Instead of a drawing of male genitalia, there is graffiti of the initials VG'\n",
      "\n",
      "A Sunday photo from \n",
      "\n",
      " account shows both @andreysmygov and @vgotorious leaning on a scrubbed-clean Veyron, suggesting the luxury vehicle no longer features any markings.\n",
      "\n",
      "'Filming new vid with @vgtorious this one is going to be sick! #vgproductions #bugatti @andreysmygov captioned the photograph.\n",
      "\n",
      "A photo of the car being waxed - with no graffitti visible - was posted by @vgtorious to Instagram on Saturday, though it is not clear when that took place.\n",
      "\n",
      "Different drawing.  A second photo @andreysmygov's account shows different graffitti on the hood of the Veyron\n",
      "\n",
      "He also re-grammed the photograph showing He next to the with the letters VG on the hood, confirming the hoax.\n",
      "\n",
      "'Oops I think we pranked the WORLD and the video hasn't aired...yet �� #bugatti #veyron #vw #youtube #global #news #pranks #funny #bugattifamilyimsorry', �� #bugatti #veyron #vw #youtube #global #news #pranks #funny #bugattifamilyimsorry' captioned the snap.\n",
      "\n",
      "Jeremy Holden also uploaded a snap of the penis drawing on the Veyron on Saturday.\n",
      "\n",
      "Jeremy Holden wrote, I got to spray paint this on @vgtorious #buggati today haha #prank #twinztv #youtube #funny #seattle with @_twinztv_ @twinztv2 @andreysmygov.'\n",
      "\n",
      "TwinzTV already featured the Veyron in an August YouTube video, Car Crushing pointed out.\n",
      "\n",
      "In that clip, a man leans against the Veyron picking up women, with a much less expensive silver car parked behind a man.\n",
      "\n",
      "When a man convinces the women to get food with a man, all but one leave when the women realize a man is not the Veyron's actual owner - and actually owns the silver car.\n",
      "\n",
      "[An image of a gold Bugatti Veyron graffitied with a drawing of a penis may have upset car lovers - but An image of a gold Bugatti Veyron graffitied with a drawing of a penis turns out the vehicle was included in a YouTube hoax.\n",
      "\n",
      ", An image of a gold Bugatti Veyron graffitied with a drawing of a penis may have upset car lovers - but An image of a gold Bugatti Veyron graffitied with a drawing of a penis turns out the vehicle was included in a YouTube hoax.\n",
      "\n",
      ", Photos from multiple Instagram accounts have revealed the vehicle wasn't permanently damaged.\n",
      "\n",
      ", Instagram user @andreysmygov uploaded a photo last Friday of the Veyron with a caption that suggested it was painted on as a stunt for TwinzTV, Car Crushing noted.\n",
      "\n",
      ", Scroll down for video\n",
      "\n",
      "Graffitied.  ]\n",
      "{'bugatti': [5, 3], 'veyron': [4, 3], 'penis': [7, 6], 'graffiti': [4, 4], 'viral': [None, None], 'photo': [6, 4], 'what': [None, None], '-pron-': [5, 4], '_vocab': [None, None]}\n",
      "({'image': image, 'bugatti': Bugatti, 'car': car, 'vehicle': vehicle, 'youtube': YouTube}, {'graffiti': graffitied}, {'gold': gold, 'drawing': drawing, 'penis': penis, 'lover': lovers, 'hoax': hoax})\n",
      "4\n",
      "(set(), {'include', 'graffiti', 'upset', 'have', 'turn'}, 0, 2)\n",
      "\n",
      "{'bugatti': [5, 3], 'veyron': [4, 3], 'penis': [7, 6], 'graffiti': [4, 4], 'viral': [None, None], 'photo': [6, 4], 'what': [None, None], '-pron-': [5, 4], '_vocab': [None, None]}\n",
      "({'image': image, 'bugatti': Bugatti, 'car': car, 'vehicle': vehicle, 'youtube': YouTube}, {'graffiti': graffitied}, {'gold': gold, 'drawing': drawing, 'penis': penis, 'lover': lovers, 'hoax': hoax})\n",
      "4\n",
      "(set(), {'include', 'graffiti', 'upset', 'have', 'turn'}, 0, 2)\n",
      "\n",
      "{'bugatti': [5, 3], 'veyron': [4, 3], 'penis': [7, 6], 'graffiti': [4, 4], 'viral': [None, None], 'photo': [6, 4], 'what': [None, None], '-pron-': [5, 4], '_vocab': [None, None]}\n",
      "({'photo': Photos, 'instagram': Instagram, 'vehicle': vehicle}, {'reveal': revealed}, {'account': accounts})\n",
      "3\n",
      "({'reveal', 'damage'}, set(), 1, 0)\n",
      "\n",
      "{'bugatti': [5, 3], 'veyron': [4, 3], 'penis': [7, 6], 'graffiti': [4, 4], 'viral': [None, None], 'photo': [6, 4], 'what': [None, None], '-pron-': [5, 4], '_vocab': [None, None]}\n",
      "({'instagram': Instagram, 'user': user, '@andreysmygov': @andreysmygov, 'that': that, '-pron-': it, 'car': Car, 'crushing': Crushing}, {'note': noted}, {'photo': photo, 'veyron': Veyron, 'caption': caption, 'stunt': stunt, 'twinztv': TwinzTV})\n",
      "5\n",
      "(set(), set(), 0, 0)\n",
      "\n",
      "{'bugatti': [5, 3], 'veyron': [4, 3], 'penis': [7, 6], 'graffiti': [4, 4], 'viral': [None, None], 'photo': [6, 4], 'what': [None, None], '-pron-': [5, 4], '_vocab': [None, None]}\n",
      "({}, {'scroll': Scroll}, {'video': video})\n",
      "4\n",
      "(set(), set(), 0, 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "body_text = get_body(list(df.values)[h_id][1])\n",
    "body = coref(preprocess(body_text))\n",
    "resolved = body._.coref_resolved\n",
    "print(resolved)\n",
    "print(\"\")\n",
    "body = nlp(resolved)\n",
    "body_graph = build_graph(body)\n",
    "summary = get_summary(body, test_subj, 5)\n",
    "print(summary)\n",
    "for s in summary:\n",
    "    svo_s = get_svos(s)\n",
    "    print(get_shortest_path_to_negating(body_graph, test_subj))\n",
    "    print(svo_s)\n",
    "    print(root_distance(body_graph, list(svo_s[1].keys())[0]))\n",
    "    print(get_neg_ancestors(s))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0\n",
      "Processed 2500\n",
      "Processed 5000\n",
      "Processed 7500\n",
      "Processed 10000\n",
      "Processed 12500\n",
      "Done!\n",
      "Processed 0\n",
      "Processed 100\n",
      "Processed 200\n",
      "Processed 300\n",
      "Processed 400\n",
      "Processed 500\n",
      "Processed 600\n",
      "Processed 700\n",
      "Processed 800\n",
      "Processed 900\n",
      "Processed 1000\n",
      "Processed 1100\n",
      "Processed 1200\n",
      "Processed 1300\n",
      "Processed 1400\n",
      "Processed 1500\n",
      "Processed 1600\n",
      "Done!\n",
      "878\n"
     ]
    }
   ],
   "source": [
    "headline_info = {}\n",
    "body_info = {}\n",
    "start = time.time()\n",
    "stance_data = list(train_stances.values)\n",
    "body_data = list(train_bodies.values)\n",
    "for headline in range(len(stance_data)):\n",
    "    if headline % 2500 == 0:\n",
    "        print(\"Processed \"+str(headline))\n",
    "    h, b_id, s = tuple(stance_data[headline])\n",
    "    nlp_h = nlp(preprocess(h))\n",
    "    headline_graph = build_graph(nlp_h)\n",
    "    headline_subj = get_topics(nlp_h)\n",
    "    headline_svo = get_svos(nlp_h)\n",
    "    headline_root_dist = root_distance(headline_graph, list(headline_svo[1].keys())[0])\n",
    "    headline_neg_ancestors = get_neg_ancestors(nlp_h)\n",
    "    nqh = 0\n",
    "    for tok in nlp_h:\n",
    "        if tok.text == \"?\":\n",
    "            nqh += 1\n",
    "    headline_info[h] = (nlp_h, headline_graph, headline_subj, headline_svo, headline_root_dist, headline_neg_ancestors, nqh)\n",
    "print(\"Done!\")\n",
    "for body in range(len(body_data)):\n",
    "    if body % 100 == 0:\n",
    "        print(\"Processed \"+str(body))\n",
    "    b_id, txt = tuple(body_data[body])\n",
    "    nlp_a = coref(preprocess(txt))\n",
    "    nlp_b = nlp(nlp_a._.coref_resolved)\n",
    "    body_graph = build_graph(nlp_b)\n",
    "    nqb = 0\n",
    "    for tok in nlp_b:\n",
    "        if tok.text == \"?\":\n",
    "            nqb += 1\n",
    "    body_info[b_id] = (nlp_b, body_graph, nqb)\n",
    "print(\"Done!\")\n",
    "end = time.time()\n",
    "print(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentence_vec(s):\n",
    "    vecs = [token.vector for token in s]\n",
    "    return np.nan_to_num(np.sum(vecs, axis = 0))\n",
    "\n",
    "def get_features(stance_df, n_sent = 5):\n",
    "    start = time.time()\n",
    "    data = list(stance_df.values)\n",
    "    features = []\n",
    "    actual = []\n",
    "    for item in data:\n",
    "        h, b, s = tuple(item)\n",
    "        headline, headline_graph, headline_subjs, headline_svo, headline_root_dist, headline_neg_ancestors, nq_h  = headline_info[h]\n",
    "        body, body_graph, nq_b = body_info[b]\n",
    "        \n",
    "        #sometimes the coref deletes bodies that are one sentence\n",
    "        if len(body) == 0:\n",
    "            body = nlp(preprocess(get_body(b)))\n",
    "            body_graph = build_graph(body)\n",
    "\n",
    "        #return the shortest path to negating word for each subject in headline_subjs, if one exists\n",
    "        neg_h = get_shortest_path_to_negating(headline_graph, headline_subjs)\n",
    "        neg_b = get_shortest_path_to_negating(body_graph, headline_subjs)\n",
    "\n",
    "        #body summary\n",
    "        summary = get_summary(body, headline_subjs, n_sent)\n",
    "        first_summ_sentence = summary[0]\n",
    "        \n",
    "        summary_svos = [get_svos(s) for s in summary]\n",
    "        summary_root_dist = [root_distance(body_graph, list(s[1].keys())[0]) for s in summary_svos]\n",
    "        summary_neg_ancestors = [get_neg_ancestors(s) for s in summary]\n",
    "        summary_neg_counts = [s[2:] for s in summary_neg_ancestors]\n",
    "        \n",
    "        #svo\n",
    "        body_s, body_v, body_o = {}, {}, {}\n",
    "        headline_s, headline_v, headline_o = headline_svo\n",
    "        for svo in summary_svos:\n",
    "            body_s.update(svo[0])\n",
    "            body_v.update(svo[1])\n",
    "            body_o.update(svo[2])\n",
    "        body_s_vec = list(np.sum([body_s[s].vector for s in body_s], axis = 0)) if len(body_s) > 0 else np.zeros(384)\n",
    "        body_v_vec = list(np.sum([body_v[s].vector for s in body_v], axis = 0)) if len(body_v) > 0 else np.zeros(384)\n",
    "        body_o_vec = list(np.sum([body_o[s].vector for s in body_o], axis = 0)) if len(body_o) > 0 else np.zeros(384)\n",
    "    \n",
    "        headline_s_vec = list(np.sum([headline_s[s].vector for s in headline_s], axis = 0)) if len(headline_s) > 0 else np.zeros(384)\n",
    "        headline_v_vec = list(np.sum([headline_v[s].vector for s in headline_v], axis = 0)) if len(headline_v) > 0 else np.zeros(384)\n",
    "        headline_o_vec = list(np.sum([headline_o[s].vector for s in headline_o], axis = 0)) if len(headline_o) > 0 else np.zeros(384)\n",
    "        \n",
    "        cos_sim_s = cosine_similarity(body_s_vec, headline_s_vec)\n",
    "        cos_sim_v = cosine_similarity(body_v_vec, headline_v_vec)\n",
    "        cos_sim_o = cosine_similarity(body_o_vec, headline_o_vec)\n",
    "        \n",
    "        #negating paths\n",
    "        headline_paths = [neg_h[x] for x in neg_h]\n",
    "        headline_neg_paths = [1 if x[0] != None else 0 for x in headline_paths] + [1]\n",
    "        headline_hedge_paths = [1 if x[1] != None else 0 for x in headline_paths] + [1]\n",
    "        body_paths = [neg_h[x] for x in neg_h]\n",
    "        body_neg_paths = [1 if x[0] != None else 0 for x in body_paths] + [1]\n",
    "        body_hedge_paths = [1 if x[1] != None else 0 for x in body_paths] + [1]\n",
    "        \n",
    "        neg_path_cos_sim = cosine_similarity(headline_neg_paths, body_neg_paths)\n",
    "        hedge_path_cos_sim = cosine_similarity(headline_hedge_paths, body_hedge_paths)\n",
    "        \n",
    "        #root distance\n",
    "        avg_summary_root_dist = None\n",
    "        non_null = [x for x in summary_root_dist if x != None]\n",
    "        if len(non_null) != 0:\n",
    "            avg_summary_root_dist = sum(non_null)/len(non_null)\n",
    "        root_dist_feats = [headline_root_dist, avg_summary_root_dist]\n",
    "        root_dist_feats = [x if x != None else 100 for x in root_dist_feats]\n",
    "    \n",
    "        #sentiment\n",
    "        headline_sent = get_sentiment(headline)\n",
    "        body_sents = [get_sentiment(s) for s in summary]\n",
    "        diff_sents = list(np.sum([get_diff_sentiment(headline_sent, s) for s in body_sents], axis = 0))\n",
    "        \n",
    "        #bow\n",
    "        headline_vocab = set([tok.lemma_.lower() for tok in headline])\n",
    "        fst_summ_vocab = set([tok.lemma_.lower() for tok in first_summ_sentence])\n",
    "        total_vocab = list(headline_vocab.union(fst_summ_vocab))\n",
    "        headline_embedding = [1 if tok in headline_vocab else 0 for tok in total_vocab]\n",
    "        fst_summ_embedding = [1 if tok in fst_summ_vocab else 0 for tok in total_vocab]\n",
    "        bow_cos_sim = cosine_similarity(headline_embedding, fst_summ_embedding)\n",
    "        \n",
    "        #word vecs\n",
    "        cos_sims = [cosine_similarity(get_sentence_vec(s), headline.vector) for s in summary]\n",
    "        fst_cos_sim = cos_sims[0]\n",
    "        avg_cos_sim = sum(cos_sims)/len(cos_sims)\n",
    "        \n",
    "        #build final features list\n",
    "        fts = (\n",
    "            [fst_cos_sim, avg_cos_sim, bow_cos_sim, \n",
    "               neg_path_cos_sim, hedge_path_cos_sim, \n",
    "               cos_sim_s, cos_sim_v, cos_sim_o, nq_h, nq_b] + \n",
    "            headline_sent + diff_sents + root_dist_feats + \n",
    "            list(headline_neg_ancestors[2:]) + list(np.sum(summary_neg_counts, axis = 0))\n",
    "        )\n",
    "        features.append(fts)\n",
    "        actual.append(s)\n",
    "    end = time.time()\n",
    "    print(int(end-start))\n",
    "    return features, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dannyyang/Library/Python/3.6/lib/python/site-packages/scipy/spatial/distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "stance_data = get_features(train_stances, 5)\n",
    "stance_dict = {}\n",
    "for idx, d in enumerate(list(train_stances.values)):\n",
    "    h, b, s = d\n",
    "    stance_dict[(h, b)] = stance_data[0][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiple(models, folds = 1, sampling = [1,1,1]):\n",
    "    \"\"\"\n",
    "    helper function for training on multiple splits\n",
    "    this isn't true K-fold CV because of the way we do our splits and augmentation\n",
    "    models: a list of instantiated models\n",
    "    folds: number of splits\n",
    "    sampling: list of 3 ints, representing how much we should oversample agree, disagree, discuss\n",
    "            for example, [1,1,2] will sample each discuss item twice\n",
    "    \"\"\"\n",
    "    for i in range(folds):\n",
    "        print(\"Training Fold \"+str(i + 1))\n",
    "        stances_tr, stances_val = train_test_split(train_bodies, train_stances)\n",
    "        disagrees = stances_tr[stances_tr[\"Stance\"]==\"disagree\"]\n",
    "        agrees = stances_tr[stances_tr[\"Stance\"]==\"agree\"]\n",
    "        discusses = stances_tr[stances_tr[\"Stance\"]==\"discuss\"]\n",
    "        data = []\n",
    "        for i in range(sampling[0]):\n",
    "            data.append(agrees)\n",
    "        for i in range(sampling[1]):\n",
    "            data.append(disagrees)\n",
    "        for i in range(sampling[2]):\n",
    "            data.append(discusses)\n",
    "        stances_tr_augmented = pd.concat(data).sample(frac=1).reset_index(drop=True)\n",
    "        training_data = [[],[]]\n",
    "        for h,b,s in list(stances_tr_augmented.values):\n",
    "            training_data[0].append(stance_dict[(h,b)])\n",
    "            training_data[1].append(s)\n",
    "        testing_data = [[],[]]\n",
    "        for h,b,s in list(stances_val.values):\n",
    "            testing_data[0].append(stance_dict[(h,b)])\n",
    "            testing_data[1].append(s)\n",
    "        c1, c2 = Counter(training_data[1]), Counter(testing_data[1])\n",
    "        baseline_tr = c1['discuss']/(c1['agree']+c1['disagree']+c1['discuss'])\n",
    "        baseline_val = c2['discuss']/(c2['agree']+c2['disagree']+c2['discuss'])\n",
    "        print(\"Training Baseline {0:.2f}% Testing Baseline {1:.2f}%\".format(baseline_tr * 100, baseline_val * 100))\n",
    "        for m in range(len(models)):\n",
    "            model = models[m]\n",
    "            print(\"Model \"+str(m + 1))\n",
    "            model.fit(training_data[0], training_data[1])\n",
    "            tr_acc = model.score(training_data[0], training_data[1])\n",
    "            print('{0:.2f}% training accuracy, vs Baseline {1:.2f}%'.format(tr_acc*100, (tr_acc-baseline_tr)*100))\n",
    "            val_acc = model.score(testing_data[0], testing_data[1])\n",
    "            print('{0:.2f}% validation accuracy, vs Baseline {1:.2f}%'.format(val_acc*100, (val_acc-baseline_val)*100))\n",
    "        print(\"#\"*50)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'discuss': 7172, 'agree': 2925, 'disagree': 650}) Counter({'discuss': 1737, 'agree': 753, 'disagree': 190})\n",
      "Training Baseline 66.73% Testing Baseline 64.81%\n"
     ]
    }
   ],
   "source": [
    "sampling = [1,1,1]\n",
    "stances_tr, stances_val = train_test_split(train_bodies, train_stances)\n",
    "disagrees = stances_tr[stances_tr[\"Stance\"]==\"disagree\"]\n",
    "agrees = stances_tr[stances_tr[\"Stance\"]==\"agree\"]\n",
    "discusses = stances_tr[stances_tr[\"Stance\"]==\"discuss\"]\n",
    "data = []\n",
    "for i in range(sampling[0]):\n",
    "    data.append(agrees)\n",
    "for i in range(sampling[1]):\n",
    "    data.append(disagrees)\n",
    "for i in range(sampling[2]):\n",
    "    data.append(discusses)\n",
    "stances_tr_augmented = pd.concat(data).sample(frac=1).reset_index(drop=True)\n",
    "training_data = [[],[]]\n",
    "for h,b,s in list(stances_tr_augmented.values):\n",
    "    training_data[0].append(stance_dict[(h,b)])\n",
    "    training_data[1].append(s)\n",
    "testing_data = [[],[]]\n",
    "for h,b,s in list(stances_val.values):\n",
    "    testing_data[0].append(stance_dict[(h,b)])\n",
    "    testing_data[1].append(s)\n",
    "c1, c2 = Counter(training_data[1]), Counter(testing_data[1])\n",
    "baseline_tr = c1['discuss']/(c1['agree']+c1['disagree']+c1['discuss'])\n",
    "baseline_val = c2['discuss']/(c2['agree']+c2['disagree']+c2['discuss'])\n",
    "print(c1, c2)\n",
    "print(\"Training Baseline {0:.2f}% Testing Baseline {1:.2f}%\".format(baseline_tr * 100, baseline_val * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(30):\n",
    "#     print(np.size(training_data[0][i][0]))\n",
    "# for i in range(len(training_data[0][0])):\n",
    "#     r = []\n",
    "#     for row in training_data[0]:\n",
    "#         r.append(row[i])\n",
    "#     print(r[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_int(labels):\n",
    "    return [(1 if l == \"agree\" else (0 if l == \"discuss\" else -1)) for l in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1\n",
      "Training Baseline 56.82% Testing Baseline 65.89%\n",
      "Model 1\n",
      "85.45% training accuracy, vs Baseline 28.63%\n",
      "58.96% validation accuracy, vs Baseline -6.93%\n",
      "##################################################\n",
      "Training Fold 1\n",
      "Training Baseline 55.34% Testing Baseline 63.15%\n",
      "Model 1\n",
      "76.19% training accuracy, vs Baseline 20.85%\n",
      "67.17% validation accuracy, vs Baseline 4.03%\n",
      "##################################################\n",
      "Training Fold 1\n",
      "Training Baseline 0.00% Testing Baseline 68.31%\n",
      "Model 1\n",
      "85.11% training accuracy, vs Baseline 85.11%\n",
      "23.29% validation accuracy, vs Baseline -45.02%\n",
      "##################################################\n",
      "Training Fold 1\n",
      "Training Baseline 66.99% Testing Baseline 63.79%\n",
      "Model 1\n",
      "75.86% training accuracy, vs Baseline 8.87%\n",
      "69.12% validation accuracy, vs Baseline 5.33%\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "models1 = [\n",
    "GradientBoostingClassifier(n_estimators = 400, subsample = 0.2, learning_rate = 0.025, random_state=0, min_samples_leaf = 3),\n",
    "]\n",
    "models2 = [\n",
    "GradientBoostingClassifier(n_estimators = 400, subsample = 0.2, learning_rate = 0.025, random_state=0, min_samples_leaf = 3),\n",
    "]\n",
    "models3 = [\n",
    "GradientBoostingClassifier(n_estimators = 400, subsample = 0.2, learning_rate = 0.025, random_state=0, min_samples_leaf = 3),\n",
    "]\n",
    "models4 = [\n",
    "GradientBoostingClassifier(n_estimators = 400, subsample = 0.2, learning_rate = 0.025, random_state=0, min_samples_leaf = 3),\n",
    "]\n",
    "trained1 = train_multiple(models1, 1, [0,8,1])\n",
    "trained2 = train_multiple(models2, 1, [2,0,1])\n",
    "trained3 = train_multiple(models3, 1, [2,8,0])\n",
    "trained4 = train_multiple(models3, 1, [1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.57% training accuracy\n",
      "70.30% validation accuracy\n",
      "Baseline comparison: 5.49%\n"
     ]
    }
   ],
   "source": [
    "# model = RandomForestClassifier(max_depth = 8, n_estimators=250, random_state = 0, min_samples_split = 10, min_samples_leaf = 5)\n",
    "model = LogisticRegression(max_iter = 200)\n",
    "models = [trained1[0], trained2[0], trained3[0], trained4[0]]\n",
    "preds = [label_to_int(m.predict(training_data[0])) for m in models]\n",
    "# model = SVC()\n",
    "# model = GradientBoostingClassifier(n_estimators = 500, subsample = 0.1, learning_rate = 0.02, random_state=0)\n",
    "model.fit(np.swapaxes(preds,0,1), training_data[1])\n",
    "tr_acc = model.score(tr_input, training_data[1])\n",
    "print('{0:.2f}% training accuracy'.format(tr_acc*100))\n",
    "\n",
    "test_preds = [label_to_int(m.predict(testing_data[0])) for m in models]\n",
    "val_acc = model.score(np.swapaxes(test_preds,0,1), testing_data[1])\n",
    "print('{0:.2f}% validation accuracy'.format(val_acc*100))\n",
    "print(\"Baseline comparison: {0:.2f}%\".format((val_acc-baseline_val)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.classes_, model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    274    |     0     |    479    |     0     |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    39     |     6     |    145    |     0     |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    132    |     1     |   1604    |     0     |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |     0     |     0     |     0     |   7500    |\n",
      "-------------------------------------------------------------\n",
      "Score: 3958.0 out of 4555.0\t(86.89352360043908%)\n",
      "F1 Score\n",
      "[0.45742905 0.06091371 0.80907945 1.        ]\n",
      "Avg Precision Score\n",
      "[0.61573034 0.85714286 0.71992819 1.        ]\n",
      "Normalized confusion matrix\n",
      "[[3.63877822e-01 0.00000000e+00 6.36122178e-01 0.00000000e+00]\n",
      " [2.05263158e-01 3.15789474e-02 7.63157895e-01 0.00000000e+00]\n",
      " [7.59930915e-02 5.75705239e-04 9.23431203e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAEYCAYAAAApuP8NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naaCITUana1MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a5f73d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "actual = testing_data[1]\n",
    "predicted = model.predict(np.swapaxes(test_preds,0,1))\n",
    "actual = actual + [\"unrelated\"] * 7500\n",
    "predicted = np.concatenate((predicted, [\"unrelated\"] * 7500),axis = 0)\n",
    "sc.report_score(actual, predicted)\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(actual, predicted, average = None))\n",
    "print(\"Avg Precision Score\")\n",
    "print(precision_score(actual, predicted, average = None))\n",
    "matrix = confusion_matrix(actual,predicted)\n",
    "plot_confusion_matrix(matrix, classes=[\"agree\",\"disagree\", \"discuss\"],\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
