{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import networkx as nx\n",
    "import score as sc\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, pairwise\n",
    "from scipy.spatial import distance\n",
    "from preprocessing.utils import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from collections import Counter, defaultdict\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import torch\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.cm\n",
    "# print(matplotlib.cm.cmap_d.keys())\n",
    "import sys\n",
    "importlib.reload(sys.modules['preprocessing.utils'])\n",
    "from preprocessing.utils import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://github.com/huggingface/neuralcoref\n",
    "#note: this NEEDS spacy 2.0.12 to work! downgrade with pip install spacy=2.0.12\n",
    "import en_coref_md\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "coref = en_coref_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negating_words = set([\n",
    "    \"n't\", \"not\", \"no\", \n",
    "    \"never\", \"nobody\", \"non\", \"nope\"])\n",
    "doubting_words = set([\n",
    "    'fake','fraud', 'hoax', \n",
    "    'false', 'deny', 'denies', \n",
    "    'despite', 'doubt', \n",
    "    'bogus', 'debunk', 'prank', \n",
    "    'retract', 'scam', \"withdrawn\",\n",
    "    \"misinformation\"])\n",
    "hedging_words = set([\n",
    "    'allege', 'allegedly','apparently',\n",
    "    'appear','claim','could',\n",
    "    'evidently','largely','likely',\n",
    "    'mainly','may', 'maybe', 'might',\n",
    "    'mostly','perhaps','presumably',\n",
    "    'probably','purport', 'purportedly',\n",
    "    'reported', 'reportedly',\n",
    "    'rumor', 'rumour', 'rumored', 'rumoured',\n",
    "    'says','seem','somewhat',\n",
    "    'unconfirmed'])\n",
    "sus_words = doubting_words.union(hedging_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(data, targets, i,batch_size):\n",
    "    batches = data[i*batch_size:i*batch_size+batch_size]\n",
    "    results = targets[i*batch_size:i*batch_size+batch_size]\n",
    "    results = [(2.0 if result == \"agree\" else (1.0 if result == \"discuss\" else 0.0)) for result in results]\n",
    "    batches = np.array(batches, dtype = \"float\")\n",
    "    return batches, np.array(results)\n",
    "\n",
    "def eval_model(model, data):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_x_test,batch_y_test = get_batch(data[0], data[1],0,len(stances_val))\n",
    "    model.eval()\n",
    "    predicted = None\n",
    "    with torch.no_grad():\n",
    "        inputs = Variable(torch.FloatTensor(batch_x_test))\n",
    "        labels = torch.LongTensor(batch_y_test)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy: %d %%' % (100 * correct / total))\n",
    "    return predicted\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    correct = (preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc\n",
    "\n",
    "def train(model, total_batch, optimizer, criterion, data):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = get_batch(data[0], data[1],i, batch_size)\n",
    "        #print(batch_x, batch_y)\n",
    "        inputs = Variable(torch.FloatTensor(batch_x))\n",
    "        labels = Variable(torch.LongTensor(batch_y))\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(inputs)\n",
    "        loss = criterion(predictions, labels)\n",
    "        _, predicted = torch.max(predictions.data, 1)\n",
    "        acc = binary_accuracy(predicted, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / total_batch, epoch_acc / total_batch\n",
    "\n",
    "def evaluate(model, total_batch, criterion, data):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(total_batch):\n",
    "            batch_x,batch_y = get_batch(data[0], data[1],i,batch_size)\n",
    "            inputs = Variable(torch.FloatTensor(batch_x))\n",
    "            labels = Variable(torch.LongTensor(batch_y))\n",
    "            predictions = model(inputs)\n",
    "            loss = criterion(predictions, labels)\n",
    "            _, predicted = torch.max(predictions.data, 1)\n",
    "            acc = binary_accuracy(predicted, labels)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / total_batch, epoch_acc / total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(sentence):\n",
    "    sent =  vader.polarity_scores(sentence.text)\n",
    "    return [sent[\"pos\"],sent[\"neg\"],sent[\"neu\"],sent[\"compound\"]]\n",
    "\n",
    "def get_avg_sentiment(lst):\n",
    "    sents = np.array([get_sentiment(s) for s in lst])\n",
    "    return list(np.mean(sents, axis = 0))\n",
    "\n",
    "def get_diff_sentiment(a,b):\n",
    "    return list(np.absolute(np.array(a) - np.array(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(bodies, stances, split=0.8):\n",
    "    idx = np.random.permutation(np.arange(len(bodies)))\n",
    "    bodies = bodies.values[idx]\n",
    "    train = int(len(bodies)*0.8)\n",
    "    bodies_tr = set([i[0] for i in bodies[:train]])\n",
    "    bodies_val = set([i[0] for i in bodies[train:]])\n",
    "    stances_tr = stances.loc[stances[\"Body ID\"].isin(bodies_tr), :]\n",
    "    stances_val = stances.loc[stances[\"Body ID\"].isin(bodies_val), :]\n",
    "    return stances_tr, stances_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13427, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'Nasa Confirms Earth Will Experience 6 Days of...</td>\n",
       "      <td>154</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Banksy 'Arrested &amp; Real Identity Revealed' Is ...</td>\n",
       "      <td>1739</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gateway Pundit</td>\n",
       "      <td>2327</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Woman detained in Lebanon is not al-Baghdadi's...</td>\n",
       "      <td>1468</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Soon Marijuana May Lead to Ticket, Not Arrest,...</td>\n",
       "      <td>47</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Boko Haram Denies Nigeria Cease-Fire Claim</td>\n",
       "      <td>2463</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>No, Robert Plant Didn’t Rip Up an $800 Million...</td>\n",
       "      <td>295</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ISIL Beheads American Photojournalist in Iraq</td>\n",
       "      <td>608</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Boko Haram ceasefire ignored as violence flare...</td>\n",
       "      <td>1681</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NET Extra: Back-from-the-dead Catholic priest ...</td>\n",
       "      <td>1014</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Rumor debunked: RoboCop-style robots are not p...</td>\n",
       "      <td>633</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Report: Christian Bale Just Bailed on the Stev...</td>\n",
       "      <td>1157</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Insurgents killed in Nigeria despite alleged t...</td>\n",
       "      <td>1896</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline  Body ID    Stance\n",
       "1   Hundreds of Palestinians flee floods in Gaza a...      158     agree\n",
       "4   Spider burrowed through tourist's stomach and ...     1923  disagree\n",
       "5   'Nasa Confirms Earth Will Experience 6 Days of...      154     agree\n",
       "8   Banksy 'Arrested & Real Identity Revealed' Is ...     1739     agree\n",
       "10                                     Gateway Pundit     2327   discuss\n",
       "11  Woman detained in Lebanon is not al-Baghdadi's...     1468     agree\n",
       "14  Soon Marijuana May Lead to Ticket, Not Arrest,...       47   discuss\n",
       "16         Boko Haram Denies Nigeria Cease-Fire Claim     2463   discuss\n",
       "17  No, Robert Plant Didn’t Rip Up an $800 Million...      295     agree\n",
       "19      ISIL Beheads American Photojournalist in Iraq      608   discuss\n",
       "21  Boko Haram ceasefire ignored as violence flare...     1681   discuss\n",
       "24  NET Extra: Back-from-the-dead Catholic priest ...     1014     agree\n",
       "25  Rumor debunked: RoboCop-style robots are not p...      633     agree\n",
       "29  Report: Christian Bale Just Bailed on the Stev...     1157   discuss\n",
       "31  Insurgents killed in Nigeria despite alleged t...     1896   discuss"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stances = pd.read_csv(\"fn_data/train_stances.csv\")\n",
    "train_stances = train_stances.loc[lambda x: x.Stance != \"unrelated\"]\n",
    "print(train_stances.shape)\n",
    "train_stances.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1683, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody\n",
       "0        0  A small meteorite crashed into a wooded area i...\n",
       "1        4  Last week we hinted at what was to come as Ebo...\n",
       "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...\n",
       "3        6  Posting photos of a gun-toting child online, I...\n",
       "4        7  At least 25 suspected Boko Haram insurgents we..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bodies = pd.read_csv(\"fn_data/train_bodies.csv\")\n",
    "print(train_bodies.shape)\n",
    "train_bodies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10713, 3), (2714, 3))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stances_tr, stances_val = train_test_split(train_bodies, train_stances)\n",
    "stances_tr.shape, stances_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagrees = stances_tr[stances_tr[\"Stance\"]==\"disagree\"]\n",
    "agrees = stances_tr[stances_tr[\"Stance\"]==\"agree\"]\n",
    "discusses = stances_tr[stances_tr[\"Stance\"]==\"discuss\"]\n",
    "stances_tr_augmented = pd.concat([stances_tr, agrees, disagrees, disagrees, disagrees, disagrees, disagrees, disagrees]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_body(n):\n",
    "    return train_bodies.loc[lambda x: x[\"Body ID\"] == n, \"articleBody\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.replace(\"' \",' ')\n",
    "    text = text.replace(\" '\",' ')\n",
    "    text = text.replace(\":\", \". \")\n",
    "    text = text.replace(\";\", \". \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(x,y):\n",
    "    return 1 - np.nan_to_num(distance.cosine(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_topics(doc):\n",
    "    \"\"\"\n",
    "    get topics of a sentence\n",
    "    input: spacy doc\n",
    "    output: dictionary with nouns as the key, and the set of noun chunks that contain the noun as the value\n",
    "    special entry _vocab has the set of all tokens in the dict\n",
    "    \"\"\"\n",
    "    subjs = {}\n",
    "    for token in doc:\n",
    "        if token.dep_ in [\"nsubj\", \"nsubjpass\", \"csubj\",\"csubjpass\", \"dobj\", \"dative\", \"attr\", \"oprd\", \"pobj\", \"compound\"]:\n",
    "            txt = token.lemma_.lower()\n",
    "            if txt not in subjs:\n",
    "                subjs[txt] = set([txt])      \n",
    "    for chunk in doc.noun_chunks:\n",
    "        if len(chunk.root.text) > 2:\n",
    "            txt = chunk.root.text.lower()\n",
    "            if txt not in subjs:\n",
    "                subjs[txt] = set([txt])\n",
    "            subjs[txt].add(chunk.text.lower())\n",
    "    subjects_= []\n",
    "    for word in subjs:\n",
    "        for phrase in subjs[word]:\n",
    "            subjects_ += phrase.split(\" \")\n",
    "    subjs[\"_vocab\"] = set(subjects_)\n",
    "    return subjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_svos(sent):\n",
    "    \"\"\"\n",
    "    input: Spacy processed sentence\n",
    "    output: dict of subj, dict of v, dict of obj (each word is lemmatized and lowercased)\n",
    "    each entry in dict has key of lemmatized token, value is actual token (to do traversals with later if needed)\n",
    "    \"\"\"\n",
    "    s = {}\n",
    "    v = {}\n",
    "    o = {}\n",
    "    for token in sent:\n",
    "        if token.dep_ == 'ROOT':\n",
    "            v[token.lemma_.lower()] = token\n",
    "        elif token.dep_ in [\"nsubj\", \"nsubjpass\", \"csubj\",\"csubjpass\", \"agent\",\"compound\"]:\n",
    "            s[token.lemma_.lower()] = token\n",
    "        elif token.dep_ in [\"dobj\", \"dative\", \"attr\", \"oprd\", \"pobj\"]:\n",
    "            o[token.lemma_.lower()] = token\n",
    "    # https://github.com/clir/clearnlp-guidelines/blob/master/md/specifications/dependency_labels.md\n",
    "    return (s,v,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_graph(doc):\n",
    "    \"\"\"\n",
    "    build a NetworkX graph of the dependency tree\n",
    "    input: spacy Doc\n",
    "    output: networkx graph\n",
    "    \"\"\"\n",
    "    edges = set()\n",
    "    for token in doc:\n",
    "        for child in token.children:\n",
    "            edges.add((token.lemma_.lower(),child.lemma_.lower()))\n",
    "    graph = nx.Graph(list(edges))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_summary(doc, subjects, n = 5):\n",
    "    \"\"\"\n",
    "    get summary of n sentences in document\n",
    "    first meaningful sentence will always be returned\n",
    "    \"\"\"\n",
    "    subjects_ = subjects[\"_vocab\"]\n",
    "    def score_sentence(sent):\n",
    "        # not very robust right now\n",
    "        score = 0\n",
    "        word_count = 0\n",
    "        for token in sent:\n",
    "            word_count += 1\n",
    "            t = token.lemma_.lower()\n",
    "            if t in subjects_:\n",
    "                score += 1\n",
    "            elif t in negating_words or t in doubting_words or t in hedging_words:\n",
    "                score += 0.5\n",
    "            return score/word_count if word_count > 4 else 0\n",
    "    sentences = [s for s in doc.sents]\n",
    "    scored_sentences = [[idx, sent, score_sentence(sent)] for idx, sent in enumerate(sentences)]\n",
    "    # scored_sentences = [s for s in scored_sentences if s[2] > 0] #filter out non-scoring sentences\n",
    "    scored_sentences.sort(key = lambda x: x[2], reverse = True)\n",
    "    top = scored_sentences[:n-1]\n",
    "    top.sort(key = lambda x: x[0])\n",
    "    result = [scored_sentences[0][1]] + [s[1] for s in top]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_shortest_path_to_negating(graph, subjects):\n",
    "    \"\"\"\n",
    "    get the shortest path from each subject to any negating or doubting/hedging word\n",
    "    returns: dictionary with subject as key, and 2-element list of path lengths [negating, doubting]\n",
    "    - if a subject does not exist in graph or have a path to any negating word, then the value will be [None, None]\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for s in subjects:\n",
    "        results[s] = [None, None]\n",
    "        if graph.has_node(s):\n",
    "            for word in negating_words:\n",
    "                if word in graph:\n",
    "                    try:\n",
    "                        path = nx.shortest_path(graph, source = s, target = word)\n",
    "                        if results[s][0] == None or len(path) < results[s][0]:\n",
    "                            results[s][0] = len(path)\n",
    "                    except:\n",
    "                        continue\n",
    "            for word in sus_words:\n",
    "                if word in graph:\n",
    "                    try:\n",
    "                        path = nx.shortest_path(graph, source = s, target = word)\n",
    "                        if results[s][1] == None or len(path) < results[s][1]:\n",
    "                            results[s][1] = len(path)\n",
    "                    except:\n",
    "                        continue\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def root_distance(graph, root):\n",
    "    \"\"\"\n",
    "    as implemented in the Emergent paper - return the shortest distance between the given root and any \n",
    "    doubting or hedging words in the graph, or None if no such path exists\n",
    "    \"\"\"\n",
    "    if root == None:\n",
    "        return None\n",
    "    min_dist = None\n",
    "    for word in sus_words:\n",
    "        if word in graph:\n",
    "            try:\n",
    "                path = nx.shortest_path(graph, source = root, target = word)\n",
    "                if min_dist == None or len(path) < min_dist:\n",
    "                    min_dist = len(path)\n",
    "            except:\n",
    "                continue\n",
    "    return min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_neg_ancestors(doc):\n",
    "    \"\"\"\n",
    "    get the ancestors of every negating word\n",
    "    input: spacy Doc\n",
    "    returns: tuple  - set of words that were in the ancestor list of negating words, \n",
    "    set of words that were in ancestor list of refuting words, # negating words, # refuting words\n",
    "    \"\"\"\n",
    "    results = [set(), set(), 0, 0]\n",
    "    for token in doc:\n",
    "        if token.lemma_.lower() in negating_words:\n",
    "            results[0] = results[0].union(\n",
    "                set([ancestor.lemma_.lower() for ancestor in token.ancestors if len(ancestor) > 2])\n",
    "            )\n",
    "            results[2] += 1\n",
    "        elif token.lemma_.lower() in sus_words:\n",
    "            results[1] = results[1].union(\n",
    "                set([ancestor.lemma_.lower() for ancestor in token.ancestors if len(ancestor) > 2])\n",
    "            )\n",
    "            results[3] += 1\n",
    "    return tuple(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeh Johnson.  Politicians Shouldn't Feed The Flames Of Fear Over ISIS, Ebola\n",
      "{'jeh': [None, None], 'politician': [3, None], 'flames': [3, None], 'fear': [5, None], 'isis': [None, None], 'ebola': [None, None], 'johnson': [None, None], 'politicians': [None, None], 'over': [None, None], '_vocab': [None, None]}\n",
      "{'jeh': {'jeh'}, 'politician': {'politician'}, 'flames': {'flames', 'the flames'}, 'fear': {'fear'}, 'isis': {'isis'}, 'ebola': {'ebola'}, 'johnson': {'jeh johnson', 'johnson'}, 'politicians': {'politicians'}, 'over': {'over'}, '_vocab': {'jeh', 'fear', 'isis', 'politicians', 'flames', 'ebola', 'politician', 'over', 'the', 'johnson'}} ({'jeh': Jeh, 'politician': Politicians}, {'johnson': Johnson, 'feed': Feed, 'over': Over}, {'flames': Flames, 'fear': Fear, 'isis': ISIS, 'ebola': Ebola}) johnson\n",
      "None\n",
      "({'feed'}, set(), 1, 0)\n"
     ]
    }
   ],
   "source": [
    "h_id = 20\n",
    "df = agrees\n",
    "test = nlp(preprocess(list(df.values)[h_id][0]))\n",
    "print(test)\n",
    "test_graph = build_graph(test)\n",
    "test_subj = get_topics(test)\n",
    "test_svo = get_svos(test)\n",
    "print(get_shortest_path_to_negating(test_graph, test_subj))\n",
    "print(test_subj, test_svo, list(test_svo[1].keys())[0])\n",
    "print(root_distance(test_graph, list(test_svo[1].keys())[0]))\n",
    "print(get_neg_ancestors(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homeland Security Secretary Jeh Johnson says Islamic State militants are not entering the U.S. through the southern border. Homeland Security Secretary Jeh Johnson was responding to a claim made by Rep. Duncan Hunter, R-Calif., that at least 10 Islamic State operatives were detained trying to come in from Mexico.\n",
      "\n",
      "“We have no credible, specific intelligence to that effect,” Homeland Security Secretary Jeh Johnson said on CNN Wednesday evening of the militants also known as ISIS. “And I look at the intelligence reports from overseas from our southern border from our intelligence community virtually every day, numerous times a day, to be on the lookout for something of that nature. So, what I’d say to the American public is we’re vigilant in looking out for individuals of suspicion who may be crossing we .”\n",
      "\n",
      "Johnson never mentioned Hunter by name, but Johnson has called on lawmakers to act responsibly and not frighten Americans. “Let’s not unduly create fear and anxiety in the American public by passing on speculation and rumor,” Johnson said.\n",
      "\n",
      "The group Judicial Watch reported late Wednesday that four “Islamic terrorists” had been seized along the southern border within 36 hours. Hunter said in an interview with Fox News on Tuesday that \"at least 10 ISIS fighters have been caught coming across the Mexican border in Texas.\"\n",
      "\n",
      "[Homeland Security Secretary Jeh Johnson says Islamic State militants are not entering the U.S. through the southern border., Homeland Security Secretary Jeh Johnson says Islamic State militants are not entering the U.S. through the southern border., We have no credible, specific intelligence to that effect,” Homeland Security Secretary Jeh Johnson said on CNN Wednesday evening of the militants also known as ISIS., Johnson never mentioned Hunter by name, but Johnson has called on lawmakers to act responsibly and not frighten Americans., Let’s not unduly create fear and anxiety in the American public by passing on speculation and rumor,” Johnson said.\n",
      "\n",
      "]\n",
      "{'jeh': [4, 5], 'politician': [None, None], 'flames': [None, None], 'fear': [3, 4], 'isis': [6, 6], 'ebola': [None, None], 'johnson': [3, 4], 'politicians': [None, None], 'over': [None, None], '_vocab': [None, None]}\n",
      "({'homeland': Homeland, 'security': Security, 'secretary': Secretary, 'jeh': Jeh, 'johnson': Johnson, 'islamic': Islamic, 'state': State, 'militant': militants}, {'say': says}, {'u.s.': U.S., 'border': border})\n",
      "3\n",
      "({'enter', 'say'}, set(), 1, 0)\n",
      "\n",
      "{'jeh': [4, 5], 'politician': [None, None], 'flames': [None, None], 'fear': [3, 4], 'isis': [6, 6], 'ebola': [None, None], 'johnson': [3, 4], 'politicians': [None, None], 'over': [None, None], '_vocab': [None, None]}\n",
      "({'homeland': Homeland, 'security': Security, 'secretary': Secretary, 'jeh': Jeh, 'johnson': Johnson, 'islamic': Islamic, 'state': State, 'militant': militants}, {'say': says}, {'u.s.': U.S., 'border': border})\n",
      "3\n",
      "({'enter', 'say'}, set(), 1, 0)\n",
      "\n",
      "{'jeh': [4, 5], 'politician': [None, None], 'flames': [None, None], 'fear': [3, 4], 'isis': [6, 6], 'ebola': [None, None], 'johnson': [3, 4], 'politicians': [None, None], 'over': [None, None], '_vocab': [None, None]}\n",
      "({'-pron-': We, 'homeland': Homeland, 'security': Security, 'secretary': Secretary, 'jeh': Jeh, 'johnson': Johnson, 'wednesday': Wednesday}, {'say': said}, {'intelligence': intelligence, 'effect': effect, 'cnn': CNN, 'militant': militants, 'isis': ISIS})\n",
      "3\n",
      "({'intelligence', 'have', 'say'}, set(), 1, 0)\n",
      "\n",
      "{'jeh': [4, 5], 'politician': [None, None], 'flames': [None, None], 'fear': [3, 4], 'isis': [6, 6], 'ebola': [None, None], 'johnson': [3, 4], 'politicians': [None, None], 'over': [None, None], '_vocab': [None, None]}\n",
      "({'johnson': Johnson}, {'mention': mentioned}, {'hunter': Hunter, 'name': name, 'lawmaker': lawmakers, 'americans': Americans})\n",
      "4\n",
      "({'mention', 'frighten', 'act', 'call'}, set(), 2, 0)\n",
      "\n",
      "{'jeh': [4, 5], 'politician': [None, None], 'flames': [None, None], 'fear': [3, 4], 'isis': [6, 6], 'ebola': [None, None], 'johnson': [3, 4], 'politicians': [None, None], 'over': [None, None], '_vocab': [None, None]}\n",
      "({'-pron-': ’s, 'johnson': Johnson}, {'say': said}, {'fear': fear, 'public': public, 'speculation': speculation})\n",
      "3\n",
      "({'say', 'let', 'create'}, {'pass', 'speculation', 'say', 'create', 'let'}, 1, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "body_text = get_body(list(df.values)[h_id][1])\n",
    "body = coref(preprocess(body_text))\n",
    "resolved = body._.coref_resolved\n",
    "print(resolved)\n",
    "print(\"\")\n",
    "body = nlp(resolved)\n",
    "body_graph = build_graph(body)\n",
    "summary = get_summary(body, test_subj, 5)\n",
    "print(summary)\n",
    "for s in summary:\n",
    "    svo_s = get_svos(s)\n",
    "    print(get_shortest_path_to_negating(body_graph, test_subj))\n",
    "    print(svo_s)\n",
    "    print(root_distance(body_graph, list(svo_s[1].keys())[0]))\n",
    "    print(get_neg_ancestors(s))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0\n",
      "Processed 2500\n",
      "Processed 5000\n",
      "Processed 7500\n",
      "Processed 10000\n",
      "Processed 12500\n",
      "Done!\n",
      "Processed 0\n",
      "Processed 100\n",
      "Processed 200\n",
      "Processed 300\n",
      "Processed 400\n",
      "Processed 500\n",
      "Processed 600\n",
      "Processed 700\n",
      "Processed 800\n",
      "Processed 900\n",
      "Processed 1000\n",
      "Processed 1100\n",
      "Processed 1200\n",
      "Processed 1300\n",
      "Processed 1400\n",
      "Processed 1500\n",
      "Processed 1600\n",
      "Done!\n",
      "783\n"
     ]
    }
   ],
   "source": [
    "headline_info = {}\n",
    "body_info = {}\n",
    "start = time.time()\n",
    "stance_data = list(train_stances.values)\n",
    "body_data = list(train_bodies.values)\n",
    "for headline in range(len(stance_data)):\n",
    "    if headline % 2500 == 0:\n",
    "        print(\"Processed \"+str(headline))\n",
    "    h, b_id, s = tuple(stance_data[headline])\n",
    "    nlp_h = nlp(preprocess(h))\n",
    "    headline_graph = build_graph(nlp_h)\n",
    "    headline_subj = get_topics(nlp_h)\n",
    "    headline_svo = get_svos(nlp_h)\n",
    "    headline_root_dist = root_distance(headline_graph, list(headline_svo[1].keys())[0])\n",
    "    headline_neg_ancestors = get_neg_ancestors(nlp_h)\n",
    "    nqh = 0\n",
    "    for tok in nlp_h:\n",
    "        if tok.text == \"?\":\n",
    "            nqh += 1\n",
    "    headline_info[h] = (nlp_h, headline_graph, headline_subj, headline_svo, headline_root_dist, headline_neg_ancestors, nqh)\n",
    "print(\"Done!\")\n",
    "for body in range(len(body_data)):\n",
    "    if body % 100 == 0:\n",
    "        print(\"Processed \"+str(body))\n",
    "    b_id, txt = tuple(body_data[body])\n",
    "    nlp_a = coref(preprocess(txt))\n",
    "    nlp_b = nlp(nlp_a._.coref_resolved)\n",
    "    body_graph = build_graph(nlp_b)\n",
    "    nqb = 0\n",
    "    for tok in nlp_b:\n",
    "        if tok.text == \"?\":\n",
    "            nqb += 1\n",
    "    body_info[b_id] = (nlp_b, body_graph, nqb)\n",
    "print(\"Done!\")\n",
    "end = time.time()\n",
    "print(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentence_vec(s):\n",
    "    vecs = [token.vector for token in s]\n",
    "    return np.nan_to_num(np.sum(vecs, axis = 0))\n",
    "\n",
    "def get_features(stance_df, n_sent = 5):\n",
    "    start = time.time()\n",
    "    data = list(stance_df.values)\n",
    "    features = []\n",
    "    actual = []\n",
    "    for item in data:\n",
    "        h, b, s = tuple(item)\n",
    "        headline, headline_graph, headline_subjs, headline_svo, headline_root_dist, headline_neg_ancestors, nq_h  = headline_info[h]\n",
    "        body, body_graph, nq_b = body_info[b]\n",
    "        \n",
    "        #sometimes the coref deletes bodies that are one sentence\n",
    "        if len(body) == 0:\n",
    "            body = nlp(preprocess(get_body(b)))\n",
    "            body_graph = build_graph(body)\n",
    "\n",
    "        #return the shortest path to negating word for each subject in headline_subjs, if one exists\n",
    "        neg_h = get_shortest_path_to_negating(headline_graph, headline_subjs)\n",
    "        neg_b = get_shortest_path_to_negating(body_graph, headline_subjs)\n",
    "\n",
    "        #body summary\n",
    "        summary = get_summary(body, headline_subjs, n_sent)\n",
    "        first_summ_sentence = summary[0]\n",
    "        \n",
    "        summary_svos = [get_svos(s) for s in summary]\n",
    "        summary_root_dist = [root_distance(body_graph, list(s[1].keys())[0]) for s in summary_svos]\n",
    "        summary_neg_ancestors = [get_neg_ancestors(s) for s in summary]\n",
    "        summary_neg_counts = [s[2:] for s in summary_neg_ancestors]\n",
    "        \n",
    "        #svo\n",
    "        body_s, body_v, body_o = {}, {}, {}\n",
    "        headline_s, headline_v, headline_o = headline_svo\n",
    "        for svo in summary_svos:\n",
    "            body_s.update(svo[0])\n",
    "            body_v.update(svo[1])\n",
    "            body_o.update(svo[2])\n",
    "        body_s_vec = list(np.sum([body_s[s].vector for s in body_s], axis = 0)) if len(body_s) > 0 else np.zeros(384)\n",
    "        body_v_vec = list(np.sum([body_v[s].vector for s in body_v], axis = 0)) if len(body_v) > 0 else np.zeros(384)\n",
    "        body_o_vec = list(np.sum([body_o[s].vector for s in body_o], axis = 0)) if len(body_o) > 0 else np.zeros(384)\n",
    "    \n",
    "        headline_s_vec = list(np.sum([headline_s[s].vector for s in headline_s], axis = 0)) if len(headline_s) > 0 else np.zeros(384)\n",
    "        headline_v_vec = list(np.sum([headline_v[s].vector for s in headline_v], axis = 0)) if len(headline_v) > 0 else np.zeros(384)\n",
    "        headline_o_vec = list(np.sum([headline_o[s].vector for s in headline_o], axis = 0)) if len(headline_o) > 0 else np.zeros(384)\n",
    "        \n",
    "        cos_sim_s = cosine_similarity(body_s_vec, headline_s_vec)\n",
    "        cos_sim_v = cosine_similarity(body_v_vec, headline_v_vec)\n",
    "        cos_sim_o = cosine_similarity(body_o_vec, headline_o_vec)\n",
    "        \n",
    "        #negating paths\n",
    "        headline_paths = [neg_h[x] for x in neg_h]\n",
    "        headline_neg_paths = [1 if x[0] != None else 0 for x in headline_paths] + [1]\n",
    "        headline_hedge_paths = [1 if x[1] != None else 0 for x in headline_paths] + [1]\n",
    "        body_paths = [neg_h[x] for x in neg_h]\n",
    "        body_neg_paths = [1 if x[0] != None else 0 for x in body_paths] + [1]\n",
    "        body_hedge_paths = [1 if x[1] != None else 0 for x in body_paths] + [1]\n",
    "        \n",
    "        neg_path_cos_sim = cosine_similarity(headline_neg_paths, body_neg_paths)\n",
    "        hedge_path_cos_sim = cosine_similarity(headline_hedge_paths, body_hedge_paths)\n",
    "        \n",
    "        #root distance\n",
    "        avg_summary_root_dist = None\n",
    "        non_null = [x for x in summary_root_dist if x != None]\n",
    "        if len(non_null) != 0:\n",
    "            avg_summary_root_dist = sum(non_null)/len(non_null)\n",
    "        root_dist_feats = [headline_root_dist, avg_summary_root_dist]\n",
    "        root_dist_feats = [x if x != None else 100 for x in root_dist_feats]\n",
    "    \n",
    "        #sentiment\n",
    "        headline_sent = get_sentiment(headline)\n",
    "        body_sents = [get_sentiment(s) for s in summary]\n",
    "        diff_sents = list(np.sum([get_diff_sentiment(headline_sent, s) for s in body_sents], axis = 0))\n",
    "        \n",
    "        #bow\n",
    "        headline_vocab = set([tok.lemma_.lower() for tok in headline])\n",
    "        fst_summ_vocab = set([tok.lemma_.lower() for tok in first_summ_sentence])\n",
    "        total_vocab = list(headline_vocab.union(fst_summ_vocab))\n",
    "        headline_embedding = [1 if tok in headline_vocab else 0 for tok in total_vocab]\n",
    "        fst_summ_embedding = [1 if tok in fst_summ_vocab else 0 for tok in total_vocab]\n",
    "        bow_cos_sim = cosine_similarity(headline_embedding, fst_summ_embedding)\n",
    "        \n",
    "        #word vecs\n",
    "        cos_sims = [cosine_similarity(get_sentence_vec(s), headline.vector) for s in summary]\n",
    "        fst_cos_sim = cos_sims[0]\n",
    "        avg_cos_sim = sum(cos_sims)/len(cos_sims)\n",
    "        \n",
    "        #build final features list\n",
    "        fts = (\n",
    "            [fst_cos_sim, avg_cos_sim, bow_cos_sim, \n",
    "               neg_path_cos_sim, hedge_path_cos_sim, \n",
    "               cos_sim_s, cos_sim_v, cos_sim_o, nq_h, nq_b] + \n",
    "            headline_sent + diff_sents + root_dist_feats + \n",
    "            list(headline_neg_ancestors[2:]) + list(np.sum(summary_neg_counts, axis = 0))\n",
    "        )\n",
    "        features.append(fts)\n",
    "        actual.append(s)\n",
    "    end = time.time()\n",
    "    print(int(end-start))\n",
    "    return features, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_nn(stance_df, n_sent = 5):\n",
    "    start = time.time()\n",
    "    data = list(stance_df.values)\n",
    "    features = []\n",
    "    actual = []\n",
    "    for item in data:\n",
    "        h, b, s = tuple(item)\n",
    "        headline, headline_graph, headline_subjs, headline_svo, headline_root_dist, headline_neg_ancestors, nq_h  = headline_info[h]\n",
    "        body, body_graph, nq_b = body_info[b]\n",
    "        \n",
    "        #sometimes the coref deletes bodies that are one sentence\n",
    "        if len(body) == 0:\n",
    "            body = nlp(preprocess(get_body(b)))\n",
    "            body_graph = build_graph(body)\n",
    "\n",
    "        #return the shortest path to negating word for each subject in headline_subjs, if one exists\n",
    "        neg_h = get_shortest_path_to_negating(headline_graph, headline_subjs)\n",
    "        neg_b = get_shortest_path_to_negating(body_graph, headline_subjs)\n",
    "\n",
    "        #body summary\n",
    "        summary = get_summary(body, headline_subjs, n_sent)\n",
    "        first_summ_sentence = summary[0]\n",
    "        \n",
    "        summary_svos = [get_svos(s) for s in summary]\n",
    "        summary_root_dist = [root_distance(body_graph, list(s[1].keys())[0]) for s in summary_svos]\n",
    "        summary_neg_ancestors = [get_neg_ancestors(s) for s in summary]\n",
    "        summary_neg_counts = [s[2:] for s in summary_neg_ancestors]\n",
    "        \n",
    "        #svo\n",
    "        body_s, body_v, body_o = {}, {}, {}\n",
    "        headline_s, headline_v, headline_o = headline_svo\n",
    "        for svo in summary_svos:\n",
    "            body_s.update(svo[0])\n",
    "            body_v.update(svo[1])\n",
    "            body_o.update(svo[2])\n",
    "        body_s_vec = list(np.mean([body_s[s].vector for s in body_s], axis = 0)) if len(body_s) > 0 else np.zeros(384)\n",
    "        body_v_vec = list(np.mean([body_v[s].vector for s in body_v], axis = 0)) if len(body_v) > 0 else np.zeros(384)\n",
    "        body_o_vec = list(np.mean([body_o[s].vector for s in body_o], axis = 0)) if len(body_o) > 0 else np.zeros(384)\n",
    "    \n",
    "        headline_s_vec = list(np.mean([headline_s[s].vector for s in headline_s], axis = 0)) if len(headline_s) > 0 else np.zeros(384)\n",
    "        headline_v_vec = list(np.mean([headline_v[s].vector for s in headline_v], axis = 0)) if len(headline_v) > 0 else np.zeros(384)\n",
    "        headline_o_vec = list(np.mean([headline_o[s].vector for s in headline_o], axis = 0)) if len(headline_o) > 0 else np.zeros(384)\n",
    "        \n",
    "        cos_sim_s = cosine_similarity(body_s_vec, headline_s_vec)\n",
    "        cos_sim_v = cosine_similarity(body_v_vec, headline_v_vec)\n",
    "        cos_sim_o = cosine_similarity(body_o_vec, headline_o_vec)\n",
    "        \n",
    "        #negating paths\n",
    "        headline_paths = [neg_h[x] for x in neg_h]\n",
    "        headline_neg_paths = [1 if x[0] != None else 0 for x in headline_paths] + [1]\n",
    "        headline_hedge_paths = [1 if x[1] != None else 0 for x in headline_paths] + [1]\n",
    "        body_paths = [neg_h[x] for x in neg_h]\n",
    "        body_neg_paths = [1 if x[0] != None else 0 for x in body_paths] + [1]\n",
    "        body_hedge_paths = [1 if x[1] != None else 0 for x in body_paths] + [1]\n",
    "        \n",
    "        neg_path_cos_sim = cosine_similarity(headline_neg_paths, body_neg_paths)\n",
    "        hedge_path_cos_sim = cosine_similarity(headline_hedge_paths, body_hedge_paths)\n",
    "        \n",
    "        #root distance\n",
    "        avg_summary_root_dist = None\n",
    "        non_null = [x for x in summary_root_dist if x != None]\n",
    "        if len(non_null) != 0:\n",
    "            avg_summary_root_dist = sum(non_null)/len(non_null)\n",
    "        root_dist_feats = [headline_root_dist, avg_summary_root_dist]\n",
    "        root_dist_feats = [x if x != None else 100 for x in root_dist_feats]\n",
    "    \n",
    "        #sentiment\n",
    "        headline_sent = get_sentiment(headline)\n",
    "        body_sents = [get_sentiment(s) for s in summary]\n",
    "        diff_sents = list(np.sum([get_diff_sentiment(headline_sent, s) for s in body_sents], axis = 0))\n",
    "        \n",
    "        #bow\n",
    "        headline_vocab = set([tok.lemma_.lower() for tok in headline])\n",
    "        fst_summ_vocab = set([tok.lemma_.lower() for tok in first_summ_sentence])\n",
    "        total_vocab = list(headline_vocab.union(fst_summ_vocab))\n",
    "        headline_embedding = [1 if tok in headline_vocab else 0 for tok in total_vocab]\n",
    "        fst_summ_embedding = [1 if tok in fst_summ_vocab else 0 for tok in total_vocab]\n",
    "        bow_cos_sim = cosine_similarity(headline_embedding, fst_summ_embedding)\n",
    "        \n",
    "        #word vecs\n",
    "        cos_sims = [cosine_similarity(s.vector, headline.vector) for s in summary]\n",
    "        fst_cos_sim = cos_sims[0]\n",
    "        avg_cos_sim = sum(cos_sims)/len(cos_sims)\n",
    "        \n",
    "        #build final features list\n",
    "        fts = (\n",
    "            [fst_cos_sim, avg_cos_sim, bow_cos_sim, \n",
    "               neg_path_cos_sim, hedge_path_cos_sim, \n",
    "               cos_sim_s, cos_sim_v, cos_sim_o, nq_h, nq_b] + \n",
    "            headline_sent + diff_sents + root_dist_feats + \n",
    "            list(headline_neg_ancestors[2:]) + list(np.sum(summary_neg_counts, axis = 0))\n",
    "        )\n",
    "        features.append(np.nan_to_num(fts))\n",
    "        actual.append(s)\n",
    "    end = time.time()\n",
    "    print(int(end-start))\n",
    "    return features, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dannyyang/Library/Python/3.6/lib/python/site-packages/scipy/spatial/distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "training_data = get_features(stances_tr_augmented, 5)\n",
    "testing_data = get_features(stances_val, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(30):\n",
    "#     print(np.size(training_data[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(training_data[0][0])):\n",
    "#     r = []\n",
    "#     for row in training_data[0]:\n",
    "#         r.append(row[i])\n",
    "#     print(r[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [np.nan_to_num(x) for x in training_data[0]], training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'discuss': 7167, 'agree': 5744, 'disagree': 4718}) Counter({'discuss': 1742, 'agree': 806, 'disagree': 166})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(training_data[1]), Counter(testing_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6418570375829035\n"
     ]
    }
   ],
   "source": [
    "c = Counter(testing_data[1])\n",
    "baseline = c['discuss']/(c['agree']+c['disagree']+c['discuss'])\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "model = RandomForestClassifier(max_depth = 8 , n_estimators=250)\n",
    "# model = LogisticRegression(max_iter = 200)\n",
    "# model = SVC()\n",
    "model.fit(training_data[0], training_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.24% training accuracy\n",
      "68.72% validation accuracy\n",
      "Baseline comparison: 4.53%\n"
     ]
    }
   ],
   "source": [
    "tr_acc = model.score(training_data[0], training_data[1])\n",
    "print('{0:.2f}% training accuracy'.format(tr_acc*100))\n",
    "val_acc = model.score(testing_data[0], testing_data[1])\n",
    "print('{0:.2f}% validation accuracy'.format(val_acc*100))\n",
    "print(\"Baseline comparison: {0:.2f}%\".format((val_acc-baseline)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5d7d16af431f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "print(model.classes_, model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim (int): the size of the input vectors\n",
    "            hidden_dim (int): the output size of the first Linear layer\n",
    "            output_dim (int): the output size of the second Linear layer\n",
    "        \"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the MLP\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor \n",
    "                x_in.shape should be (batch, input_dim)\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the cross-entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, output_dim)\n",
    "        \"\"\"\n",
    "        intermediate = F.relu(self.fc1(x_in))\n",
    "        output = self.fc2(self.dropout(intermediate))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers=1, bidirectional=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, hidden = self.rnn(x)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        fc = self.fc(hidden.squeeze(0))\n",
    "        fc2 = self.fc2(F.relu(fc))\n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = len(training_data[0][0])\n",
    "HIDDEN_DIM = int(EMBEDDING_DIM/2)\n",
    "OUTPUT_DIM = 3\n",
    "DROPOUT = 0.3\n",
    "num_epochs = 10\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_train= int(len(training_data[1])/batch_size)\n",
    "batches_val = int(len(testing_data[1])/batch_size)\n",
    "\n",
    "mlp = MLP(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT)\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-5)\n",
    "criterion = criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 5.388 | Train Acc: 37.99% | Val. Loss: 2.029 | Val. Acc: 62.20% |\n",
      "| Epoch: 02 | Train Loss: 5.333 | Train Acc: 38.39% | Val. Loss: 2.003 | Val. Acc: 62.08% |\n",
      "| Epoch: 03 | Train Loss: 5.273 | Train Acc: 37.91% | Val. Loss: 1.978 | Val. Acc: 61.84% |\n",
      "| Epoch: 04 | Train Loss: 5.305 | Train Acc: 37.69% | Val. Loss: 1.953 | Val. Acc: 61.80% |\n",
      "| Epoch: 05 | Train Loss: 5.196 | Train Acc: 37.55% | Val. Loss: 1.930 | Val. Acc: 61.56% |\n",
      "| Epoch: 06 | Train Loss: 5.167 | Train Acc: 37.92% | Val. Loss: 1.907 | Val. Acc: 61.60% |\n",
      "| Epoch: 07 | Train Loss: 5.156 | Train Acc: 37.18% | Val. Loss: 1.884 | Val. Acc: 61.48% |\n",
      "| Epoch: 08 | Train Loss: 5.086 | Train Acc: 37.28% | Val. Loss: 1.862 | Val. Acc: 61.32% |\n",
      "| Epoch: 09 | Train Loss: 4.997 | Train Acc: 37.50% | Val. Loss: 1.840 | Val. Acc: 61.24% |\n",
      "| Epoch: 10 | Train Loss: 4.992 | Train Acc: 37.26% | Val. Loss: 1.819 | Val. Acc: 61.24% |\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss, train_acc = train(mlp, batches_train, optimizer, criterion, training_data)\n",
    "    valid_loss, valid_acc = evaluate(mlp, batches_val, criterion, testing_data)\n",
    "\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')\n",
    "end = time.time()\n",
    "print(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = None\n",
    "with torch.no_grad():\n",
    "    inputs = Variable(torch.FloatTensor(np.array(testing_data[0])))\n",
    "    labels = [(2.0 if result == \"agree\" else (1.0 if result == \"discuss\" else 0.0)) for result in testing_data[1]]\n",
    "    labels = torch.LongTensor(labels)\n",
    "    outputs = mlp(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predicted = [(\"agree\" if x == 2 else (\"discuss\" if x == 1 else \"disagree\")) for x in predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual = testing_data[1]\n",
    "predicted = model.predict(testing_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    470    |    21     |    315    |     0     |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    43     |    45     |    78     |     0     |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    308    |    84     |   1350    |     0     |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |     0     |     0     |     0     |     0     |\n",
      "-------------------------------------------------------------\n",
      "Score: 2077.25 out of 2714.0\t(76.53831982313928%)\n",
      "Normalized confusion matrix\n",
      "[[0.58312655 0.02605459 0.39081886]\n",
      " [0.25903614 0.27108434 0.46987952]\n",
      " [0.17680827 0.04822044 0.7749713 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAEYCAYAAAApuP8NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEu//A20RHnCZOODzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e88240f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc.report_score(actual, predicted)\n",
    "matrix = confusion_matrix(actual,predicted)\n",
    "plot_confusion_matrix(matrix, classes=[\"agree\",\"disagree\", \"discuss\"],\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
