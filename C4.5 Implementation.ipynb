{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "C4.5 Binary Decision Tree Implementation\n",
    "\n",
    "Usage: \n",
    "Read csv file in; will be stored as a 2 Dimensional list. (See fread())\n",
    "Train a classifier (i.e. train(list))\n",
    "Prune the decision tree (i.e. prune_tree(tree, 0.5))\n",
    "Predict the result (i.e. predict([.....], classifier))\n",
    "\n",
    "The function assumes that the last column of your data is populated by labels.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.feature_selection import mutual_info_classif\n",
    "from collections import OrderedDict\n",
    "from math import log\n",
    "import csv\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fread(\"./Iris.csv\", True)\n",
    "#n * d data, n rows d cols\n",
    "df = [i[1:] for i in df]\n",
    "\n",
    "#these are for performance testing estimates\n",
    "df2 = df[:int(len(df)/2)] #n/2\n",
    "df3 = [i[:2] for i in df] #d/2\n",
    "df4 = [i[:-1]+i for i in df] #2d\n",
    "df5 = df+df # 2n\n",
    "df6 = df5+df5 #4n\n",
    "df7 = [i[:-1]+i for i in df4] #4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def n_distinct_dict(rows):\n",
    "    counts = dict()\n",
    "    for x in rows:\n",
    "        xs = x[-1]\n",
    "        if xs not in counts: \n",
    "            #Add it to the counts dictionary\n",
    "            counts[xs] = 0\n",
    "        counts[xs] += 1\n",
    "    return counts\n",
    "\n",
    "def entropy(X):\n",
    "    \"\"\"\n",
    "    Calculate Entropy (as per Octavian)\n",
    "    \"\"\"\n",
    "    counts = n_distinct_dict(X)\n",
    "    log_2 = lambda x: log(x)/log(2)\n",
    "    #Declare entropy value\n",
    "    entropy = 0.0\n",
    "    \n",
    "    for c in counts:\n",
    "        #Calculate P(C_i)\n",
    "        p = float(counts[c])/len(X)\n",
    "        entropy = entropy -  p*log_2(p)\n",
    "    return entropy\n",
    "\n",
    "def gini(X):\n",
    "    \"\"\"\n",
    "    Calculate Gini Index\n",
    "    \"\"\"\n",
    "    total = len(X)\n",
    "    counts = n_distinct_dict(X)\n",
    "    imp = 0.0\n",
    "    \n",
    "    for k1 in counts:\n",
    "        p1 = float(counts[k1])/total  \n",
    "        for k2 in counts:\n",
    "            if k1 == k2: continue\n",
    "            p2 = float(counts[k2])/total\n",
    "            imp += p1*p2\n",
    "    return imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Test1': 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    1\n",
      "Name: Test1, dtype: int64, 'Test2': 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    1\n",
      "Name: Test2, dtype: int64}\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    \"\"\"\n",
    "    Decision Tree class\n",
    "    \"\"\"\n",
    "    def __init__(self, col=-1, value=None, right_branch=None, left_branch=None, results=None):\n",
    "        self.col = col\n",
    "        self.value = value\n",
    "        self.right_branch = right_branch\n",
    "        self.left_branch = left_branch\n",
    "        self.results = results\n",
    "\n",
    "\n",
    "def prune_tree(tree, least_gain, eval_fun = entropy):\n",
    "    \"\"\"\n",
    "    tree : type Tree\n",
    "    eval_fun : entropy(X) or gini(X)\n",
    "    least_gain : float\n",
    "    \"\"\"\n",
    "    \n",
    "    if tree.right_branch.results == None: #if the right branch is a node\n",
    "        prune_tree(tree.right_branch, least_gain, eval_fun)\n",
    "    if tree.left_branch.results == None: #if the left branch is a node\n",
    "        prune_tree(tree.left_branch, least_gain, eval_fun)\n",
    "    if (tree.right_branch.results != None) and (tree.left_branch.results != None):\n",
    "        right, left = [], []\n",
    "        for v, c in tree.right_branch.results.items(): \n",
    "            right += [[v]] * c\n",
    "        for v, c in tree.left_branch.results.items(): \n",
    "            left += [[v]] * c\n",
    "        p = float(len(right)) / len(left + right)\n",
    "        diff_entropy = eval_fun(right+left) - p*eval_fun(right) - (1-p)*eval_fun(left)\n",
    "        if diff_entropy < least_gain:\n",
    "            tree.right_branch, tree.left_branch = None, None\n",
    "            tree.results = n_distinct_dict(left + right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper functions\n",
    "\"\"\"\n",
    "def type_conversion(val):\n",
    "        val = val.strip()\n",
    "        \n",
    "        try:\n",
    "            if '.' in val:\n",
    "                return float(val)\n",
    "            else:\n",
    "                return int(val)\n",
    "            \n",
    "        except ValueError:\n",
    "            #For other types, return\n",
    "            return val\n",
    "        \n",
    "def fread(f, col_labels = False):\n",
    "    \"\"\"\n",
    "    takes a filepath, f, and a boolean argument, col_labels.\n",
    "    By default, col_labels is False, implying that the columns do not have labels. If set to true,\n",
    "    fread will remove the row containing column labels at the end.\n",
    "    \"\"\"\n",
    "    data = csv.reader(open(f, 'rt'))\n",
    "    lst = [[type_conversion(i) for i in r] for r in data]\n",
    "    if col_labels:\n",
    "        lst.pop(0)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition(r, c, val):\n",
    "    \"\"\"\n",
    "    Function to partition the data based on value\n",
    "    \"\"\"\n",
    "    #Declare anonymous function\n",
    "    split_fun = None\n",
    "    if isinstance(val, float) or isinstance(val, int): \n",
    "        #Anonymous function for numeric values\n",
    "        split_fun = lambda row : row[c] >= val\n",
    "    else: \n",
    "        #For string values\n",
    "        split_fun = lambda row : row[c] == val\n",
    "    list1 = [row for row in r if split_fun(row)]\n",
    "    list2 = [row for row in r if not split_fun(row)]\n",
    "    return (list1, list2)\n",
    "\n",
    "\n",
    "\n",
    "def train(lst, criteria = entropy):\n",
    "    \"\"\"\n",
    "    Decision tree construction - by default, the entropy function is used to calculate the criteria for splitting. \n",
    "    lst : dataframe with the last column reserved for labels\n",
    "    criteria : entropy or gini calculation function\n",
    "    \"\"\"\n",
    "    #Base Case: Empty Set\n",
    "    if len(lst) == 0: \n",
    "        return Tree()\n",
    "    \n",
    "    #Calculate Entropy/Gini of current X, declare A_best, create sets/gain accordingly\n",
    "    score = criteria(lst)\n",
    "    Attribute_best = None\n",
    "    Set_best = None\n",
    "    Gain_best = 0.0\n",
    "    \n",
    "\n",
    "    num_col = len(lst[0]) - 1  # last column of lst is labels\n",
    "    for c in range(num_col):\n",
    "        col_val = [row[c] for row in lst]\n",
    "        for value in col_val:\n",
    "            #Split dataset\n",
    "            (set1, set2) = partition(lst, c, value)\n",
    "            # Calculate Gain\n",
    "            p = float(len(set1))/len(lst)\n",
    "            gain = score - p*criteria(set1) - (1-p)*criteria(set2)\n",
    "            if gain>Gain_best and len(set1)>0 and len(set2)>0:\n",
    "                Gain_best = gain\n",
    "                Attribute_best = (c, value)\n",
    "                Set_best = (set1, set2)\n",
    "\n",
    "    if Gain_best > 0:\n",
    "        #Recursive Call on partitioned Sets\n",
    "        right_branch = train(Set_best[0])\n",
    "        left_branch = train(Set_best[1])\n",
    "        return Tree(col=Attribute_best[0], value=Attribute_best[1], right_branch=right_branch, left_branch=left_branch)\n",
    "    \n",
    "    else:\n",
    "        return Tree(results=n_distinct_dict(lst))\n",
    "\n",
    "\n",
    "def tree_classify(X, tree):\n",
    "    \"\"\"\n",
    "    Classification function using a list read from fread, X, and grown Decision Tree, tree\n",
    "    \"\"\"\n",
    "    if tree.results != None:\n",
    "        return (tree.results)\n",
    "    else:\n",
    "        b = None\n",
    "        val = X[tree.col] #Retrieve label from dataframe X\n",
    "        if isinstance(val, float) or isinstance(val,int):\n",
    "            #Traversing decision tree for numerics\n",
    "            if val >= tree.value:\n",
    "                branch = tree.right_branch\n",
    "            else:\n",
    "                branch = tree.left_branch\n",
    "            \n",
    "        else:\n",
    "            #Traversing decision tree for non-numeric types\n",
    "            if val == tree.value:\n",
    "                branch = tree.right_branch\n",
    "            else:\n",
    "                branch = tree.left_branch\n",
    "    return tree_classify(X, branch)\n",
    "\n",
    "def predict(x, classifier):\n",
    "    return list(tree_classify(x, classifier))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "Optimize\n",
    "Testing\n",
    "\"\"\"\n",
    "\n",
    "data = fread(\"./test_val_dump.csv\", True)\n",
    "drop_first_col = []\n",
    "for x in data:\n",
    "    drop_first_col.append(x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = train(drop_first_col)\n",
    "prune_tree(tree, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(predict([2,0,2,6,1,0,0,3,1,0,0,2,0,0,0,0,0,1,.223606798,0,.285714,.141421,0,.253546],tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe base cases are the following:\\n\\n•  All the examples from the training set belong to the same class ( a tree leaf labeled with that class is returned ).\\n\\n•  The training set is empty ( returns a tree leaf called failure ).\\n\\n•  The attribute list is empty ( returns a leaf labeled with the most frequent class or the disjuction of all the classes).\\nhttps://octaviansima.wordpress.com/2011/03/25/decision-trees-c4-5/\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The base cases are the following:\n",
    "\n",
    "•  All the examples from the training set belong to the same class ( a tree leaf labeled with that class is returned ).\n",
    "\n",
    "•  The training set is empty ( returns a tree leaf called failure ).\n",
    "\n",
    "•  The attribute list is empty ( returns a leaf labeled with the most frequent class or the disjuction of all the classes).\n",
    "https://octaviansima.wordpress.com/2011/03/25/decision-trees-c4-5/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09544761092518456\n"
     ]
    }
   ],
   "source": [
    "#n * d\n",
    "times = []\n",
    "for i in range(25):\n",
    "    start = timeit.default_timer()\n",
    "    tree = train(df)\n",
    "    prune_tree(tree, 0.5)\n",
    "    stop = timeit.default_timer()\n",
    "    times.append(stop-start)\n",
    "print(sum(times)/len(times)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01982154435128905\n"
     ]
    }
   ],
   "source": [
    "#n/2 * d\n",
    "times = []\n",
    "for i in range(25):\n",
    "    start = timeit.default_timer()\n",
    "    tree = train(df2)\n",
    "    prune_tree(tree, 0.5)\n",
    "    stop = timeit.default_timer()\n",
    "    times.append(stop-start)\n",
    "print(sum(times)/len(times)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.038575201586354524\n"
     ]
    }
   ],
   "source": [
    "#n * d/2\n",
    "times = []\n",
    "for i in range(25):\n",
    "    start = timeit.default_timer()\n",
    "    tree = train(df3)\n",
    "    prune_tree(tree, 0.5)\n",
    "    stop = timeit.default_timer()\n",
    "    times.append(stop-start)\n",
    "print(sum(times)/len(times)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1923355341120623\n"
     ]
    }
   ],
   "source": [
    "#n * 2d\n",
    "times = []\n",
    "for i in range(25):\n",
    "    start = timeit.default_timer()\n",
    "    tree = train(df4)\n",
    "    prune_tree(tree, 0.5)\n",
    "    stop = timeit.default_timer()\n",
    "    times.append(stop-start)\n",
    "print(sum(times)/len(times)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3688689094118308\n"
     ]
    }
   ],
   "source": [
    "#2n * d\n",
    "times = []\n",
    "for i in range(25):\n",
    "    start = timeit.default_timer()\n",
    "    tree = train(df5)\n",
    "    prune_tree(tree, 0.5)\n",
    "    stop = timeit.default_timer()\n",
    "    times.append(stop-start)\n",
    "print(sum(times)/len(times)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.384299785438925\n"
     ]
    }
   ],
   "source": [
    "#4n * d\n",
    "times = []\n",
    "for i in range(25):\n",
    "    start = timeit.default_timer()\n",
    "    tree = train(df6)\n",
    "    prune_tree(tree, 0.5)\n",
    "    stop = timeit.default_timer()\n",
    "    times.append(stop-start)\n",
    "print(sum(times)/len(times)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3654549332521856\n"
     ]
    }
   ],
   "source": [
    "#n * 4d\n",
    "times = []\n",
    "for i in range(25):\n",
    "    start = timeit.default_timer()\n",
    "    tree = train(df7)\n",
    "    prune_tree(tree, 0.5)\n",
    "    stop = timeit.default_timer()\n",
    "    times.append(stop-start)\n",
    "print(sum(times)/len(times)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
