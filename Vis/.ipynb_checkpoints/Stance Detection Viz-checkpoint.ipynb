{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stance Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5d65a9a68fef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_engineering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'preprocessing'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import preprocessing, feature_engineering, helpers\n",
    "import importlib\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import itertools\n",
    "import utils\n",
    "import importlib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(preprocessing)\n",
    "importlib.reload(feature_engineering)\n",
    "importlib.reload(helpers)\n",
    "importlib.reload(utils)\n",
    "preprocess = preprocessing.Preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stances = pd.read_csv(\"fn_data/train_stances.csv\")\n",
    "train_stances = train_stances.loc[lambda x: x.Stance != \"unrelated\"]\n",
    "print(train_stances.shape)\n",
    "train_stances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_bodies = pd.read_csv(\"fn_data/train_bodies.csv\")\n",
    "print(train_bodies.shape)\n",
    "train_bodies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stances_tr, stances_val = preprocess.train_test_split(train_bodies, train_stances)\n",
    "stances_tr.shape, stances_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct,ct2 = Counter(stances_val['Stance']),Counter(stances_tr['Stance'])\n",
    "print(ct, ct2)\n",
    "print(ct.most_common(1)[0][1]/len(list(stances_val[\"Stance\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dict = preprocess.get_glove_dict(\"glove.6B.50d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(nltk.pos_tag([x]),preprocess.get_sentiment(x)) for x in preprocess.get_clean_tokens(list(stances_tr.iloc[2,:])[0], False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess.cosine_similarity(glove_dict['reveal'], glove_dict['revealed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagrees = stances_tr[stances_tr[\"Stance\"]==\"disagree\"]\n",
    "stances_tr = pd.concat([stances_tr, disagrees, disagrees]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(stances_tr['Stance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?preprocess.get_clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word_stance(word, glove_dict):\n",
    "    #50d word vector\n",
    "    if word in glove_dict:\n",
    "        wv = glove_dict[word]\n",
    "    else:\n",
    "        wv = np.zeros((50, ))\n",
    "    #4d sentiment\n",
    "    sent = preprocess.get_sentiment(word)\n",
    "    #16d one-hot encoding of part of speech (shortened)\n",
    "    pos = nltk.pos_tag(word)[1][0]\n",
    "    pos_encoding = [(1 if tag == pos else 0) for tag in preprocess.pos_short]\n",
    "    #boolean flag for negating word\n",
    "    stemmed_word = preprocess.stem_word(word)\n",
    "    is_neg = (1 if stemmed_word in preprocess.negating_words_stemmed else 0)\n",
    "    is_refuting = (1 if stemmed_word in preprocess.refuting_words_stemmed else 0)\n",
    "    embedding = np.concatenate([wv, [sent[\"pos\"], sent[\"neg\"], sent[\"neu\"], sent[\"compound\"], is_neg, is_refuting], pos_encoding])\n",
    "    return embedding\n",
    "\n",
    "def process_text_stance(text, glove_dict, n_words = 20):\n",
    "    tokens = preprocess.get_clean_tokens(text, False)\n",
    "    if len(tokens)>=n_words:\n",
    "        tokens = tokens[:n_words]\n",
    "        encoding = np.array([process_word_stance(token, glove_dict) for token in tokens])\n",
    "    elif len(tokens)<n_words:\n",
    "        padding = [np.zeros((72,))]*(n_words-len(tokens))\n",
    "        encoding = np.array([process_word_stance(token, glove_dict) for token in tokens]+padding)\n",
    "    return encoding\n",
    "\n",
    "def process_bodies_stance(df, glove_dict):\n",
    "    body_info = {}\n",
    "    ids = list(df[\"Body ID\"])\n",
    "    for i in range(len(ids)):\n",
    "        if i % 100 == 0 and i != 0:\n",
    "            print(\"processed \"+str(i))\n",
    "        body_info[ids[i]] = process_text_stance(preprocess.get_body(ids[i],df), glove_dict, 40)\n",
    "    print(\"done! processed \" + str(len(ids)))\n",
    "    return body_info\n",
    "\n",
    "def process_feats_stance(data, body_dict, glove_dict):\n",
    "    headline, body_id = data[0], int(data[1])\n",
    "    padding = [np.zeros((72,))]*(1)\n",
    "    return np.concatenate([process_text_stance(headline, glove_dict), np.array(padding), body_dict[body_id]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_dict = process_bodies_stance(train_bodies, glove_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "train_feats = [process_feats_stance(i, body_dict, glove_dict) for i in stances_tr.values]\n",
    "val_feats = [process_feats_stance(i, body_dict, glove_dict) for i in stances_val.values]\n",
    "end = time.time()\n",
    "print(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(val_feats).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, targets, i,batch_size):\n",
    "    batches = data[i*batch_size:i*batch_size+batch_size]\n",
    "    results = targets[i*batch_size:i*batch_size+batch_size]\n",
    "    results = [(2.0 if result == \"agree\" else (1.0 if result == \"discuss\" else 0.0)) for result in results]\n",
    "    batches = np.array(batches)\n",
    "    return np.swapaxes(batches, 0, 1), np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "def eval_model(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_x_test,batch_y_test = get_batch(val_feats,[str(x[-1]) for x in stances_val.values],0,len(stances_val))\n",
    "    model.eval()\n",
    "    predicted = None\n",
    "    with torch.no_grad():\n",
    "        inputs = Variable(torch.FloatTensor(batch_x_test))\n",
    "        labels = torch.LongTensor(batch_y_test)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy: %d %%' % (100 * correct / total))\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(predictions):    \n",
    "    #use FNC scorer to generate score report\n",
    "    label_prediction = [(\"agree\" if x == 2 else (\"discuss\" if x == 1 else \"disagree\")) for x in predictions]\n",
    "    label_actual = pd.DataFrame(stances_val)['Stance']\n",
    "    matrix = confusion_matrix(label_actual,label_prediction)\n",
    "    print('confusion matrix: \\n{}\\n'.format(matrix))\n",
    "    score.report_score(label_actual, label_prediction)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    correct = (preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla RNN\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, hidden = self.rnn(x)\n",
    "        #hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        fc = self.fc(hidden.squeeze(0))\n",
    "        self.output = output\n",
    "        return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "class RNN_LSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = [sent len, batch size, emb dim]\n",
    "        output, (hidden, cell) = self.rnn(x)\n",
    "        #output = [sent len, batch size, hid dim * num directions]\n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        #cell = [num layers * num directions, batch size, hid dim]\n",
    "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        #and apply dropout\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        fc = self.fc(hidden.squeeze(0))\n",
    "        fc2 = self.fc2(F.relu(fc))\n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU\n",
    "class RNN_GRU(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, hidden = self.rnn(x)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        fc = self.fc(hidden.squeeze(0))\n",
    "        fc2 = self.fc2(F.relu(fc))\n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 8\n",
    "batch_size = 250\n",
    "\n",
    "EMBEDDING_DIM = 72\n",
    "OUTPUT_DIM = 3\n",
    "DROPOUT = 0.2\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RNN(EMBEDDING_DIM, 128, OUTPUT_DIM, 1, DROPOUT)\n",
    "opt1 = torch.optim.Adam(model1.parameters(), lr=2e-4)\n",
    "m1 = model1, opt1\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = [m1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, total_batch, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = get_batch(train_feats, [str(x[-1]) for x in stances_tr.values],i,batch_size)\n",
    "        inputs = Variable(torch.FloatTensor(batch_x))\n",
    "        labels = Variable(torch.LongTensor(batch_y))\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(inputs)\n",
    "        loss = criterion(predictions, labels)\n",
    "        _, predicted = torch.max(predictions.data, 1)\n",
    "        acc = binary_accuracy(predicted, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / total_batch, epoch_acc / total_batch\n",
    "\n",
    "def evaluate(model, total_batch, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(total_batch):\n",
    "            batch_x,batch_y = get_batch(val_feats, [str(x[-1]) for x in stances_val.values],i,batch_size)\n",
    "            inputs = Variable(torch.FloatTensor(batch_x))\n",
    "            labels = Variable(torch.LongTensor(batch_y))\n",
    "            predictions = model(inputs)\n",
    "            loss = criterion(predictions, labels)\n",
    "            _, predicted = torch.max(predictions.data, 1)\n",
    "            acc = binary_accuracy(predicted, labels)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / total_batch, epoch_acc / total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batches_train= int(len(train_feats)/batch_size)\n",
    "batches_val = int(len(val_feats)/batch_size)\n",
    "\n",
    "for x in queue:\n",
    "    model = x[0]\n",
    "    optimizer = x[1]\n",
    "    print(\"\\n\")\n",
    "    start = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(model, batches_train, optimizer, criterion)\n",
    "        valid_loss, valid_acc = evaluate(model, batches_val, criterion)\n",
    "\n",
    "        print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')\n",
    "    end = time.time()\n",
    "    print(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch_x,batch_y = get_batch(val_feats, [str(x[-1]) for x in stances_val.values],0,1)\n",
    "    inputs = Variable(torch.FloatTensor(batch_x))\n",
    "    labels = Variable(torch.LongTensor(batch_y))\n",
    "    predictions = model(inputs)\n",
    "    _, predicted = torch.max(predictions.data, 0)\n",
    "output = model.output.permute([1,0,2]).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try comparing L2 norm for each input. This is for WHOLE hidden state\n",
    "# ignore for now\n",
    "\"\"\"hidden_mag = np.array([np.linalg.norm(i) for i in output])\n",
    "print(scipy.stats.describe(hidden_mag))\n",
    "print(hidden_mag.shape)\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks at the activations for the specific neuron in a hidden state\n",
    "# the features we'll actually compare\n",
    "cell = np.array(np.swapaxes(output, 0, 1)[0])\n",
    "print(scipy.stats.describe(cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the full headline text\n",
    "body = stances_val.iloc[0][\"Body ID\"]\n",
    "text_body = preprocess.get_body(body,train_bodies)\n",
    "text_headline = stances_val.iloc[0][\"Headline\"]\n",
    "\n",
    "# Get the tokens that are actually fed into the network\n",
    "tokens_body = preprocess.get_clean_tokens(text_body, False)[:40]\n",
    "tokens_headline = preprocess.get_clean_tokens(text_headline, False)[:20]\n",
    "tokens = np.concatenate((tokens_headline, tokens_body))\n",
    "\n",
    "text_body = text_body.split(\" \")\n",
    "text_headline = text_headline.split(\" \")\n",
    "text = np.concatenate((text_headline[:20], text_body[:40]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values = get_values(text, tokens, cell)\n",
    "values_body = v[-40:] # Gets the body text\n",
    "values_headline = v[:-40] # Gets the headline text\n",
    "values_json = {\"body\":values_body, \"headline\":values_headline}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_values(text, tokens, cell):\n",
    "    wln = nltk.WordNetLemmatizer()\n",
    "    j = 0 # index in tokens for duplicate token values\n",
    "    num_word = 0\n",
    "    body = [{} for i in range(len(text))]\n",
    "        \n",
    "    for i in range(len(text)):\n",
    "        test = preprocess.clean(text[i])\n",
    "        test = preprocess.get_tokenized_lemmas(test)\n",
    "        test = preprocess.remove_stopwords(test, True)\n",
    "        if(len(test)==0): \n",
    "            body[i] = {text[i]:str(0)}\n",
    "            #print(text_body[i], 0)\n",
    "        else:\n",
    "            #token_index = np.where(tokens[j:]==test[0])\n",
    "            index = list(tokens[j:]).index(test[0])\n",
    "            body[i] = {text[i]:str(cell[index])}\n",
    "            j+=1\n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('Vis/activations.json', 'w') as outfile:  \n",
    "    json.dump(values_json, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Recreate the whole sentence and body, with non-token words having a value of 0\n",
    "# and turn into a JSON for viz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find a way to quickly identify cells that have meaningful pattenrs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
